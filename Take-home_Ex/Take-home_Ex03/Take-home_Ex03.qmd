---
title: "Take-home Exercise 3 - Vast Challenge 2024"
author: "Alicia Loh"
date: "May 10, 2024"
date-modified: last-modified
execute: 
  eval: true
  echo: true
  warning: false
  freeze: false
---

# **The Source**

The task is taken from the [VAST Challenge 2024](https://vast-challenge.github.io/2024/). Questions from [Mini Case 3: Temporal Analysis](https://vast-challenge.github.io/2024/MC3.html) will be completed.

# Challenge Overview

![](data/Oceanus%20Information/Oceanus%20Location.png){width="288"}

![](data/Oceanus%20Information/Oceanus%20Geography.png){width="308"}

Welcome to Oceanus, an island nation with a healthy market for commercial fishing. Most companies in the region are united in following regulations and implementing sustainable fishing practices. But there are a few companies who are willing to cross ethical lines to increase their catch and their profits. Luckily, FishEye International maintains a watchful eye on fishing data. Their dedicated analysts have been processing data from various sources into a knowledge graph that they call CatchNet: the Oceanus Knowledge Graph.

# **The Task**

![](images/clipboard-587959097.png){width="320"}

Mini-challenge 3 concerns visualizing changes in business relationships within the commercial fishing industry. FishEye wants to understand how companies react to the closure of a competitor caught fishing illegally and how these changes affect influence networks. Design visualizations to show these changes over time and identify companies that may benefit from illegal fishing

Apply appropriate visual analytics methods to help FishEye, a non-profit organization that focuses on illegal fishing, to better identify bias, track behavior changes, and infer temporal patterns from the knowledge graphs prepared by their data analysts.

This take home exercise is done in conjunction with the group project. My group members are [Keke](https://isss608keke.netlify.app/) and [Quek You Ting](https://isss608ytquek.netlify.app/).

## Background

The business community in Oceanus is dynamic with new startups, mergers, acquisitions, and investments. FishEye International closely watches business records to keep tabs on commercial fishing operators. FishEye’s goal is to identify and prevent illegal fishing in the region’s sensitive marine ecosystem. Analysts are working with company records that show ownership, shareholders, transactions, and information about the typical products and services of each entity. FishEye’s analysts have a hybrid automated/manual process to transform the data into CatchNet: the Oceanus Knowledge Graph.

In the past year, Oceanus’s commercial fishing business community was rocked by the news that SouthSeafood Express Corp was caught fishing illegally. FishEye wants to understand temporal patterns and infer what may be happening in Oceanus’s fishing marketplace because of SouthSeafood Express Corp’s illegal behavior and eventual closure. The competitive nature of Oceanus’s fishing market may cause some businesses to react aggressively to capture SouthSeafood Express Corp’s business while other reactions may come from the awareness that illegal fishing does not go undetected and unpunished.

## Tasks and Questions:

A key element in stopping illegal fishing is holding the people who own nefarious companies accountable. Thus, FishEye is keenly interested in developing visualization tools that work with CatchNet to identify the people who hold influence over business networks. That is especially difficult with varied and changing shareholder and ownership relationships.

1.  FishEye analysts want to better visualize changes in corporate structures over time. Create a visual analytics approach that analysts can use to highlight temporal patterns and changes in corporate structures. Examine the most active people and businesses using visual analytics.

2.  Using your visualizations, find and display examples of typical and atypical business transactions (e.g., mergers, acquisitions, etc.). Can you infer the motivations behind changes in their activity?

3.  Develop a visual approach to examine inferences. Infer how the influence of a company changes through time. Can you infer ownership or influence that a network may have?

4.  Identify the network associated with SouthSeafood Express Corp and visualize how this network and competing businesses change as a result of their illegal fishing behavior. Which companies benefited from SouthSeafood Express Corp legal troubles? Are there other suspicious transactions that may be related to illegal fishing? Provide visual evidence for your conclusions.

Note: the VAST challenge is focused on visual analytics and graphical figures should be included with your response to each question. Please include a reasonable number of figures for each question (no more than about 6) and keep written responses as brief as possible (around 250 words per question). Participants are encouraged to new visual representations rather than relying on traditional or existing approaches.

**Reflection Questions**

-   Which version of the data did you choose to work with and why? Did you download more than one version and change course during the challenge?

-   Given the task to develop visualizations for knowledge graphs, did you find that the challenge pushed you to develop new techniques for visual representation?

-   Did you participate in last year’s challenge? If so, did your experience last year help prepare you for this year’s challenge?

-   What was the most difficult part of working on this year’s data and what could have made it more accessible?

# Getting Started

## Installing and loading the required libraries

Note: Ensure that the [pacman](https://cran.r-project.org/web/packages/pacman/) package has already been installed.

The following R packages will be used:

-   tidytext

-   tidyverse

-   readtext

-   quanteda

-   jsonlite

-   igraph

-   tidygraph

-   ggraph

-   visNetwork

-   [clock](https://cran.r-project.org/web/packages/clock/index.html)

```{r}
pacman::p_load(tidytext, readtext, quanteda, tidyverse, jsonlite, igraph, tidygraph, ggraph, visNetwork, clock, graphlayouts)
```

## **Importing JSON File**

Direct import of the mc3.json file shows an error message indicating that there's an invalid character in the JSON text, specifically "NaN". As "NaN" is not recognised as a valid value, preprocessing of the JSON file to replace "NaN" is required.

In the code chunk below, *mc3.json* is first imported, then all instances of "NaN" are replaced with "null", and the processed file is written into a json file *mc3_fixed.json* for later use.

```{r}
# Read the JSON file as text
json_text <- readLines("data/mc3.json")

# Replace "NaN" with "null"
json_text_fixed <- gsub("NaN", "null", json_text)

# Write the fixed JSON text back to a file
writeLines(json_text_fixed, "data/mc3_fixed.json")
```

Importing preprocessed mc3_fixed.json file

```{r}
mc3_data <- fromJSON("data/mc3_fixed.json")
```

Check dataframe

-   Opens new tabs within R workspace, not shown in website

-   Example of the view is shown in the screenshot tab below

::: panel-tabset
## Code

```{r,eval=FALSE}
view(mc3_data[["nodes"]])
view(mc3_data[["links"]])
```

## Screenshot Example

mc3_data\[\["nodes'\]

![](images/clipboard-1212461262.png)

![](images/clipboard-3963926457.png)

mc3_data\[\["links"\]\]

![](images/clipboard-2580708180.png)

![](images/clipboard-3147037567.png)
:::

View dataframe

-   Similar info as shown above

```{r}
glimpse(mc3_data)
```

::: callout-note
mc3_date\[\["nodes"\]\] dataframe contains 15 columns and 60520 rows.

mc3_date\[\["links"\]\] dataframe contains 11 columns and 75817 rows.
:::

::: callout-note
On closer inspection of `mc3_data`, we note some issues to be rectified:

1.  Columns containing dates are treated as “Character” data type instead of *date* data type, which is incorrect. Thus, the data type of the following fields need to be changed to “Date”” data type:
    -   founding_date
    -   \_last_edited_date
    -   \_date_added
    -   start_date
    -   \_last_edited_date
    -   \_date_added
    -   dob
2.  Some columns have missing values, which need to be handled appropriately for ease of later analysis.
3.  Some columns are prefixed with "\_", we remove them to reduce chance of bugs later
:::

## Missing Values

Identify the percentage of missing values within the dataset

```{r}
# Function to calculate missing value percentages
calculate_missing_percentage <- function(df) {
  total_values <- nrow(df) * ncol(df)
  missing_values <- sum(is.na(df))
  missing_percentage <- (missing_values / total_values) * 100
  return(missing_percentage)
}
```

::: panel-tabset
## Nodes

```{r}
nodes_missing_percentage <- calculate_missing_percentage(mc3_data[["nodes"]])
nodes_missing_percentage

nodes_missing_by_column <- sapply(mc3_data[["nodes"]], function(x) sum(is.na(x)) / length(x) * 100)
nodes_missing_by_column
```

## Links

```{r}
links_missing_percentage <- calculate_missing_percentage(mc3_data[["links"]])
links_missing_percentage

links_missing_by_column <- sapply(mc3_data[["links"]], function(x) sum(is.na(x)) / length(x) * 100)
links_missing_by_column
```
:::

::: callout-note
Nodes: Overall, there are 35.12% missing values. While most columns have no missing values, the majority of those with missing data pertain to optional attributes:

-   ProductServices (Optional) - 85.34%

-   PointOfContact (Optional)- 85.38%

-   HeadofOrg (Optional) - 85.36%

-   founding_date - 85.34%

-   revenue (Optional) - 85.37%

-   TradeDescription (Optional) - 85.34%

-   dob - 14.66%

Links: Overall, there are 9.06% missing values. Most of the columns do not contain missing values, except for:

-   start_date - 0.12%

-   end_date (Optional) - 99.54%

In addition, according to the *VAST2024 - MC3 Data Description* file, all empty values in the revenue column are supposed to have been set to 0. However, there are still some values with "NA".
:::

## Setting empty values in *`revenue`* to 0

```{r}
# Create a copy of mc3_data
mc3_data2 <- mc3_data

# Set empty values in revenue to 0 and save it to the new list
mc3_data2$nodes$revenue <- ifelse(is.na(mc3_data2$nodes$revenue) | mc3_data2$nodes$revenue == "", 0, mc3_data2$nodes$revenue)
```

Verify changes

```{r}
# ensure no more missing values in revenue column
sum(is.na(mc3_data2$nodes$revenue))
```

## Rename Columns

Remove prefix "\_" from columns to reduce chance of issues later

```{r}
# Function to remove leading underscores from column names
remove_leading_underscores <- function(df) {
  colnames(df) <- gsub("^_", "", colnames(df))
  return(df)
}

# Create a copy of mc3_data2 and name it mc3_data3
mc3_data3 <- mc3_data2

# Apply the function to the nodes and links data frames in mc3_data3
mc3_data3$nodes <- remove_leading_underscores(mc3_data3$nodes)
mc3_data3$links <- remove_leading_underscores(mc3_data3$links)
```

Verify changes

```{r}
colnames(mc3_data3$nodes)
colnames(mc3_data3$links)
```

## Standardising Date Time Formats

In preparation for temporal analysis

```{r}

# Create a copy of mc3_data3 and name it mc3_data4
mc3_data4 <- mc3_data3

# Convert date columns to Date-Time type
mc3_data4$nodes <- mc3_data4$nodes %>%
  mutate(
    founding_date = ymd_hms(founding_date),
    last_edited_date = ymd_hms(last_edited_date),
    date_added = ymd_hms(date_added),
    dob = ymd_hms(dob)
  )

mc3_data4$links <- mc3_data4$links %>%
  mutate(
    start_date = ymd_hms(start_date),
    last_edited_date = ymd_hms(last_edited_date),
    date_added = ymd_hms(date_added),
    end_date = ymd_hms(end_date)
  )
```

::: callout-note
The `ymd_hms` function is designed to work with character vectors and will return `NA` for any existing `NA` values. This means that any `NA` value in the original columns will remain `NA` after the conversion.
:::

Verify changes

```{r}
# View the first few rows of the date columns in nodes
head(mc3_data4$nodes %>% select(founding_date, last_edited_date, date_added, dob))

# View the first few rows of the date columns in links
head(mc3_data4$links %>% select(start_date))

# Summary of date columns in nodes
summary(mc3_data4$nodes %>% select(founding_date, last_edited_date, date_added, dob))

# Summary of date columns in links
summary(mc3_data4$links %>% select(start_date))
```

```{r,eval=FALSE}
view(mc3_data4[["nodes"]])
view(mc3_data4[["links"]])
```

## Split Words

The steps below will be used to split text in type column of **nodes** into two columns: namely type1 and type2.

```{r}
# Make a copy of mc3_data4
mc3_data5 <- mc3_data4

# Split the type column into two columns, handling the special case
mc3_data5$nodes <- mc3_data5$nodes %>%
  mutate(
    type1 = sub("(.*?\\..*?)(\\.[^.]+)?$", "\\1", type),
    type2 = ifelse(grepl("\\.", type), sub(".*\\.", "", type), "Organization")
  )

# remove the original 'type' column
mc3_data5$nodes <- mc3_data5$nodes %>%
  select(-type)
```

The steps below will be used to split text in type column of **links** into two columns: namely type1 and type2.

```{r}
# Make a copy of mc3_data4
mc3_data6 <- mc3_data5

# Split the type column into two columns, handling the special case
mc3_data6$links <- mc3_data6$links %>%
  mutate(
    type1 = sub("(.*?\\..*?)(\\.[^.]+)?$", "\\1", type),
    type2 = ifelse(grepl("\\.", type), sub(".*\\.", "", type), "")
  )

# remove the original 'type' column
mc3_data6$links <- mc3_data6$links %>%
  select(-type)
```

Verify changes

```{r,eval=FALSE}
view(mc3_data6[["nodes"]])
view(mc3_data6[["links"]])
```

## Extract Nodes

```{r}
mc3_nodes <- as_tibble(mc3_data6$nodes)
```

Save as rds file for future use

```{r}
write_rds(mc3_nodes, "data/rds/mc3_nodes.rds")
```

## Extract Links

```{r}
mc3_links <- as_tibble(mc3_data6$links) %>% 
  distinct() 
```

Save as rds file for future use

```{r}
write_rds(mc3_links, "data/rds/mc3_links.rds")
```

# Visualize Changes in Corporate Structures Over Time

Load rds file

```{r,eval=FALSE}
mc3_links <- readRDS("data/rds/mc3_links.rds")
mc3_nodes <- readRDS("data/rds/mc3_nodes.rds")
```

The plot shows how transaction volume changes over time, which helps identify periods of increased or decreased activity

```{r}
transactions_over_time <- mc3_links %>%
  group_by(start_date) %>%
  summarize(count = n())
```

Drop na values before plotting data

```{r}
transactions_over_time2 <- transactions_over_time %>%
  drop_na()
```

Number of Transactions over Time

::: panel-tabset
## Plot

```{r,echo=FALSE}
ggplot(transactions_over_time2, aes(x = start_date, y = count)) +
  geom_line() +
  labs(title = "Transactions Over Time", x = "Year", y = "Number of Transactions")
```

## Code

```{r,eval=FALSE}
ggplot(transactions_over_time2, aes(x = start_date, y = count)) +
  geom_line() +
  labs(title = "Transactions Over Time", x = "Date", y = "Number of Transactions")
```
:::

::: callout-note
The dataset spans from year 1952 to 2035.

We can see that from the start of the dataset until about year 2000, there were relatively few transactions. There was a small spike after year 2000, proceeded by rapid growth around 2005. Eversince, there has been a general sharp increase in number of transactions, especially during the last 5 years 2030-2035.

We should focus the analysis from year 2005 onwards.
:::

## Identify and Visualize Transactions

### Filter Transactions and Nodes of Interest

By filtering the transactions and nodes, the network graph highlights significant relationships and transactions that stand out.

```{r}
# Filter edges for atypical business transactions
atypical_edges <- mc3_links %>%
  filter(type2 %in% c("Shareholdership", "WorksFor", "BeneficialOwnership"))

# Extract nodes that are part of these transactions
atypical_nodes <- mc3_nodes %>%
  filter(id %in% unique(c(atypical_edges$source, atypical_edges$target)))
```

Drop unnecessary columns, then remove rows with NA and NaN values.

```{r}
#edges
atypical_edges2 <- atypical_edges %>%
  select(-algorithm, -end_date, -type1) %>%
  drop_na() %>%
  mutate_if(is.numeric, ~ replace(., is.nan(.), NA_real_)) %>%
  drop_na()

# nodes
atypical_nodes2 <- atypical_nodes %>%
  select(-type1, -dob, -algorithm, -TradeDescription) %>%
  drop_na() %>%
  mutate_if(is.numeric, ~ replace(., is.nan(.), NA_real_)) %>%
  drop_na()
```

Check number of nodes and edges

```{r}
# Check the number of nodes
num_nodes <- nrow(atypical_nodes2)
num_edges <- nrow(atypical_edges2)

num_nodes
num_edges

```

::: callout-note
It seems the number of nodes (8846) is less than the number of edges (61096), which will cause issues when creating the graph object.

To create a graph object, we need to ensure that all nodes in the edges are present in the nodes data frame.

One way to handle this is to filter out edges where either the source or target node is not present in the nodes data frame.
:::

Filter edges

```{r}
# Filter edges to only include nodes present in the nodes data frame
atypical_edges3 <- atypical_edges2 %>%
  filter(source %in% atypical_nodes2$node_id & target %in% atypical_nodes2$node_id)
```

### Create Graph Object

```{r}
# make a copy of atypical_nodes2 for ease of reference
atypical_nodes3 <- atypical_nodes2

# Create the graph object with filtered edges
atypical_graph <- tbl_graph(nodes = atypical_nodes3, edges = atypical_edges3, directed = FALSE) %>%
  mutate(betweenness_centrality = centrality_betweenness(),
         closeness_centrality = centrality_closeness())
```

### Compute Centrality Measures

```{r}
# Compute betweenness centrality using igraph
betweenness <- igraph::betweenness(as.igraph(atypical_graph))

# Compute closeness centrality using igraph
closeness <- igraph::closeness(as.igraph(atypical_graph))

# Add centrality measures to the graph object
atypical_graph <- atypical_graph %>%
  mutate(betweenness_centrality = betweenness,
         closeness_centrality = closeness)
```

### Further Filtering

```{r}
# Define higher centrality thresholds for more filtering
betweenness_threshold <- quantile(atypical_graph %>% activate(nodes) %>% pull(betweenness_centrality), 0.995, na.rm = TRUE)
closeness_threshold <- quantile(atypical_graph %>% activate(nodes) %>% pull(closeness_centrality), 0.995, na.rm = TRUE)

# Filter nodes based on higher centrality thresholds
filtered_graph <- atypical_graph %>%
  activate(nodes) %>%
  filter(betweenness_centrality >= betweenness_threshold | closeness_centrality >= closeness_threshold) %>%
  activate(edges) %>%
  filter(edge_is_between())
```

## Plot Centrality

::: panel-tabset
## Plot

```{r,echo=FALSE}
# Display the refined network graph
ggraph(filtered_graph, layout = "fr") + 
  geom_edge_link(aes(edge_alpha = 0.8, edge_width = 0.8)) +
  geom_node_point(aes(size = betweenness_centrality, color = closeness_centrality)) +
  scale_color_viridis_c(transform = scales::log10_trans(), na.value = "grey90") +  # Updated
  theme_void() +
  labs(title = "Refined Network Graph of Atypical Business Transactions",
       subtitle = "Nodes colored by closeness centrality and sized by betweenness centrality",
       caption = "Data Source: mc3.json")
```

## Code

```{r,eval=FALSE}
# Display the refined network graph
ggraph(filtered_graph, layout = "fr") + 
  geom_edge_link(aes(edge_alpha = 0.8, edge_width = 0.8)) +
  geom_node_point(aes(size = betweenness_centrality, color = closeness_centrality)) +
  scale_color_viridis_c(transform = scales::log10_trans(), na.value = "grey90") +  # Updated
  theme_void() +
  labs(title = "Refined Network Graph of Atypical Business Transactions",
       subtitle = "Nodes colored by closeness centrality and sized by betweenness centrality",
       caption = "Data Source: mc3.json")
```
:::
