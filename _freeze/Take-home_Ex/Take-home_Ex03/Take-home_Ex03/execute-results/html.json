{
  "hash": "e6a914567a60ebc6e0904fbff8597d5d",
  "result": {
    "markdown": "---\ntitle: \"Take-home Exercise 3 - Vast Challenge 2024\"\nauthor: \"Alicia Loh\"\ndate: \"May 10, 2024\"\ndate-modified: last-modified\nexecute: \n  eval: true\n  echo: true\n  warning: false\n  freeze: true\n---\n\n\n# **The Source**\n\nThe task is taken from the [VAST Challenge 2024](https://vast-challenge.github.io/2024/). Questions from [Mini Case 3: Temporal Analysis](https://vast-challenge.github.io/2024/MC3.html) will be completed.\n\n# Challenge Overview\n\n![](data/Oceanus%20Information/Oceanus%20Location.png){width=\"288\"}\n\n![](data/Oceanus%20Information/Oceanus%20Geography.png){width=\"308\"}\n\nWelcome to Oceanus, an island nation with a healthy market for commercial fishing. Most companies in the region are united in following regulations and implementing sustainable fishing practices. But there are a few companies who are willing to cross ethical lines to increase their catch and their profits. Luckily, FishEye International maintains a watchful eye on fishing data. Their dedicated analysts have been processing data from various sources into a knowledge graph that they call CatchNet: the Oceanus Knowledge Graph.\n\n# **The Task**\n\n![](images/clipboard-587959097.png){width=\"320\"}\n\nMini-challenge 3 concerns visualizing changes in business relationships within the commercial fishing industry. FishEye wants to understand how companies react to the closure of a competitor caught fishing illegally and how these changes affect influence networks. Design visualizations to show these changes over time and identify companies that may benefit from illegal fishing\n\nApply appropriate visual analytics methods to help FishEye, a non-profit organization that focuses on illegal fishing, to better identify bias, track behavior changes, and infer temporal patterns from the knowledge graphs prepared by their data analysts.\n\nThis take home exercise is done in conjunction with the group project. My group members are [Keke](https://isss608keke.netlify.app/) and [Quek You Ting](https://isss608ytquek.netlify.app/).\n\n## Background\n\nThe business community in Oceanus is dynamic with new startups, mergers, acquisitions, and investments. FishEye International closely watches business records to keep tabs on commercial fishing operators. FishEye’s goal is to identify and prevent illegal fishing in the region’s sensitive marine ecosystem. Analysts are working with company records that show ownership, shareholders, transactions, and information about the typical products and services of each entity. FishEye’s analysts have a hybrid automated/manual process to transform the data into CatchNet: the Oceanus Knowledge Graph.\n\nIn the past year, Oceanus’s commercial fishing business community was rocked by the news that SouthSeafood Express Corp was caught fishing illegally. FishEye wants to understand temporal patterns and infer what may be happening in Oceanus’s fishing marketplace because of SouthSeafood Express Corp’s illegal behavior and eventual closure. The competitive nature of Oceanus’s fishing market may cause some businesses to react aggressively to capture SouthSeafood Express Corp’s business while other reactions may come from the awareness that illegal fishing does not go undetected and unpunished.\n\n## Tasks and Questions:\n\nA key element in stopping illegal fishing is holding the people who own nefarious companies accountable. Thus, FishEye is keenly interested in developing visualization tools that work with CatchNet to identify the people who hold influence over business networks. That is especially difficult with varied and changing shareholder and ownership relationships.\n\n1.  FishEye analysts want to better visualize changes in corporate structures over time. Create a visual analytics approach that analysts can use to highlight temporal patterns and changes in corporate structures. Examine the most active people and businesses using visual analytics.\n\n2.  Using your visualizations, find and display examples of typical and atypical business transactions (e.g., mergers, acquisitions, etc.). Can you infer the motivations behind changes in their activity?\n\nNote: the VAST challenge is focused on visual analytics and graphical figures should be included with your response to each question. Please include a reasonable number of figures for each question (no more than about 6) and keep written responses as brief as possible (around 250 words per question). Participants are encouraged to new visual representations rather than relying on traditional or existing approaches.\n\n# Getting Started\n\n## Installing and loading the required libraries\n\nNote: Ensure that the [pacman](https://cran.r-project.org/web/packages/pacman/) package has already been installed.\n\nThe following R packages will be used:\n\n-   tidytext\n\n-   tidyverse\n\n-   readtext\n\n-   quanteda\n\n-   jsonlite\n\n-   igraph\n\n-   tidygraph\n\n-   ggraph\n\n-   visNetwork\n\n-   [clock](https://cran.r-project.org/web/packages/clock/index.html)\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(tidytext, readtext, quanteda, tidyverse, jsonlite, igraph, tidygraph, ggraph, visNetwork, clock, graphlayouts)\n```\n:::\n\n\n## **Importing JSON File**\n\nDirect import of the mc3.json file shows an error message indicating that there's an invalid character in the JSON text, specifically \"NaN\". As \"NaN\" is not recognised as a valid value, preprocessing of the JSON file to replace \"NaN\" is required.\n\nIn the code chunk below, *mc3.json* is first imported, then all instances of \"NaN\" are replaced with \"null\", and the processed file is written into a json file *mc3_fixed.json* for later use.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read the JSON file as text\njson_text <- readLines(\"data/mc3.json\")\n\n# Replace \"NaN\" with \"null\"\njson_text_fixed <- gsub(\"NaN\", \"null\", json_text)\n\n# Write the fixed JSON text back to a file\nwriteLines(json_text_fixed, \"data/mc3_fixed.json\")\n```\n:::\n\n\nImporting preprocessed mc3_fixed.json file\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmc3_data <- fromJSON(\"data/mc3_fixed.json\")\n```\n:::\n\n\nCheck dataframe\n\n-   Opens new tabs within R workspace, not shown in website\n\n-   Example of the view is shown in the screenshot tab below\n\n::: panel-tabset\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nview(mc3_data[[\"nodes\"]])\nview(mc3_data[[\"links\"]])\n```\n:::\n\n\n## Screenshot Example\n\nmc3_data\\[\\[\"nodes'\\]\n\n![](images/clipboard-1212461262.png)\n\n![](images/clipboard-3963926457.png)\n\nmc3_data\\[\\[\"links\"\\]\\]\n\n![](images/clipboard-2580708180.png)\n\n![](images/clipboard-3147037567.png)\n:::\n\nView dataframe\n\n-   Similar info as shown above\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(mc3_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     : Named list()\n $ nodes     :'data.frame':\t60520 obs. of  15 variables:\n  ..$ type             : chr [1:60520] \"Entity.Organization.Company\" \"Entity.Organization.Company\" \"Entity.Organization.Company\" \"Entity.Organization.Company\" ...\n  ..$ country          : chr [1:60520] \"Uziland\" \"Mawalara\" \"Uzifrica\" \"Islavaragon\" ...\n  ..$ ProductServices  : chr [1:60520] \"Unknown\" \"Furniture and home accessories\" \"Food products\" \"Unknown\" ...\n  ..$ PointOfContact   : chr [1:60520] \"Rebecca Lewis\" \"Michael Lopez\" \"Steven Robertson\" \"Anthony Wyatt\" ...\n  ..$ HeadOfOrg        : chr [1:60520] \"Émilie-Susan Benoit\" \"Honoré Lemoine\" \"Jules Labbé\" \"Dr. Víctor Hurtado\" ...\n  ..$ founding_date    : chr [1:60520] \"1954-04-24T00:00:00\" \"2009-06-12T00:00:00\" \"2029-12-15T00:00:00\" \"1972-02-16T00:00:00\" ...\n  ..$ revenue          : num [1:60520] 5995 71767 0 0 4747 ...\n  ..$ TradeDescription : chr [1:60520] \"Unknown\" \"Abbott-Gomez is a leading manufacturer and supplier of high-quality furniture and home accessories, catering to\"| __truncated__ \"Abbott-Harrison is a leading manufacturer of high-quality food products, including baked goods, snacks, and bev\"| __truncated__ \"Unknown\" ...\n  ..$ _last_edited_by  : chr [1:60520] \"Pelagia Alethea Mordoch\" \"Pelagia Alethea Mordoch\" \"Pelagia Alethea Mordoch\" \"Pelagia Alethea Mordoch\" ...\n  ..$ _last_edited_date: chr [1:60520] \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" ...\n  ..$ _date_added      : chr [1:60520] \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" ...\n  ..$ _raw_source      : chr [1:60520] \"Existing Corporate Structure Data\" \"Existing Corporate Structure Data\" \"Existing Corporate Structure Data\" \"Existing Corporate Structure Data\" ...\n  ..$ _algorithm       : chr [1:60520] \"Automatic Import\" \"Automatic Import\" \"Automatic Import\" \"Automatic Import\" ...\n  ..$ id               : chr [1:60520] \"Abbott, Mcbride and Edwards\" \"Abbott-Gomez\" \"Abbott-Harrison\" \"Abbott-Ibarra\" ...\n  ..$ dob              : chr [1:60520] NA NA NA NA ...\n $ links     :'data.frame':\t75817 obs. of  11 variables:\n  ..$ start_date       : chr [1:75817] \"2016-10-29T00:00:00\" \"2035-06-03T00:00:00\" \"2028-11-20T00:00:00\" \"2024-09-04T00:00:00\" ...\n  ..$ type             : chr [1:75817] \"Event.Owns.Shareholdership\" \"Event.Owns.Shareholdership\" \"Event.Owns.Shareholdership\" \"Event.Owns.Shareholdership\" ...\n  ..$ _last_edited_by  : chr [1:75817] \"Pelagia Alethea Mordoch\" \"Niklaus Oberon\" \"Pelagia Alethea Mordoch\" \"Pelagia Alethea Mordoch\" ...\n  ..$ _last_edited_date: chr [1:75817] \"2035-01-01T00:00:00\" \"2035-07-15T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" ...\n  ..$ _date_added      : chr [1:75817] \"2035-01-01T00:00:00\" \"2035-07-15T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" ...\n  ..$ _raw_source      : chr [1:75817] \"Existing Corporate Structure Data\" \"Oceanus Corporations Monthly - Jun '35\" \"Existing Corporate Structure Data\" \"Existing Corporate Structure Data\" ...\n  ..$ _algorithm       : chr [1:75817] \"Automatic Import\" \"Manual Entry\" \"Automatic Import\" \"Automatic Import\" ...\n  ..$ source           : chr [1:75817] \"Avery Inc\" \"Berger-Hayes\" \"Bowers Group\" \"Bowman-Howe\" ...\n  ..$ target           : chr [1:75817] \"Allen, Nichols and Thompson\" \"Jensen, Morris and Downs\" \"Barnett Inc\" \"Bennett Ltd\" ...\n  ..$ key              : int [1:75817] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ end_date         : chr [1:75817] NA NA NA NA ...\n```\n:::\n:::\n\n\n::: callout-note\nmc3_date\\[\\[\"nodes\"\\]\\] dataframe contains 15 columns and 60520 rows.\n\nmc3_date\\[\\[\"links\"\\]\\] dataframe contains 11 columns and 75817 rows.\n:::\n\n::: callout-note\nOn closer inspection of `mc3_data`, we note some issues to be rectified:\n\n1.  Columns containing dates are treated as “Character” data type instead of *date* data type, which is incorrect. Thus, the data type of the following fields need to be changed to “Date”” data type:\n    -   founding_date\n    -   \\_last_edited_date\n    -   \\_date_added\n    -   start_date\n    -   \\_last_edited_date\n    -   \\_date_added\n    -   dob\n2.  Some columns have missing values, which need to be handled appropriately for ease of later analysis.\n3.  Some columns are prefixed with \"\\_\", we remove them to reduce chance of bugs later\n:::\n\n## Missing Values\n\nIdentify the percentage of missing values within the dataset\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to calculate missing value percentages\ncalculate_missing_percentage <- function(df) {\n  total_values <- nrow(df) * ncol(df)\n  missing_values <- sum(is.na(df))\n  missing_percentage <- (missing_values / total_values) * 100\n  return(missing_percentage)\n}\n```\n:::\n\n\n::: panel-tabset\n## Nodes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnodes_missing_percentage <- calculate_missing_percentage(mc3_data[[\"nodes\"]])\nnodes_missing_percentage\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 35.11952\n```\n:::\n\n```{.r .cell-code}\nnodes_missing_by_column <- sapply(mc3_data[[\"nodes\"]], function(x) sum(is.na(x)) / length(x) * 100)\nnodes_missing_by_column\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             type           country   ProductServices    PointOfContact \n          0.00000           0.00000          85.34204          85.38334 \n        HeadOfOrg     founding_date           revenue  TradeDescription \n         85.35691          85.34204          85.36847          85.34204 \n  _last_edited_by _last_edited_date       _date_added       _raw_source \n          0.00000           0.00000           0.00000           0.00000 \n       _algorithm                id               dob \n          0.00000           0.00000          14.65796 \n```\n:::\n:::\n\n\n## Links\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlinks_missing_percentage <- calculate_missing_percentage(mc3_data[[\"links\"]])\nlinks_missing_percentage\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 9.059973\n```\n:::\n\n```{.r .cell-code}\nlinks_missing_by_column <- sapply(mc3_data[[\"links\"]], function(x) sum(is.na(x)) / length(x) * 100)\nlinks_missing_by_column\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       start_date              type   _last_edited_by _last_edited_date \n        0.1187069         0.0000000         0.0000000         0.0000000 \n      _date_added       _raw_source        _algorithm            source \n        0.0000000         0.0000000         0.0000000         0.0000000 \n           target               key          end_date \n        0.0000000         0.0000000        99.5410000 \n```\n:::\n:::\n\n:::\n\n::: callout-note\nNodes: Overall, there are 35.12% missing values. While most columns have no missing values, the majority of those with missing data pertain to optional attributes:\n\n-   ProductServices (Optional) - 85.34%\n\n-   PointOfContact (Optional)- 85.38%\n\n-   HeadofOrg (Optional) - 85.36%\n\n-   founding_date - 85.34%\n\n-   revenue (Optional) - 85.37%\n\n-   TradeDescription (Optional) - 85.34%\n\n-   dob - 14.66%\n\nLinks: Overall, there are 9.06% missing values. Most of the columns do not contain missing values, except for:\n\n-   start_date - 0.12%\n\n-   end_date (Optional) - 99.54%\n\nIn addition, according to the *VAST2024 - MC3 Data Description* file, all empty values in the revenue column are supposed to have been set to 0. However, there are still some values with \"NA\".\n:::\n\n## Setting empty values in *`revenue`* to 0\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a copy of mc3_data\nmc3_data2 <- mc3_data\n\n# Set empty values in revenue to 0 and save it to the new list\nmc3_data2$nodes$revenue <- ifelse(is.na(mc3_data2$nodes$revenue) | mc3_data2$nodes$revenue == \"\", 0, mc3_data2$nodes$revenue)\n```\n:::\n\n\nVerify changes\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ensure no more missing values in revenue column\nsum(is.na(mc3_data2$nodes$revenue))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n\n## Rename Columns\n\nRemove prefix \"\\_\" from columns to reduce chance of issues later\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to remove leading underscores from column names\nremove_leading_underscores <- function(df) {\n  colnames(df) <- gsub(\"^_\", \"\", colnames(df))\n  return(df)\n}\n\n# Create a copy of mc3_data2 and name it mc3_data3\nmc3_data3 <- mc3_data2\n\n# Apply the function to the nodes and links data frames in mc3_data3\nmc3_data3$nodes <- remove_leading_underscores(mc3_data3$nodes)\nmc3_data3$links <- remove_leading_underscores(mc3_data3$links)\n```\n:::\n\n\nVerify changes\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolnames(mc3_data3$nodes)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"type\"             \"country\"          \"ProductServices\"  \"PointOfContact\"  \n [5] \"HeadOfOrg\"        \"founding_date\"    \"revenue\"          \"TradeDescription\"\n [9] \"last_edited_by\"   \"last_edited_date\" \"date_added\"       \"raw_source\"      \n[13] \"algorithm\"        \"id\"               \"dob\"             \n```\n:::\n\n```{.r .cell-code}\ncolnames(mc3_data3$links)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"start_date\"       \"type\"             \"last_edited_by\"   \"last_edited_date\"\n [5] \"date_added\"       \"raw_source\"       \"algorithm\"        \"source\"          \n [9] \"target\"           \"key\"              \"end_date\"        \n```\n:::\n:::\n\n\n## Standardising Date Time Formats\n\nIn preparation for temporal analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a copy of mc3_data3 and name it mc3_data4\nmc3_data4 <- mc3_data3\n\n# Convert date columns to Date-Time type\nmc3_data4$nodes <- mc3_data4$nodes %>%\n  mutate(\n    founding_date = ymd_hms(founding_date),\n    last_edited_date = ymd_hms(last_edited_date),\n    date_added = ymd_hms(date_added),\n    dob = ymd_hms(dob)\n  )\n\nmc3_data4$links <- mc3_data4$links %>%\n  mutate(\n    start_date = ymd_hms(start_date),\n    last_edited_date = ymd_hms(last_edited_date),\n    date_added = ymd_hms(date_added),\n    end_date = ymd_hms(end_date)\n  )\n```\n:::\n\n\n::: callout-note\nThe `ymd_hms` function is designed to work with character vectors and will return `NA` for any existing `NA` values. This means that any `NA` value in the original columns will remain `NA` after the conversion.\n:::\n\nVerify changes\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# View the first few rows of the date columns in nodes\nhead(mc3_data4$nodes %>% select(founding_date, last_edited_date, date_added, dob))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  founding_date last_edited_date date_added  dob\n1    1954-04-24       2035-01-01 2035-01-01 <NA>\n2    2009-06-12       2035-01-01 2035-01-01 <NA>\n3    2029-12-15       2035-01-01 2035-01-01 <NA>\n4    1972-02-16       2035-01-01 2035-01-01 <NA>\n5    1954-04-06       2035-01-01 2035-01-01 <NA>\n6    2031-09-30       2035-01-01 2035-01-01 <NA>\n```\n:::\n\n```{.r .cell-code}\n# View the first few rows of the date columns in links\nhead(mc3_data4$links %>% select(start_date))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  start_date\n1 2016-10-29\n2 2035-06-03\n3 2028-11-20\n4 2024-09-04\n5 2034-11-12\n6 2007-04-06\n```\n:::\n\n```{.r .cell-code}\n# Summary of date columns in nodes\nsummary(mc3_data4$nodes %>% select(founding_date, last_edited_date, date_added, dob))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n founding_date                     last_edited_date               \n Min.   :1945-01-01 00:00:00.000   Min.   :2035-01-01 00:00:00.0  \n 1st Qu.:1968-01-11 00:00:00.000   1st Qu.:2035-01-01 00:00:00.0  \n Median :1991-07-03 00:00:00.000   Median :2035-01-01 00:00:00.0  \n Mean   :1991-04-22 15:54:58.072   Mean   :2035-01-02 10:34:13.4  \n 3rd Qu.:2014-09-04 12:00:00.000   3rd Qu.:2035-01-01 00:00:00.0  \n Max.   :2035-12-29 00:00:00.000   Max.   :2036-01-15 00:00:00.0  \n NA's   :51649                                                    \n   date_added                         dob                         \n Min.   :2035-01-01 00:00:00.0   Min.   :1970-01-02 00:00:00.000  \n 1st Qu.:2035-01-01 00:00:00.0   1st Qu.:1978-01-30 00:00:00.000  \n Median :2035-01-01 00:00:00.0   Median :1986-02-06 00:00:00.000  \n Mean   :2035-01-02 10:28:32.2   Mean   :1987-05-23 22:21:33.182  \n 3rd Qu.:2035-01-01 00:00:00.0   3rd Qu.:1995-05-13 00:00:00.000  \n Max.   :2036-01-15 00:00:00.0   Max.   :2017-03-20 00:00:00.000  \n                                 NA's   :9047                     \n```\n:::\n\n```{.r .cell-code}\n# Summary of date columns in links\nsummary(mc3_data4$links %>% select(start_date))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   start_date                    \n Min.   :1952-05-31 00:00:00.00  \n 1st Qu.:2015-08-18 00:00:00.00  \n Median :2024-03-22 00:00:00.00  \n Mean   :2022-11-23 10:50:43.11  \n 3rd Qu.:2030-12-13 00:00:00.00  \n Max.   :2035-12-29 00:00:00.00  \n NA's   :14720                   \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nview(mc3_data4[[\"nodes\"]])\nview(mc3_data4[[\"links\"]])\n```\n:::\n\n\n## Split Words\n\nThe steps below will be used to split text in type column of **nodes** into two columns: namely type1 and type2.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Make a copy of mc3_data4\nmc3_data5 <- mc3_data4\n\n# Split the type column into two columns, handling the special case\nmc3_data5$nodes <- mc3_data5$nodes %>%\n  mutate(\n    type1 = sub(\"(.*?\\\\..*?)(\\\\.[^.]+)?$\", \"\\\\1\", type),\n    type2 = ifelse(grepl(\"\\\\.\", type), sub(\".*\\\\.\", \"\", type), \"Organization\")\n  )\n\n# remove the original 'type' column\nmc3_data5$nodes <- mc3_data5$nodes %>%\n  select(-type)\n```\n:::\n\n\nThe steps below will be used to split text in type column of **links** into two columns: namely type1 and type2.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Make a copy of mc3_data4\nmc3_data6 <- mc3_data5\n\n# Split the type column into two columns, handling the special case\nmc3_data6$links <- mc3_data6$links %>%\n  mutate(\n    type1 = sub(\"(.*?\\\\..*?)(\\\\.[^.]+)?$\", \"\\\\1\", type),\n    type2 = ifelse(grepl(\"\\\\.\", type), sub(\".*\\\\.\", \"\", type), \"\")\n  )\n\n# remove the original 'type' column\nmc3_data6$links <- mc3_data6$links %>%\n  select(-type)\n```\n:::\n\n\nVerify changes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nview(mc3_data6[[\"nodes\"]])\nview(mc3_data6[[\"links\"]])\n```\n:::\n\n\n## Extract Nodes\n\nFor Question 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#keep only necessary columns\nmc3_nodes_1 <- as_tibble(mc3_data6$nodes) %>%\n  select (-TradeDescription,\n          -last_edited_by,\n          -last_edited_date,\n          -algorithm,\n          -dob,\n          -type1,\n          -founding_date)\n```\n:::\n\n\nFor Question 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmc3_nodes_2 <- as_tibble(mc3_data6$nodes) %>%\n  mutate(country = as.character(country), \n         id = as.character(id), \n         ProductServices = as.character(ProductServices), \n         revenue = as.numeric(as.character(revenue)), \n         type2 = as.character(type2)) %>%\n  select(id, country, type2, revenue, ProductServices)\n```\n:::\n\n\nSave as rds file for future use\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(mc3_nodes_1, \"data/rds/mc3_nodes_1.rds\")\nwrite_rds(mc3_nodes_2, \"data/rds/mc3_nodes_2.rds\")\n```\n:::\n\n\n## Extract Links\n\nFor Question 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmc3_links_1 <- as_tibble(mc3_data6$links) %>%\n  select (-last_edited_by,\n          -last_edited_date,\n          -date_added,\n          -key,\n          -algorithm,\n          -type1,\n          -end_date)\n```\n:::\n\n\nFor Question 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmc3_links_2 <- as_tibble(mc3_data6$links) %>% \n  distinct() %>%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type2 = as.character(type2)) %>%\n  group_by(source, target, type2) %>%\n  summarise(weights = n()) %>%\n  filter(source != target) %>%\n  ungroup()\n```\n:::\n\n\nSave as rds file for future use\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(mc3_links_1, \"data/rds/mc3_links_1.rds\")\nwrite_rds(mc3_links_2, \"data/rds/mc3_links_2.rds\")\n```\n:::\n\n\n# Changes in Corporate Structures Over Time\n\nLoad rds file\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmc3_links_1 <- readRDS(\"data/rds/mc3_links_1.rds\")\nmc3_nodes_1 <- readRDS(\"data/rds/mc3_nodes_1.rds\")\n```\n:::\n\n\nThe plot shows how transaction volume changes over time, which helps identify periods of increased or decreased activity\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntransactions_over_time <- mc3_links_1 %>%\n  group_by(start_date) %>%\n  summarize(count = n()) %>%\n  drop_na()\n```\n:::\n\n\n## Number of Transactions over Time\n\n::: panel-tabset\n## Plot\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(transactions_over_time, aes(x = start_date, y = count)) +\n  geom_line() +\n  labs(title = \"Transactions Over Time\", x = \"Date\", y = \"Number of Transactions\")\n```\n:::\n\n:::\n\n::: callout-note\nThe dataset spans from year 1952 to 2035.\n\nWe can see that from the start of the dataset until about year 2000, there were relatively few transactions. There was a small spike after year 2000, proceeded by exponential growth around 2005. However, there was a dip in transactions in 2035.\n\nThe dip could be due to effects after SouthSeafood Express Corp was caught for illegal behaviour and eventually closed.\n\nAnalysis should focus on transactions from year 2005 onwards. Data analysed should also be aggregated by year.\n:::\n\n### Filter data\n\nFilter data to only keep transactions from 2000 (5 years before 2005) to 2035 (end of dataset). We keep some data that occurs before the start of our period of interest to capture any recent changes to entities.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter the data frames to keep only data from the year 2000 and onwards\nmc3_links_1_filtered <- mc3_links_1 %>%\n  filter(start_date >= as.Date(\"2000-01-01\"))\n```\n:::\n\n\n### Aggregate Data by Year\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract year for aggregation\nmc3_links_1_filtered2 <- mc3_links_1_filtered %>%\n  mutate(transaction_year = year(start_date))\n\n# Calculate the number of transactions per year\nyearly_txns <- mc3_links_1_filtered2 %>%\n  group_by(transaction_year) %>%\n  summarise(num_transactions = n())\n```\n:::\n\n\n::: panel-tabset\n## Plot\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot the number of transactions per year\nggplot(yearly_txns, aes(x = transaction_year, y = num_transactions)) +\n  geom_line(color = \"blue\") +\n  labs(title = \"Number of Transactions Per Year\",\n       x = \"Year\",\n       y = \"Number of Transactions\") +\n  theme_minimal()\n```\n:::\n\n:::\n\n::: callout-note\nIt is now clearer that the rapid growth in transactions started around 2005, before reaching its peak at 2034 and sharply dropping in 2035, likely due to after effects of the SouthSeafood Express Corp incident.\n:::\n\n## Number of Active Companies Per Year\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract year for aggregation\nmc3_nodes_1_filtered <- mc3_nodes_1 %>%\n  mutate(active_year = floor_date(date_added, \"year\"))\n\n# Calculate the number of active companies per month\nactive_companies <- mc3_nodes_1_filtered %>%\n  group_by(active_year) %>%\n  summarise(num_active_companies = n())\n```\n:::\n\n\nPlot graph\n\n::: panel-tabset\n## Plot\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot the number of active companies over time\nggplot(active_companies, aes(x = active_year, y = num_active_companies)) +\n  geom_line(color = \"darkgreen\") +\n  labs(title = \"Number of Active Companies Over Time\",\n       x = \"Date\",\n       y = \"Number of Active Companies\") +\n  theme_minimal()\n```\n:::\n\n:::\n\n::: callout-note\nIt can be noted that while the number of transactions showed an increasing trend, the number of active companies are showing a decreasing trend. This suggests that some major players are involved in an increasing number of transactions.\n:::\n\n## Centrality Measures Over Time\n\n### Find unique IDs\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Duplicate mc3_nodes_1_filtered\nmc3_nodes_1_filtered2 <- mc3_nodes_1_filtered\n\n# Extract unique IDs from edge source and target\nid1 <- mc3_links_1_filtered2 %>%\n  select(source) %>%\n  distinct() %>%\n  rename(id = source)\n\nid2 <- mc3_links_1_filtered2 %>%\n  select(target) %>%\n  distinct() %>%\n  rename(id = target)\n\n# Combine unique IDs and remove duplicates\nmc3_nodes_1_filtered2 <- rbind(id1, id2) %>%\n  distinct() %>%\n  # Join with node information\n  left_join(mc3_nodes_1_filtered2, by = \"id\") %>%\n  # Add an indicator for unmatched IDs\n  mutate(unmatched = ifelse(is.na(id), \"drop\", \"\"))\n\n# Drop unmatched nodes\nmc3_nodes_1_filtered3 <- mc3_nodes_1_filtered2 %>%\n  filter(unmatched != \"drop\")\n```\n:::\n\n\n### Create Graph Object\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmc3_graph <- tbl_graph(nodes = mc3_nodes_1_filtered3, edges = mc3_links_1_filtered2, directed = TRUE) %>%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness())\n  theme_graph()\n```\n:::\n\n\nPlot Graph\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Assuming you have a function to calculate centrality for each year\ncalculate_centrality_over_time <- function(nodes, edges, time_unit = \"year\") {\n  edges <- edges %>%\n    mutate(period = year(start_date))\n  \n  centrality_results <- edges %>%\n    group_by(period) %>%\n    do({\n      current_edges <- .\n      current_nodes <- nodes %>% filter(id %in% unique(c(current_edges$source, current_edges$target)))\n      graph <- tbl_graph(nodes = current_nodes, edges = current_edges, directed = TRUE)\n      graph %>%\n        mutate(betweenness = centrality_betweenness()) %>%\n        as_tibble() %>%\n        summarise(mean_betweenness = mean(betweenness, na.rm = TRUE))\n    }) %>%\n    ungroup()\n  \n  return(centrality_results)\n}\n\n# Calculate centrality measures over time\ncentrality_over_time <- calculate_centrality_over_time(mc3_nodes_1_filtered2, mc3_links_1_filtered3)\n\n# Plot centrality measures over time\nggplot(centrality_over_time, aes(x = period, y = mean_betweenness)) +\n  geom_line(color = \"red\") +\n  labs(title = \"Average Betweenness Centrality Per Year\",\n       x = \"Year\",\n       y = \"Mean Betweenness Centrality\") +\n  theme_minimal()\n```\n:::\n\n\n::: callout-note\nThe nodes represent entities e.g. Logistics Companies, Fishing Companies, and the edges represent relationships between them e.g. Shareholdership. Overall, this graph can help identify central or influential transactions/entities within the network, as well as potential outliers or anomalies based on their position and connectivity patterns.\n:::\n\n### Identify Top Nodes\n\nFilter out the top nodes,\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Identify top nodes by betweenness centrality\ntop_nodes <- mc3_graph %>% \n  as_tibble() %>% \n  filter(betweenness_centrality >= 3000000)\n```\n:::\n",
    "supporting": [
      "Take-home_Ex03_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}