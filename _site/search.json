[
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 3 - Vast Challenge 2024",
    "section": "",
    "text": "The task is taken from the VAST Challenge 2024. Questions from Mini Case 3: Temporal Analysis will be completed."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#background",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#background",
    "title": "Take-home Exercise 3 - Vast Challenge 2024",
    "section": "Background",
    "text": "Background\nThe business community in Oceanus is dynamic with new startups, mergers, acquisitions, and investments. FishEye International closely watches business records to keep tabs on commercial fishing operators. FishEye’s goal is to identify and prevent illegal fishing in the region’s sensitive marine ecosystem. Analysts are working with company records that show ownership, shareholders, transactions, and information about the typical products and services of each entity. FishEye’s analysts have a hybrid automated/manual process to transform the data into CatchNet: the Oceanus Knowledge Graph.\nIn the past year, Oceanus’s commercial fishing business community was rocked by the news that SouthSeafood Express Corp was caught fishing illegally. FishEye wants to understand temporal patterns and infer what may be happening in Oceanus’s fishing marketplace because of SouthSeafood Express Corp’s illegal behavior and eventual closure. The competitive nature of Oceanus’s fishing market may cause some businesses to react aggressively to capture SouthSeafood Express Corp’s business while other reactions may come from the awareness that illegal fishing does not go undetected and unpunished."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#tasks-and-questions",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#tasks-and-questions",
    "title": "Take-home Exercise 3 - Vast Challenge 2024",
    "section": "Tasks and Questions:",
    "text": "Tasks and Questions:\nA key element in stopping illegal fishing is holding the people who own nefarious companies accountable. Thus, FishEye is keenly interested in developing visualization tools that work with CatchNet to identify the people who hold influence over business networks. That is especially difficult with varied and changing shareholder and ownership relationships.\n\nFishEye analysts want to better visualize changes in corporate structures over time. Create a visual analytics approach that analysts can use to highlight temporal patterns and changes in corporate structures. Examine the most active people and businesses using visual analytics.\n\nNote: the VAST challenge is focused on visual analytics and graphical figures should be included with your response to each question. Please include a reasonable number of figures for each question (no more than about 6) and keep written responses as brief as possible (around 250 words per question). Participants are encouraged to new visual representations rather than relying on traditional or existing approaches."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#installing-and-loading-the-required-libraries",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#installing-and-loading-the-required-libraries",
    "title": "Take-home Exercise 3 - Vast Challenge 2024",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nNote: Ensure that the pacman package has already been installed.\nThe following R packages will be used:\n\ntidytext\ntidyverse\nreadtext\nquanteda\njsonlite\nigraph\ntidygraph\nggraph\nvisNetwork\nclock\ngraphlayouts\nplotly\nggiraph\n\n\npacman::p_load(tidytext, readtext, quanteda, tidyverse, jsonlite, igraph, tidygraph, ggraph, visNetwork, clock, graphlayouts,plotly,ggiraph)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-json-file",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-json-file",
    "title": "Take-home Exercise 3 - Vast Challenge 2024",
    "section": "Importing JSON File",
    "text": "Importing JSON File\nDirect import of the mc3.json file shows an error message indicating that there’s an invalid character in the JSON text, specifically “NaN”. As “NaN” is not recognised as a valid value, preprocessing of the JSON file to replace “NaN” is required.\nIn the code chunk below, mc3.json is first imported, then all instances of “NaN” are replaced with “null”, and the processed file is written into a json file mc3_fixed.json for later use.\n\n# Read the JSON file as text\njson_text &lt;- readLines(\"data/mc3.json\")\n\n# Replace \"NaN\" with \"null\"\njson_text_fixed &lt;- gsub(\"NaN\", \"null\", json_text)\n\n# Write the fixed JSON text back to a file\nwriteLines(json_text_fixed, \"data/mc3_fixed.json\")\n\nImporting preprocessed mc3_fixed.json file\n\nmc3_data &lt;- fromJSON(\"data/mc3_fixed.json\")\n\nCheck dataframe\n\nOpens new tabs within R workspace, not shown in website\nExample of the view is shown in the screenshot tab below\n\n\nCodeScreenshot Example\n\n\n\nview(mc3_data[[\"nodes\"]])\nview(mc3_data[[\"links\"]])\n\n\n\nmc3_data[[“nodes’]\n\n\nmc3_data[[“links”]]\n\n\n\n\n\nView dataframe\n\nSimilar info as shown above\n\n\nglimpse(mc3_data)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     : Named list()\n $ nodes     :'data.frame': 60520 obs. of  15 variables:\n  ..$ type             : chr [1:60520] \"Entity.Organization.Company\" \"Entity.Organization.Company\" \"Entity.Organization.Company\" \"Entity.Organization.Company\" ...\n  ..$ country          : chr [1:60520] \"Uziland\" \"Mawalara\" \"Uzifrica\" \"Islavaragon\" ...\n  ..$ ProductServices  : chr [1:60520] \"Unknown\" \"Furniture and home accessories\" \"Food products\" \"Unknown\" ...\n  ..$ PointOfContact   : chr [1:60520] \"Rebecca Lewis\" \"Michael Lopez\" \"Steven Robertson\" \"Anthony Wyatt\" ...\n  ..$ HeadOfOrg        : chr [1:60520] \"Émilie-Susan Benoit\" \"Honoré Lemoine\" \"Jules Labbé\" \"Dr. Víctor Hurtado\" ...\n  ..$ founding_date    : chr [1:60520] \"1954-04-24T00:00:00\" \"2009-06-12T00:00:00\" \"2029-12-15T00:00:00\" \"1972-02-16T00:00:00\" ...\n  ..$ revenue          : num [1:60520] 5995 71767 0 0 4747 ...\n  ..$ TradeDescription : chr [1:60520] \"Unknown\" \"Abbott-Gomez is a leading manufacturer and supplier of high-quality furniture and home accessories, catering to\"| __truncated__ \"Abbott-Harrison is a leading manufacturer of high-quality food products, including baked goods, snacks, and bev\"| __truncated__ \"Unknown\" ...\n  ..$ _last_edited_by  : chr [1:60520] \"Pelagia Alethea Mordoch\" \"Pelagia Alethea Mordoch\" \"Pelagia Alethea Mordoch\" \"Pelagia Alethea Mordoch\" ...\n  ..$ _last_edited_date: chr [1:60520] \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" ...\n  ..$ _date_added      : chr [1:60520] \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" ...\n  ..$ _raw_source      : chr [1:60520] \"Existing Corporate Structure Data\" \"Existing Corporate Structure Data\" \"Existing Corporate Structure Data\" \"Existing Corporate Structure Data\" ...\n  ..$ _algorithm       : chr [1:60520] \"Automatic Import\" \"Automatic Import\" \"Automatic Import\" \"Automatic Import\" ...\n  ..$ id               : chr [1:60520] \"Abbott, Mcbride and Edwards\" \"Abbott-Gomez\" \"Abbott-Harrison\" \"Abbott-Ibarra\" ...\n  ..$ dob              : chr [1:60520] NA NA NA NA ...\n $ links     :'data.frame': 75817 obs. of  11 variables:\n  ..$ start_date       : chr [1:75817] \"2016-10-29T00:00:00\" \"2035-06-03T00:00:00\" \"2028-11-20T00:00:00\" \"2024-09-04T00:00:00\" ...\n  ..$ type             : chr [1:75817] \"Event.Owns.Shareholdership\" \"Event.Owns.Shareholdership\" \"Event.Owns.Shareholdership\" \"Event.Owns.Shareholdership\" ...\n  ..$ _last_edited_by  : chr [1:75817] \"Pelagia Alethea Mordoch\" \"Niklaus Oberon\" \"Pelagia Alethea Mordoch\" \"Pelagia Alethea Mordoch\" ...\n  ..$ _last_edited_date: chr [1:75817] \"2035-01-01T00:00:00\" \"2035-07-15T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" ...\n  ..$ _date_added      : chr [1:75817] \"2035-01-01T00:00:00\" \"2035-07-15T00:00:00\" \"2035-01-01T00:00:00\" \"2035-01-01T00:00:00\" ...\n  ..$ _raw_source      : chr [1:75817] \"Existing Corporate Structure Data\" \"Oceanus Corporations Monthly - Jun '35\" \"Existing Corporate Structure Data\" \"Existing Corporate Structure Data\" ...\n  ..$ _algorithm       : chr [1:75817] \"Automatic Import\" \"Manual Entry\" \"Automatic Import\" \"Automatic Import\" ...\n  ..$ source           : chr [1:75817] \"Avery Inc\" \"Berger-Hayes\" \"Bowers Group\" \"Bowman-Howe\" ...\n  ..$ target           : chr [1:75817] \"Allen, Nichols and Thompson\" \"Jensen, Morris and Downs\" \"Barnett Inc\" \"Bennett Ltd\" ...\n  ..$ key              : int [1:75817] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ end_date         : chr [1:75817] NA NA NA NA ...\n\n\n\n\n\n\n\n\nNote\n\n\n\nmc3_date[[“nodes”]] dataframe contains 15 columns and 60520 rows.\nmc3_date[[“links”]] dataframe contains 11 columns and 75817 rows.\n\n\n\n\n\n\n\n\nNote\n\n\n\nOn closer inspection of mc3_data, we note some issues to be rectified:\n\nColumns containing dates are treated as “Character” data type instead of date data type, which is incorrect. Thus, the data type of the following fields need to be changed to “Date”” data type:\n\nfounding_date\n_last_edited_date\n_date_added\nstart_date\n_last_edited_date\n_date_added\ndob\n\nSome columns have missing values, which need to be handled appropriately for ease of later analysis.\nSome columns are prefixed with “_”, we remove them to reduce chance of bugs later"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#missing-values",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#missing-values",
    "title": "Take-home Exercise 3 - Vast Challenge 2024",
    "section": "Missing Values",
    "text": "Missing Values\nIdentify the percentage of missing values within the dataset\n\n# Function to calculate missing value percentages\ncalculate_missing_percentage &lt;- function(df) {\n  total_values &lt;- nrow(df) * ncol(df)\n  missing_values &lt;- sum(is.na(df))\n  missing_percentage &lt;- (missing_values / total_values) * 100\n  return(missing_percentage)\n}\n\n\nNodesLinks\n\n\n\nnodes_missing_percentage &lt;- calculate_missing_percentage(mc3_data[[\"nodes\"]])\nnodes_missing_percentage\n\n[1] 35.11952\n\nnodes_missing_by_column &lt;- sapply(mc3_data[[\"nodes\"]], function(x) sum(is.na(x)) / length(x) * 100)\nnodes_missing_by_column\n\n             type           country   ProductServices    PointOfContact \n          0.00000           0.00000          85.34204          85.38334 \n        HeadOfOrg     founding_date           revenue  TradeDescription \n         85.35691          85.34204          85.36847          85.34204 \n  _last_edited_by _last_edited_date       _date_added       _raw_source \n          0.00000           0.00000           0.00000           0.00000 \n       _algorithm                id               dob \n          0.00000           0.00000          14.65796 \n\n\n\n\n\nlinks_missing_percentage &lt;- calculate_missing_percentage(mc3_data[[\"links\"]])\nlinks_missing_percentage\n\n[1] 9.059973\n\nlinks_missing_by_column &lt;- sapply(mc3_data[[\"links\"]], function(x) sum(is.na(x)) / length(x) * 100)\nlinks_missing_by_column\n\n       start_date              type   _last_edited_by _last_edited_date \n        0.1187069         0.0000000         0.0000000         0.0000000 \n      _date_added       _raw_source        _algorithm            source \n        0.0000000         0.0000000         0.0000000         0.0000000 \n           target               key          end_date \n        0.0000000         0.0000000        99.5410000 \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNodes: Overall, there are 35.12% missing values. While most columns have no missing values, the majority of those with missing data pertain to optional attributes:\n\nProductServices (Optional) - 85.34%\nPointOfContact (Optional)- 85.38%\nHeadofOrg (Optional) - 85.36%\nfounding_date - 85.34%\nrevenue (Optional) - 85.37%\nTradeDescription (Optional) - 85.34%\ndob - 14.66%\n\nLinks: Overall, there are 9.06% missing values. Most of the columns do not contain missing values, except for:\n\nstart_date - 0.12%\nend_date (Optional) - 99.54%\n\nIn addition, according to the VAST2024 - MC3 Data Description file, all empty values in the revenue column are supposed to have been set to 0. However, there are still some values with “NA”."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#setting-empty-values-in-revenue-to-0",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#setting-empty-values-in-revenue-to-0",
    "title": "Take-home Exercise 3 - Vast Challenge 2024",
    "section": "Setting empty values in revenue to 0",
    "text": "Setting empty values in revenue to 0\nSet NA values to 0 to aid analysis\n\n# Create a copy of mc3_data\nmc3_data2 &lt;- mc3_data\n\n# Set empty values in revenue to 0 and save it to the new list\nmc3_data2$nodes$revenue &lt;- ifelse(is.na(mc3_data2$nodes$revenue) | mc3_data2$nodes$revenue == \"\", 0, mc3_data2$nodes$revenue)\n\nVerify changes\n\n# ensure no more missing values in revenue column\nsum(is.na(mc3_data2$nodes$revenue))\n\n[1] 0"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#rename-columns",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#rename-columns",
    "title": "Take-home Exercise 3 - Vast Challenge 2024",
    "section": "Rename Columns",
    "text": "Rename Columns\nRemove prefix “_” from columns to reduce chance of issues later\n\n# Function to remove leading underscores from column names\nremove_leading_underscores &lt;- function(df) {\n  colnames(df) &lt;- gsub(\"^_\", \"\", colnames(df))\n  return(df)\n}\n\n# Create a copy of mc3_data2 and name it mc3_data3\nmc3_data3 &lt;- mc3_data2\n\n# Apply the function to the nodes and links data frames in mc3_data3\nmc3_data3$nodes &lt;- remove_leading_underscores(mc3_data3$nodes)\nmc3_data3$links &lt;- remove_leading_underscores(mc3_data3$links)\n\nVerify changes\n\ncolnames(mc3_data3$nodes)\n\n [1] \"type\"             \"country\"          \"ProductServices\"  \"PointOfContact\"  \n [5] \"HeadOfOrg\"        \"founding_date\"    \"revenue\"          \"TradeDescription\"\n [9] \"last_edited_by\"   \"last_edited_date\" \"date_added\"       \"raw_source\"      \n[13] \"algorithm\"        \"id\"               \"dob\"             \n\ncolnames(mc3_data3$links)\n\n [1] \"start_date\"       \"type\"             \"last_edited_by\"   \"last_edited_date\"\n [5] \"date_added\"       \"raw_source\"       \"algorithm\"        \"source\"          \n [9] \"target\"           \"key\"              \"end_date\""
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#standardising-date-time-formats",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#standardising-date-time-formats",
    "title": "Take-home Exercise 3 - Vast Challenge 2024",
    "section": "Standardising Date Time Formats",
    "text": "Standardising Date Time Formats\nIn preparation for temporal analysis\n\n# Create a copy of mc3_data3 and name it mc3_data4\nmc3_data4 &lt;- mc3_data3\n\n# Convert date columns to Date-Time type\nmc3_data4$nodes &lt;- mc3_data4$nodes %&gt;%\n  mutate(\n    founding_date = ymd_hms(founding_date),\n    last_edited_date = ymd_hms(last_edited_date),\n    date_added = ymd_hms(date_added),\n    dob = ymd_hms(dob)\n  )\n\nmc3_data4$links &lt;- mc3_data4$links %&gt;%\n  mutate(\n    start_date = ymd_hms(start_date),\n    last_edited_date = ymd_hms(last_edited_date),\n    date_added = ymd_hms(date_added),\n    end_date = ymd_hms(end_date)\n  )\n\n\n\n\n\n\n\nNote\n\n\n\nThe ymd_hms function is designed to work with character vectors and will return NA for any existing NA values. This means that any NA value in the original columns will remain NA after the conversion.\n\n\nVerify changes\n\n# View the first few rows of the date columns in nodes\nhead(mc3_data4$nodes %&gt;% select(founding_date, last_edited_date, date_added, dob))\n\n  founding_date last_edited_date date_added  dob\n1    1954-04-24       2035-01-01 2035-01-01 &lt;NA&gt;\n2    2009-06-12       2035-01-01 2035-01-01 &lt;NA&gt;\n3    2029-12-15       2035-01-01 2035-01-01 &lt;NA&gt;\n4    1972-02-16       2035-01-01 2035-01-01 &lt;NA&gt;\n5    1954-04-06       2035-01-01 2035-01-01 &lt;NA&gt;\n6    2031-09-30       2035-01-01 2035-01-01 &lt;NA&gt;\n\n# View the first few rows of the date columns in links\nhead(mc3_data4$links %&gt;% select(start_date))\n\n  start_date\n1 2016-10-29\n2 2035-06-03\n3 2028-11-20\n4 2024-09-04\n5 2034-11-12\n6 2007-04-06\n\n# Summary of date columns in nodes\nsummary(mc3_data4$nodes %&gt;% select(founding_date, last_edited_date, date_added, dob))\n\n founding_date                     last_edited_date               \n Min.   :1945-01-01 00:00:00.000   Min.   :2035-01-01 00:00:00.0  \n 1st Qu.:1968-01-11 00:00:00.000   1st Qu.:2035-01-01 00:00:00.0  \n Median :1991-07-03 00:00:00.000   Median :2035-01-01 00:00:00.0  \n Mean   :1991-04-22 15:54:58.072   Mean   :2035-01-02 10:34:13.4  \n 3rd Qu.:2014-09-04 12:00:00.000   3rd Qu.:2035-01-01 00:00:00.0  \n Max.   :2035-12-29 00:00:00.000   Max.   :2036-01-15 00:00:00.0  \n NA's   :51649                                                    \n   date_added                         dob                         \n Min.   :2035-01-01 00:00:00.0   Min.   :1970-01-02 00:00:00.000  \n 1st Qu.:2035-01-01 00:00:00.0   1st Qu.:1978-01-30 00:00:00.000  \n Median :2035-01-01 00:00:00.0   Median :1986-02-06 00:00:00.000  \n Mean   :2035-01-02 10:28:32.2   Mean   :1987-05-23 22:21:33.182  \n 3rd Qu.:2035-01-01 00:00:00.0   3rd Qu.:1995-05-13 00:00:00.000  \n Max.   :2036-01-15 00:00:00.0   Max.   :2017-03-20 00:00:00.000  \n                                 NA's   :9047                     \n\n# Summary of date columns in links\nsummary(mc3_data4$links %&gt;% select(start_date))\n\n   start_date                    \n Min.   :1952-05-31 00:00:00.00  \n 1st Qu.:2015-08-18 00:00:00.00  \n Median :2024-03-22 00:00:00.00  \n Mean   :2022-11-23 10:50:43.11  \n 3rd Qu.:2030-12-13 00:00:00.00  \n Max.   :2035-12-29 00:00:00.00  \n NA's   :14720                   \n\n# Check the types of the date columns in nodes\nstr(mc3_data4$nodes %&gt;% select(founding_date, last_edited_date, date_added, dob))\n\n'data.frame':   60520 obs. of  4 variables:\n $ founding_date   : POSIXct, format: \"1954-04-24\" \"2009-06-12\" ...\n $ last_edited_date: POSIXct, format: \"2035-01-01\" \"2035-01-01\" ...\n $ date_added      : POSIXct, format: \"2035-01-01\" \"2035-01-01\" ...\n $ dob             : POSIXct, format: NA NA ...\n\n# Check the types of the date columns in links\nstr(mc3_data4$links %&gt;% select(start_date))\n\n'data.frame':   75817 obs. of  1 variable:\n $ start_date: POSIXct, format: \"2016-10-29\" \"2035-06-03\" ...\n\n\n\nview(mc3_data4[[\"nodes\"]])\nview(mc3_data4[[\"links\"]])"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#split-words",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#split-words",
    "title": "Take-home Exercise 3 - Vast Challenge 2024",
    "section": "Split Words",
    "text": "Split Words\nThe steps below will be used to split text in type column of nodes into two columns: namely type1 and type2.\n\n# Make a copy of mc3_data4\nmc3_data5 &lt;- mc3_data4\n\n# Split the type column into two columns\nmc3_data5$nodes &lt;- mc3_data5$nodes %&gt;%\n  mutate(\n    type1 = sub(\"^(\\\\S+).*\", \"\\\\1\", type),\n    type2 = sub(\"^\\\\S+\\\\.(.*)\", \"\\\\1\", type)\n  )\n\n# If there's only one word in type, set type2 to NA\nmc3_data5$nodes$type2 &lt;- ifelse(grepl(\"\\\\.\", mc3_data5$nodes$type), mc3_data5$nodes$type2, NA)\n\n# Remove the original 'type' column\nmc3_data5$nodes &lt;- mc3_data5$nodes %&gt;%\n  select(-type)\n\nThe steps below will be used to split text in type column of links into two columns: namely type1 and type2.\n\n# Make a copy of mc3_data4\nmc3_data6 &lt;- mc3_data5\n\n# Split the type column into two columns\n# There are no special cases, exception left blank\nmc3_data6$links &lt;- mc3_data6$links %&gt;%\n  mutate(\n    type1 = sub(\"(.*?\\\\..*?)(\\\\.[^.]+)?$\", \"\\\\1\", type),\n    type2 = ifelse(grepl(\"\\\\.\", type), sub(\".*\\\\.\", \"\", type), \"\")\n  )\n\n# remove the original 'type' column\nmc3_data6$links &lt;- mc3_data6$links %&gt;%\n  select(-type)\n\nVerify changes\n\n# View the first few rows of the type columns in nodes\nhead(mc3_data6$nodes %&gt;% select(type1,type2))\n\n                        type1   type2\n1 Entity.Organization.Company Company\n2 Entity.Organization.Company Company\n3 Entity.Organization.Company Company\n4 Entity.Organization.Company Company\n5 Entity.Organization.Company Company\n6 Entity.Organization.Company Company\n\n# View the first few rows of the type columns in links\nhead(mc3_data6$links %&gt;% select(type1,type2))\n\n       type1           type2\n1 Event.Owns Shareholdership\n2 Event.Owns Shareholdership\n3 Event.Owns Shareholdership\n4 Event.Owns Shareholdership\n5 Event.Owns Shareholdership\n6 Event.Owns Shareholdership\n\n\n\nview(mc3_data6[[\"nodes\"]])\nview(mc3_data6[[\"links\"]])"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#extract-nodes",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#extract-nodes",
    "title": "Take-home Exercise 3 - Vast Challenge 2024",
    "section": "Extract Nodes",
    "text": "Extract Nodes\nFor Question 1\n\n#keep only necessary columns\nmc3_nodes_1 &lt;- as_tibble(mc3_data6$nodes) %&gt;%\n  select (-TradeDescription,\n          -last_edited_by,\n          -last_edited_date,\n          -algorithm,\n          -dob,\n          -type1)\n\nSave as rds file for future use\n\nwrite_rds(mc3_nodes_1, \"data/rds/mc3_nodes_1.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#extract-links",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#extract-links",
    "title": "Take-home Exercise 3 - Vast Challenge 2024",
    "section": "Extract Links",
    "text": "Extract Links\nFor Question 1\n\nmc3_links_1 &lt;- as_tibble(mc3_data6$links) %&gt;%\n  select (-last_edited_by,\n          -last_edited_date,\n          -date_added,\n          -key,\n          -algorithm,\n          -type1,\n          -end_date)\n\nSave as rds file for future use\n\nwrite_rds(mc3_links_1, \"data/rds/mc3_links_1.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#number-of-transactions-over-time",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#number-of-transactions-over-time",
    "title": "Take-home Exercise 3 - Vast Challenge 2024",
    "section": "Number of Transactions over Time",
    "text": "Number of Transactions over Time\nNumber of links can be used to determine transactions over time\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(transactions_over_time, aes(x = start_date, y = count)) +\n  geom_line() +\n  labs(title = \"Transactions Over Time\", x = \"Date\", y = \"Number of Transactions\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe dataset spans from year 1952 to 2035.\nWe can see that from the start of the dataset until about year 2000, there were relatively few transactions. There was a small spike after year 2000, proceeded by exponential growth around 2005. However, there was a dip in transactions in 2035.\nThe dip could be due to effects after SouthSeafood Express Corp was caught for illegal behaviour and eventually closed in 2035.\nAnalysis should focus on transactions from year 2005 onwards. Data analysed should also be aggregated by year.\n\n\n\nFilter data\nFilter data to only keep transactions from 2000 (5 years before 2005) to 2035 (end of dataset). We keep some data that occurs before the start of our period of interest to capture any recent changes to entities.\n\n# Filter the data frames to keep only data from the year 2000 and onwards\nmc3_links_1_filtered &lt;- mc3_links_1 %&gt;%\n  filter(start_date &gt;= as.Date(\"2000-01-01\"))\n\n\n\nAggregate Data by Year\n\n# Extract year for aggregation\nmc3_links_1_filtered2 &lt;- mc3_links_1_filtered %&gt;%\n  mutate(transaction_year = year(start_date))\n\n# Calculate the number of transactions per year\nyearly_txns &lt;- mc3_links_1_filtered2 %&gt;%\n  group_by(transaction_year) %&gt;%\n  summarise(num_transactions = n())\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n# Plot the number of transactions per year\nggplot(yearly_txns, aes(x = transaction_year, y = num_transactions)) +\n  geom_line(color = \"blue\") +\n  labs(title = \"Number of Transactions Per Year\",\n       x = \"Year\",\n       y = \"Number of Transactions\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is now clearer that the rapid growth in transactions started around 2005, before reaching its peak at 2034 and sharply dropping in 2035, likely due to after effects of the SouthSeafood Express Corp incident."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#number-of-active-companies-per-year",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#number-of-active-companies-per-year",
    "title": "Take-home Exercise 3 - Vast Challenge 2024",
    "section": "Number of Active Companies Per Year",
    "text": "Number of Active Companies Per Year\nDrop na values\n\nmc3_nodes2_1 &lt;- mc3_nodes_1 %&gt;%\n  drop_na(founding_date) # removes Persons and Persons CEO\n\nNumber of nodes can be used to determine the number of active companies per year.\n\n# Extract year for aggregation\nmc3_nodes3_1 &lt;- mc3_nodes2_1 %&gt;%\n  mutate(active_year = floor_date(founding_date, \"year\"))\n\n# Calculate the number of active companies per year\nactive_companies &lt;- mc3_nodes3_1 %&gt;%\n  group_by(active_year) %&gt;%\n  summarise(num_active_companies = n())\n\nSummary\n\n# Calculate the summary statistics\nsummary_stats &lt;- summary(active_companies$num_active_companies)\nsummary_stats\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  79.00   88.50   96.00   97.48  104.00  136.00 \n\n# Extract and save the mean\n# Round to 2 decimal places\nmean_active_companies &lt;- round(summary_stats[\"Mean\"], 2)\n\nPlot graph\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n# Plot the number of active companies over time\nggplot(active_companies, aes(x = active_year, y = num_active_companies)) +\n  # line plot\n  geom_line(color = \"darkgreen\") +\n  labs(title = \"Number of Active Companies Over Time\",\n       x = \"Date\",\n       y = \"Number of Active Companies\") +\n  # mean line\n  geom_hline(aes(yintercept = mean_active_companies), \n             linetype = \"dotted\", color = \"blue\") +\n  annotate(\"text\", x = min(active_companies$active_year), \n           y = mean_active_companies, \n           label = paste(\"Mean:\", mean_active_companies), \n           hjust = 0, vjust = -1, color = \"blue\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhile there are fluctuations in the number of active companies over time, there is generally an increasing trend of the number of active companies over time, especially around 2010 onwards. This period shows a rising trend with the number of active companies reaching the highest values in the dataset. This is similar to that observed in the number of transactions over time, seen above.\nWe also see a dip around 2035, before the numbers increase again. Also likely due to the after effects of the SouthSeafood Express Corp incident."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#centrality-measures",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#centrality-measures",
    "title": "Take-home Exercise 3 - Vast Challenge 2024",
    "section": "Centrality Measures",
    "text": "Centrality Measures\n\nModifying network nodes and edges\nPrepare the edges dataframe for network analysis by:\n\nEnsuring all edges are unique.\nConverting columns to a uniform type.\nCalculating the weight of each edge (how many times each connection occurs).\nRemoving any self-loops.\n\n\nmc3_edges &lt;-\n  as_tibble(mc3_links_1_filtered2) %&gt;%\n  distinct() %&gt;%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type2),\n         tyear = as.integer(transaction_year)) %&gt;%\n  group_by(source, target, type,tyear) %&gt;%\n  summarise(weights = n()) %&gt;%\n  filter(source != target) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nNote\n\n\n\nThe resulting mc3_edges tibble contains the columns source, target, type, year, and weights, where each row represents a unique edge between two nodes with a specific type, and the weights column represents the number of times that edge occurs.\n\n\nClean and preprocess the nodes data by:\n\nEnsuring that each column has the correct data type for analysis.\nSelecting only the necessary columns for further analysis or visualization.\n\n\nmc3_nodes &lt;- as_tibble(mc3_nodes_1) %&gt;%\n  mutate(country = as.character(country), \n         id = as.character(id), \n         ProductServices = as.character(ProductServices), \n         revenue = as.numeric(as.character(revenue)), \n         type = as.character(type2)) %&gt;%\n  select(id, country, type, revenue, ProductServices)\n\n\n\n\n\n\n\nNote\n\n\n\nThe resulting mc3_nodes tibble contains the cleaned and correctly typed columns id, country, type, revenue, and ProductServices.\n\n\n\n\nKeeping unique values\nEdges\n\nunique_transaction_types_edges &lt;- mc3_edges %&gt;%\n  select(type) %&gt;%\n  distinct()\n\n# Display the unique transaction types\nprint(unique_transaction_types_edges)\n\n# A tibble: 4 × 1\n  type               \n  &lt;chr&gt;              \n1 Shareholdership    \n2 BeneficialOwnership\n3 WorksFor           \n4 FamilyRelationship \n\n\n\n\n\n\n\n\nNote\n\n\n\nThere are 4 types of edges, namely:\n\nShareholdership\nWorksFor\nBeneficialOwnership\nFamilyRelationship\n\n\n\nNodes\n\nunique_transaction_types_nodes &lt;- mc3_nodes %&gt;%\n  select(type) %&gt;%\n  distinct()\n\n# Display the unique transaction types\nprint(unique_transaction_types_nodes)\n\n# A tibble: 8 × 1\n  type            \n  &lt;chr&gt;           \n1 Company         \n2 LogisticsCompany\n3 FishingCompany  \n4 FinancialCompany\n5 NewsCompany     \n6 NGO             \n7 Person          \n8 CEO             \n\n\n\n\n\n\n\n\nNote\n\n\n\nThere are 8 types of nodes, namely:\n\nCompany\nLogisticsCompany\nFishingCompany\nFinancialCompany\nNewsCompany\nNGO\nPerson\nCEO\n\n\n\n\n\nExtract all the source and target nodes\nExtract all the source and target nodes, then, drop any unmatched nodes\n\nid1 &lt;- mc3_edges %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\n\nid2 &lt;- mc3_edges %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\n\nmc3_nodes1 &lt;- rbind(id1, id2) %&gt;%\n  distinct() %&gt;%\n  left_join(mc3_nodes, by = c(\"id\" = \"id\")) %&gt;%\n  mutate(unmatched = \"drop\")\n\nVerify results\n\nprint(mc3_nodes1)\n\n# A tibble: 60,489 × 6\n   id                     country     type     revenue ProductServices unmatched\n   &lt;chr&gt;                  &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;    \n 1 4. SeaCargo Ges.m.b.H. Oceanus     Logisti…  23304. Tuna, sword fi… drop     \n 2 9. RiverLine CJSC      Oceanus     Company   50134. Unknown         drop     \n 3 Aaron Acosta           Mawalara    Person        0  &lt;NA&gt;            drop     \n 4 Aaron Allen            Galduzim    Person        0  &lt;NA&gt;            drop     \n 5 Aaron Austin           Kethilim    Person        0  &lt;NA&gt;            drop     \n 6 Aaron Baker            Azurionix   Person        0  &lt;NA&gt;            drop     \n 7 Aaron Barry            Kondanovia  Person        0  &lt;NA&gt;            drop     \n 8 Aaron Bauer            Rio Solovia Person        0  &lt;NA&gt;            drop     \n 9 Aaron Bishop           Osterivaro  Person        0  &lt;NA&gt;            drop     \n10 Aaron Bolton           n.a.        Person        0  &lt;NA&gt;            drop     \n# ℹ 60,479 more rows\n\n\n\n\nCreate Graph Object\nCreate graph object and calculate centrality measures\n\nmc3_graph &lt;- tbl_graph(nodes = mc3_nodes1, edges = mc3_edges, directed = TRUE) %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness())\n  theme_graph()\n## List of 136\n##  $ line                            :List of 6\n##   ..$ colour       : chr \"black\"\n##   ..$ linewidth    : num 0.5\n##   ..$ linetype     : num 1\n##   ..$ lineend      : chr \"butt\"\n##   ..$ arrow        : logi FALSE\n##   ..$ inherit.blank: logi TRUE\n##   ..- attr(*, \"class\")= chr [1:2] \"element_line\" \"element\"\n##  $ rect                            :List of 5\n##   ..$ fill         : chr \"white\"\n##   ..$ colour       : chr \"black\"\n##   ..$ linewidth    : num 0.5\n##   ..$ linetype     : num 1\n##   ..$ inherit.blank: logi TRUE\n##   ..- attr(*, \"class\")= chr [1:2] \"element_rect\" \"element\"\n##  $ text                            :List of 11\n##   ..$ family       : chr \"Arial Narrow\"\n##   ..$ face         : chr \"plain\"\n##   ..$ colour       : chr \"black\"\n##   ..$ size         : num 11\n##   ..$ hjust        : num 0.5\n##   ..$ vjust        : num 0.5\n##   ..$ angle        : num 0\n##   ..$ lineheight   : num 0.9\n##   ..$ margin       : 'margin' num [1:4] 0points 0points 0points 0points\n##   .. ..- attr(*, \"unit\")= int 8\n##   ..$ debug        : logi FALSE\n##   ..$ inherit.blank: logi FALSE\n##   ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n##  $ title                           : NULL\n##  $ aspect.ratio                    : NULL\n##  $ axis.title                      : list()\n##   ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n##  $ axis.title.x                    :List of 11\n##   ..$ family       : NULL\n##   ..$ face         : NULL\n##   ..$ colour       : NULL\n##   ..$ size         : NULL\n##   ..$ hjust        : NULL\n##   ..$ vjust        : num 1\n##   ..$ angle        : NULL\n##   ..$ lineheight   : NULL\n##   ..$ margin       : 'margin' num [1:4] 2.75points 0points 0points 0points\n##   .. ..- attr(*, \"unit\")= int 8\n##   ..$ debug        : NULL\n##   ..$ inherit.blank: logi TRUE\n##   ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n##  $ axis.title.x.top                :List of 11\n##   ..$ family       : NULL\n##   ..$ face         : NULL\n##   ..$ colour       : NULL\n##   ..$ size         : NULL\n##   ..$ hjust        : NULL\n##   ..$ vjust        : num 0\n##   ..$ angle        : NULL\n##   ..$ lineheight   : NULL\n##   ..$ margin       : 'margin' num [1:4] 0points 0points 2.75points 0points\n##   .. ..- attr(*, \"unit\")= int 8\n##   ..$ debug        : NULL\n##   ..$ inherit.blank: logi TRUE\n##   ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n##  $ axis.title.x.bottom             : NULL\n##  $ axis.title.y                    :List of 11\n##   ..$ family       : NULL\n##   ..$ face         : NULL\n##   ..$ colour       : NULL\n##   ..$ size         : NULL\n##   ..$ hjust        : NULL\n##   ..$ vjust        : num 1\n##   ..$ angle        : num 90\n##   ..$ lineheight   : NULL\n##   ..$ margin       : 'margin' num [1:4] 0points 2.75points 0points 0points\n##   .. ..- attr(*, \"unit\")= int 8\n##   ..$ debug        : NULL\n##   ..$ inherit.blank: logi TRUE\n##   ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n##  $ axis.title.y.left               : NULL\n##  $ axis.title.y.right              :List of 11\n##   ..$ family       : NULL\n##   ..$ face         : NULL\n##   ..$ colour       : NULL\n##   ..$ size         : NULL\n##   ..$ hjust        : NULL\n##   ..$ vjust        : num 1\n##   ..$ angle        : num -90\n##   ..$ lineheight   : NULL\n##   ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.75points\n##   .. ..- attr(*, \"unit\")= int 8\n##   ..$ debug        : NULL\n##   ..$ inherit.blank: logi TRUE\n##   ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n##  $ axis.text                       : list()\n##   ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n##  $ axis.text.x                     :List of 11\n##   ..$ family       : NULL\n##   ..$ face         : NULL\n##   ..$ colour       : NULL\n##   ..$ size         : NULL\n##   ..$ hjust        : NULL\n##   ..$ vjust        : num 1\n##   ..$ angle        : NULL\n##   ..$ lineheight   : NULL\n##   ..$ margin       : 'margin' num [1:4] 2.2points 0points 0points 0points\n##   .. ..- attr(*, \"unit\")= int 8\n##   ..$ debug        : NULL\n##   ..$ inherit.blank: logi TRUE\n##   ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n##  $ axis.text.x.top                 :List of 11\n##   ..$ family       : NULL\n##   ..$ face         : NULL\n##   ..$ colour       : NULL\n##   ..$ size         : NULL\n##   ..$ hjust        : NULL\n##   ..$ vjust        : num 0\n##   ..$ angle        : NULL\n##   ..$ lineheight   : NULL\n##   ..$ margin       : 'margin' num [1:4] 0points 0points 2.2points 0points\n##   .. ..- attr(*, \"unit\")= int 8\n##   ..$ debug        : NULL\n##   ..$ inherit.blank: logi TRUE\n##   ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n##  $ axis.text.x.bottom              : NULL\n##  $ axis.text.y                     :List of 11\n##   ..$ family       : NULL\n##   ..$ face         : NULL\n##   ..$ colour       : NULL\n##   ..$ size         : NULL\n##   ..$ hjust        : num 1\n##   ..$ vjust        : NULL\n##   ..$ angle        : NULL\n##   ..$ lineheight   : NULL\n##   ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 0points\n##   .. ..- attr(*, \"unit\")= int 8\n##   ..$ debug        : NULL\n##   ..$ inherit.blank: logi TRUE\n##   ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n##  $ axis.text.y.left                : NULL\n##  $ axis.text.y.right               :List of 11\n##   ..$ family       : NULL\n##   ..$ face         : NULL\n##   ..$ colour       : NULL\n##   ..$ size         : NULL\n##   ..$ hjust        : num 0\n##   ..$ vjust        : NULL\n##   ..$ angle        : NULL\n##   ..$ lineheight   : NULL\n##   ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.2points\n##   .. ..- attr(*, \"unit\")= int 8\n##   ..$ debug        : NULL\n##   ..$ inherit.blank: logi TRUE\n##   ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n##  $ axis.text.theta                 : NULL\n##  $ axis.text.r                     :List of 11\n##   ..$ family       : NULL\n##   ..$ face         : NULL\n##   ..$ colour       : NULL\n##   ..$ size         : NULL\n##   ..$ hjust        : num 0.5\n##   ..$ vjust        : NULL\n##   ..$ angle        : NULL\n##   ..$ lineheight   : NULL\n##   ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 2.2points\n##   .. ..- attr(*, \"unit\")= int 8\n##   ..$ debug        : NULL\n##   ..$ inherit.blank: logi TRUE\n##   ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n##  $ axis.ticks                      : list()\n##   ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n##  $ axis.ticks.x                    : NULL\n##  $ axis.ticks.x.top                : NULL\n##  $ axis.ticks.x.bottom             : NULL\n##  $ axis.ticks.y                    : NULL\n##  $ axis.ticks.y.left               : NULL\n##  $ axis.ticks.y.right              : NULL\n##  $ axis.ticks.theta                : NULL\n##  $ axis.ticks.r                    : NULL\n##  $ axis.minor.ticks.x.top          : NULL\n##  $ axis.minor.ticks.x.bottom       : NULL\n##  $ axis.minor.ticks.y.left         : NULL\n##  $ axis.minor.ticks.y.right        : NULL\n##  $ axis.minor.ticks.theta          : NULL\n##  $ axis.minor.ticks.r              : NULL\n##  $ axis.ticks.length               : 'simpleUnit' num 2.75points\n##   ..- attr(*, \"unit\")= int 8\n##  $ axis.ticks.length.x             : NULL\n##  $ axis.ticks.length.x.top         : NULL\n##  $ axis.ticks.length.x.bottom      : NULL\n##  $ axis.ticks.length.y             : NULL\n##  $ axis.ticks.length.y.left        : NULL\n##  $ axis.ticks.length.y.right       : NULL\n##  $ axis.ticks.length.theta         : NULL\n##  $ axis.ticks.length.r             : NULL\n##  $ axis.minor.ticks.length         : 'rel' num 0.75\n##  $ axis.minor.ticks.length.x       : NULL\n##  $ axis.minor.ticks.length.x.top   : NULL\n##  $ axis.minor.ticks.length.x.bottom: NULL\n##  $ axis.minor.ticks.length.y       : NULL\n##  $ axis.minor.ticks.length.y.left  : NULL\n##  $ axis.minor.ticks.length.y.right : NULL\n##  $ axis.minor.ticks.length.theta   : NULL\n##  $ axis.minor.ticks.length.r       : NULL\n##  $ axis.line                       : list()\n##   ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n##  $ axis.line.x                     : NULL\n##  $ axis.line.x.top                 : NULL\n##  $ axis.line.x.bottom              : NULL\n##  $ axis.line.y                     : NULL\n##  $ axis.line.y.left                : NULL\n##  $ axis.line.y.right               : NULL\n##  $ axis.line.theta                 : NULL\n##  $ axis.line.r                     : NULL\n##  $ legend.background               : list()\n##   ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n##  $ legend.margin                   : 'margin' num [1:4] 5.5points 5.5points 5.5points 5.5points\n##   ..- attr(*, \"unit\")= int 8\n##  $ legend.spacing                  : 'simpleUnit' num 11points\n##   ..- attr(*, \"unit\")= int 8\n##  $ legend.spacing.x                : NULL\n##  $ legend.spacing.y                : NULL\n##  $ legend.key                      : list()\n##   ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n##  $ legend.key.size                 : 'simpleUnit' num 1.2lines\n##   ..- attr(*, \"unit\")= int 3\n##  $ legend.key.height               : NULL\n##  $ legend.key.width                : NULL\n##  $ legend.key.spacing              : 'simpleUnit' num 5.5points\n##   ..- attr(*, \"unit\")= int 8\n##  $ legend.key.spacing.x            : NULL\n##  $ legend.key.spacing.y            : NULL\n##  $ legend.frame                    : NULL\n##  $ legend.ticks                    : NULL\n##  $ legend.ticks.length             : 'rel' num 0.2\n##  $ legend.axis.line                : NULL\n##  $ legend.text                     :List of 11\n##   ..$ family       : NULL\n##   ..$ face         : NULL\n##   ..$ colour       : NULL\n##   ..$ size         : 'rel' num 0.8\n##   ..$ hjust        : NULL\n##   ..$ vjust        : NULL\n##   ..$ angle        : NULL\n##   ..$ lineheight   : NULL\n##   ..$ margin       : NULL\n##   ..$ debug        : NULL\n##   ..$ inherit.blank: logi TRUE\n##   ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n##  $ legend.text.position            : NULL\n##  $ legend.title                    :List of 11\n##   ..$ family       : NULL\n##   ..$ face         : NULL\n##   ..$ colour       : NULL\n##   ..$ size         : NULL\n##   ..$ hjust        : num 0\n##   ..$ vjust        : NULL\n##   ..$ angle        : NULL\n##   ..$ lineheight   : NULL\n##   ..$ margin       : NULL\n##   ..$ debug        : NULL\n##   ..$ inherit.blank: logi TRUE\n##   ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n##  $ legend.title.position           : NULL\n##  $ legend.position                 : chr \"right\"\n##  $ legend.position.inside          : NULL\n##  $ legend.direction                : NULL\n##  $ legend.byrow                    : NULL\n##  $ legend.justification            : chr \"center\"\n##  $ legend.justification.top        : NULL\n##  $ legend.justification.bottom     : NULL\n##  $ legend.justification.left       : NULL\n##  $ legend.justification.right      : NULL\n##  $ legend.justification.inside     : NULL\n##  $ legend.location                 : NULL\n##  $ legend.box                      : NULL\n##  $ legend.box.just                 : NULL\n##  $ legend.box.margin               : 'margin' num [1:4] 0cm 0cm 0cm 0cm\n##   ..- attr(*, \"unit\")= int 1\n##  $ legend.box.background           : list()\n##   ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n##  $ legend.box.spacing              : 'simpleUnit' num 11points\n##   ..- attr(*, \"unit\")= int 8\n##   [list output truncated]\n##  - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n##  - attr(*, \"complete\")= logi TRUE\n##  - attr(*, \"validate\")= logi TRUE\n\n\n\nNetwork Graph\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n# Display the network graph\nggraph(mc3_graph, layout = \"fr\") + # Using Fruchterman-Reingold layout\n  geom_edge_link(aes(edge_alpha = 0.8, edge_width = 0.8)) + # Customize edge appearance\n  geom_node_point(aes(size = betweenness_centrality, color = closeness_centrality)) + # Customize node appearance\n  scale_color_viridis_c() + # Use viridis color scale\n  theme_void() + # Use a void theme\n  labs(title = \"Refined Network Graph of Atypical Business Transactions\",\n       subtitle = \"Nodes colored by closeness centrality and sized by betweenness centrality\",\n       caption = \"Data Source: mc3.json\") # Add titles and captions\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe grey circular portion in the center of the network graph does not represent any specific data or entities. It is a visual byproduct resulting from the dense clustering of nodes and edges in that central region. This effect is particularly noticeable in dense, highly interconnected network visualizations where nodes and edges are concentrated in a small space.\nThus, we filter the nodes to refine the graph.\n\n\n\n\nRefined Network Graph\n\nTop Nodes\nIdentify top 20 nodes by betweenness centrality\n\n# Identify top nodes by betweenness centrality\ntop_nodes &lt;- mc3_graph %&gt;% \n  as_tibble()\n\n# Identify top 20 nodes by betweenness centrality\ntop_nodes2 &lt;- top_nodes %&gt;% \n  top_n(20, wt = betweenness_centrality)\n\n\n\nList of most active people and businesses\n\ntop_nodes2\n\n# A tibble: 21 × 8\n   id     country type  revenue ProductServices unmatched betweenness_centrality\n   &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;                      &lt;dbl&gt;\n 1 Corte… Mawala… Comp…  6.99e3 Finish carpent… drop                          22\n 2 Evans… Oceanus Fish…  5.50e4 Processing and… drop                          29\n 3 Fried… Mawand… Comp…  1.64e4 Grocery produc… drop                          38\n 4 Gvard… Nalaki… Comp…  6.85e4 Shipping servi… drop                          33\n 5 Hill … Oceanus Comp…  4.75e3 Unknown         drop                          31\n 6 Howel… Mawand… Comp…  7.74e6 High-grade met… drop                          54\n 7 Johns… Valtal… Comp…  3.35e4 Machinery and … drop                          33\n 8 Kaise… Isla S… Comp…  2.32e4 Canned and cur… drop                          26\n 9 King … Oceanus Comp…  0      Operation of i… drop                          29\n10 Lane … Imazam  Fish…  4.80e3 Fish and seafo… drop                          33\n# ℹ 11 more rows\n# ℹ 1 more variable: closeness_centrality &lt;dbl&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is likely that these entities on the top 10 list are big players in the industry and control information and resources.\nHigh betweenness centrality means that a node plays a more crucial role in connecting other nodes. It can be an indicator of:\n\nBrokerage Role: Nodes with high betweenness centrality often act as bridges or intermediaries between different parts of the network. They control the flow of information, resources, or interactions between other nodes.\nControl and Influence: Nodes with high betweenness centrality have the potential to control the flow of information or resources in the network. They may have more influence or power over the network dynamics compared to other nodes.\n\n\n\nPlot refined graph\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n# Extract IDs of top nodes\n# Extract IDs of top nodes\ntop_node_ids &lt;- top_nodes$id\n\n# Filter the graph to include only top nodes and their incident edges\ntop_graph &lt;- mc3_graph %&gt;%\n  activate(nodes) %&gt;%\n  filter(id %in% top_node_ids) %&gt;%\n  activate(edges) %&gt;%\n  filter(edge_is_incident(top_node_ids))\n\n# Plot the network graph with top nodes\nggraph(top_graph, layout = \"fr\") + \n  geom_edge_link(aes(edge_alpha = 0.1, edge_width = 0.1)) +\n  geom_node_point(aes(size = betweenness_centrality, color = closeness_centrality)) +\n  scale_color_viridis_c() +\n  theme_void() +\n  labs(title = \"Top 20 Nodes Network Graph\",\n       subtitle = \"Nodes colored by closeness centrality and sized by betweenness centrality\",\n       caption = \"Data Source: mc3.json\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe can see that for the top nodes, they are highly interconnected. To the extent that the graph becomes less interpretable.\n\n\n\n\n\nCentrality Over Time\nPlot Graph\n\n# Assuming you have a function to calculate centrality for each year\ncalculate_centrality_over_time &lt;- function(nodes, edges, time_unit = \"year\")\n  {\n  edges &lt;- edges %&gt;%\n    mutate(period = as.Date(paste0(tyear, \"-01-01\")))\n  \n  centrality_results &lt;- edges %&gt;%\n    group_by(period) %&gt;%\n    do({\n      current_edges &lt;- .\n      current_nodes &lt;- nodes %&gt;% filter(id %in% unique(c(current_edges$source, current_edges$target)))\n      graph &lt;- tbl_graph(nodes = current_nodes, edges = current_edges, directed = TRUE)\n      graph %&gt;%\n        mutate(betweenness = centrality_betweenness()) %&gt;%\n        as_tibble() %&gt;%\n        summarise(mean_betweenness = mean(betweenness, na.rm = TRUE))\n    }) %&gt;%\n    ungroup()\n  \n  return(centrality_results)\n}\n\n# Calculate centrality measures over time\ncentrality_over_time &lt;- calculate_centrality_over_time(mc3_nodes1, mc3_edges)\n\n# Plot centrality measures over time\nggplot(centrality_over_time, aes(x = period, y = mean_betweenness)) +\n  geom_line(color = \"red\") +\n  labs(title = \"Average Betweenness Centrality Per Year\",\n       x = \"Year\",\n       y = \"Mean Betweenness Centrality\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis graph shows that there is a increasing trend of the average betweenness centrality per year over time.\nFrom around 2000 to 2020, the average betweenness centrality remains relatively low and fluctuates within a small range, indicating a stable network structure during this period. However, starting around 2025, there is a sharp and dramatic increase in the average betweenness centrality.\nThis sudden rise suggests a significant change in the network dynamics, where certain nodes or entities are becoming increasingly important as bridges or intermediaries connecting different parts of the network. Such a drastic increase could potentially indicate the emergence of new influential players, changes in transaction patterns, or the formation of new connections and pathways within the network.\nThe rapid growth in average betweenness centrality implies that the network structure is becoming more centralized, with a smaller number of nodes acting as critical hubs or gatekeepers, controlling the flow of information or transactions within the network."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#key-influencers",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#key-influencers",
    "title": "Take-home Exercise 3 - Vast Challenge 2024",
    "section": "Key Influencers",
    "text": "Key Influencers\n\nExtract key influencers and their edges\n\n# Filter mc3_edges to keep rows where source ID is in top_nodes2\nkeypersonnel &lt;- mc3_edges %&gt;%\n  filter(source %in% top_nodes2$id)\n\n\n\nKey influencers of the industry\n\nunique(keypersonnel$source)\n\n [1] \"Cortez LLC\"                       \"Evans-Pearson\"                   \n [3] \"Friedman, Gibson and Garcia\"      \"GvardeyskAmerica Shipping Plc\"   \n [5] \"Hill PLC\"                         \"Howell LLC\"                      \n [7] \"Johnson, Perez and Salinas\"       \"Kaiser, Warren and Shepard\"      \n [9] \"King and Sons\"                    \"Lane Group\"                      \n[11] \"Lee-Ramirez\"                      \"Mcpherson-Wright\"                \n[13] \"NamRiver Transit A/S\"             \"Osborne, Saunders and Brown\"     \n[15] \"Patel-Miller\"                     \"Ramos, Jordan and Stewart\"       \n[17] \"Rivera, Lee and Carroll\"          \"Russell and Sons\"                \n[19] \"Stein, Taylor and Williams\"       \"StichtingMarine Shipping Company\"\n[21] \"Vasquez-Gonzalez\"                \n\n\n\n\n\n\n\n\nNote\n\n\n\nThe key influencers are:\n\nCortez LLC\nEvans-Pearson\nFriedman, Gibson and Garcia\nGvardeyskAmerica Shipping Plc\nHill PLC\nHowell LLC\nJohnson, Perez and Salinas\nKaiser, Warren and Shepard\nKing and Sons\nLane Group\nLee-Ramirez\nMcpherson-Wright\nNamRiver Transit A/S\nOsborne, Saunders and Brown\nPatel-Miller\nRamos, Jordan and Stewart\nRivera, Lee and Carroll Russell and Sons\nStein, Taylor and Williams\nStichtingMarine Shipping Company\nVasquez-Gonzalez\n\n\n\nRelationship between influencers and their links\n\nunique(keypersonnel$type)\n\n[1] \"Shareholdership\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere is only 1 type of relationship between the influencers and their links. The influencers are shareholders of those they are linked to.\n\n\n\n\nNetwork Graph\nCreate Graph Object\n\n# Create a nodes dataframe from the unique source and target values\nnodes &lt;- unique(c(keypersonnel$source, keypersonnel$target)) %&gt;%\n  data.frame(name = .)\n\n# Create the graph object using tbl_graph\ngraph_data &lt;- tbl_graph(nodes = nodes,\n                        edges = keypersonnel %&gt;%\n                          rename(from = source, to = target),\n                        directed = TRUE)\n\nPlot Graph\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n# Plot the directed graph\nggraph(graph_data, layout = \"fr\") +  # Using Fruchterman-Reingold layout\n  geom_edge_link(aes(label = as.character(tyear)),  # Only label with tyear\n                 arrow = arrow(length = unit(4, 'mm')),  # Add arrows to indicate direction\n                 end_cap = circle(3, 'mm'),  # Cap the end of the edges with a circle\n                 label_dodge = unit(2, \"mm\"),  # Adjust label position to avoid overlap\n                 label_size = 3,  # Set label size\n                 edge_width = 0.8,  # Set edge width\n                 edge_alpha = 0.8) +  # Set edge transparency\n  geom_node_point(size = 5, color = \"blue\") +  # Customize node appearance\n  geom_node_text(aes(label = name), vjust = 1.5, size = 4) +  # Add node labels\n  theme_void() +  # Use a void theme\n  labs(title = \"Directed Network Graph of Key Personnel Transactions\",\n       subtitle = \"Nodes represent unique sources and targets, edges labeled with year\",\n       caption = \"Data Source: keypersonnel\")  # Add titles and captions\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nMost number of links:\n\n\n\nEntity Name\nNumber of Links\n\n\n\n\nGvardeyskAmerica Shipping Plc\n4\n\n\nRivera, Lee and Carroll\n3\n\n\nCortez LLC\n2\n\n\nKaiser, Warren and Shepard\n2\n\n\nMcpherson-Wright\n2\n\n\nPatel-Miller\n2\n\n\nStichtingMarine Shipping Company\n2\n\n\nVasquez-Gonzalez\n2\n\n\n\nThe earliest link: Lane Group has been the shareholder of Howell LLC since 2020.\nThe most recent link: GvardeyskAmerica Shipping Plc is the shareholder of ArawakFish Cargo Ges.m.b.H.. since 2034."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_geo.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_geo.html",
    "title": "Take-home Exercise 1 - Creating Data Visualisation Beyond Default (Geographical Distribution)",
    "section": "",
    "text": "Take-home Exercise 1 focuses on statistical graphic methods for visualising frequency distribution and value distribution using ggplot2 and its extensions. The below section is an exploration of the data’s geographical distribution on my own accord. \n\n\n\nTo accomplish the task, transaction data of REALIS will be used.\n\nAccess Dataset via SMU e-library\n\nAfter logging in with SMU credentials, navigate to “Residential” tab\n\nUnder Property Types, “Select All”\nUnder Sale Date, select “2024 Jan” - “2024 Mar”\nClick “Search”\nClick “Download”\nDue to the size of the dataset, it is split into multiple segments. Download all in .csv format\n\n\n\n\n\nThe data will be processed using the appropriate tidyverse family of packages and the statistical graphics will be prepared using ggplot2 and its extensions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_geo.html#downloading-the-dataset",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_geo.html#downloading-the-dataset",
    "title": "Take-home Exercise 1 - Creating Data Visualisation Beyond Default (Geographical Distribution)",
    "section": "",
    "text": "To accomplish the task, transaction data of REALIS will be used.\n\nAccess Dataset via SMU e-library\n\nAfter logging in with SMU credentials, navigate to “Residential” tab\n\nUnder Property Types, “Select All”\nUnder Sale Date, select “2024 Jan” - “2024 Mar”\nClick “Search”\nClick “Download”\nDue to the size of the dataset, it is split into multiple segments. Download all in .csv format"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_geo.html#the-designing-tool",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_geo.html#the-designing-tool",
    "title": "Take-home Exercise 1 - Creating Data Visualisation Beyond Default (Geographical Distribution)",
    "section": "",
    "text": "The data will be processed using the appropriate tidyverse family of packages and the statistical graphics will be prepared using ggplot2 and its extensions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_geo.html#installing-and-loading-the-required-libraries",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_geo.html#installing-and-loading-the-required-libraries",
    "title": "Take-home Exercise 1 - Creating Data Visualisation Beyond Default (Geographical Distribution)",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nNote: Ensure that the pacman package has already been installed.\nThe code chunk below loads the following packages using uses p_load() of pacman package:\n\ntidyverse: (i.e. readr, tidyr, dplyr, ggplot2, lubridate) for performing data science tasks such as importing, tidying, and wrangling data, as well as creating graphics based on The Grammar of Graphics\n\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_geo.html#importing-the-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_geo.html#importing-the-data",
    "title": "Take-home Exercise 1 - Creating Data Visualisation Beyond Default (Geographical Distribution)",
    "section": "Importing the Data",
    "text": "Importing the Data\n\nThe data has been split into multiple .csv files\nlist.files() list all CSV files in the specified directory.\nAfter looping through each CSV file, read it into a data frame using read_csv(), and store it in a list.\nbind_rows() combines all data frames in the list into a single big data frame.\n\n\ncsv_directory &lt;- \"data/\"\ncsv_files &lt;- list.files(csv_directory, pattern = \"\\\\.csv$\", full.names = TRUE)\n\nrealis &lt;- list()\n\nfor (file in csv_files) {\n  realis[[file]] &lt;- read_csv(file)\n}\n\n\nrealis_all &lt;- bind_rows(realis)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_geo.html#view-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_geo.html#view-data",
    "title": "Take-home Exercise 1 - Creating Data Visualisation Beyond Default (Geographical Distribution)",
    "section": "View Data",
    "text": "View Data\n\nnames() function prints the names of the columns in the tibble data frame.\nglimpse() function gives a quick overview of the tibble data frame\n\n\nColumn NamesOverview of Tibble Data Frame\n\n\n\ncol_names &lt;- names(realis_all)\ncol_names\n\n [1] \"Project Name\"                \"Transacted Price ($)\"       \n [3] \"Area (SQFT)\"                 \"Unit Price ($ PSF)\"         \n [5] \"Sale Date\"                   \"Address\"                    \n [7] \"Type of Sale\"                \"Type of Area\"               \n [9] \"Area (SQM)\"                  \"Unit Price ($ PSM)\"         \n[11] \"Nett Price($)\"               \"Property Type\"              \n[13] \"Number of Units\"             \"Tenure\"                     \n[15] \"Completion Date\"             \"Purchaser Address Indicator\"\n[17] \"Postal Code\"                 \"Postal District\"            \n[19] \"Postal Sector\"               \"Planning Region\"            \n[21] \"Planning Area\"              \n\n\n\n\n\nglimpse(realis_all)\n\nRows: 26,806\nColumns: 21\n$ `Project Name`                &lt;chr&gt; \"THE REEF AT KING'S DOCK\", \"URBAN TREASU…\n$ `Transacted Price ($)`        &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 1280…\n$ `Area (SQFT)`                 &lt;dbl&gt; 882.65, 882.65, 1076.40, 1033.34, 871.88…\n$ `Unit Price ($ PSF)`          &lt;dbl&gt; 2625, 2066, 1320, 1218, 1468, 1767, 1095…\n$ `Sale Date`                   &lt;chr&gt; \"01 Jan 2023\", \"02 Jan 2023\", \"02 Jan 20…\n$ Address                       &lt;chr&gt; \"12 HARBOURFRONT AVENUE #05-32\", \"205 JA…\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", …\n$ `Area (SQM)`                  &lt;dbl&gt; 82.0, 82.0, 100.0, 96.0, 81.0, 308.7, 42…\n$ `Unit Price ($ PSM)`          &lt;dbl&gt; 28256, 22238, 14211, 13105, 15802, 19015…\n$ `Nett Price($)`               &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Property Type`               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive…\n$ `Number of Units`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Tenure                        &lt;chr&gt; \"99 yrs from 12/01/2021\", \"Freehold\", \"9…\n$ `Completion Date`             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncomplet…\n$ `Purchaser Address Indicator` &lt;chr&gt; \"HDB\", \"Private\", \"HDB\", \"HDB\", \"HDB\", \"…\n$ `Postal Code`                 &lt;chr&gt; \"097996\", \"419535\", \"269343\", \"269294\", …\n$ `Postal District`             &lt;chr&gt; \"04\", \"14\", \"27\", \"27\", \"28\", \"19\", \"10\"…\n$ `Postal Sector`               &lt;chr&gt; \"09\", \"41\", \"26\", \"26\", \"79\", \"54\", \"27\"…\n$ `Planning Region`             &lt;chr&gt; \"Central Region\", \"East Region\", \"North …\n$ `Planning Area`               &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishu…\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nrealis_all contains:\n\nPublic and Private residential property transaction data from 1st January 2023 to 31st March 2024.\nThere are 26,806 rows and 21 columns."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_geo.html#data-preparation",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_geo.html#data-preparation",
    "title": "Take-home Exercise 1 - Creating Data Visualisation Beyond Default (Geographical Distribution)",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nStandardise Date Format\nThe “Sales Date” column is currently a cha type. It needs to be converted into date format.\ndmy() is a function from the lubridate package that converts character strings to date format in the day-month-year (DMY) order.\n\nStandardise Date FormatView Data\n\n\n\nrealis_all$`Sale Date` &lt;- dmy(realis_all$`Sale Date`)\n\n\n\n\nhead(realis_all$`Sale Date`)\n\n[1] \"2023-01-01\" \"2023-01-02\" \"2023-01-02\" \"2023-01-02\" \"2023-01-03\"\n[6] \"2023-01-03\"\n\n\n\n\n\n\n\nKeep Relevant Rows\nDuplicate and empty rows are removed.\n\nqa_pte_raw &lt;- realis_all %&gt;%\n    distinct() %&gt;%\n    drop_na()\n\n\nView Data\n\nglimpse(qa_pte_raw)\n\nRows: 26,800\nColumns: 21\n$ `Project Name`                &lt;chr&gt; \"THE REEF AT KING'S DOCK\", \"URBAN TREASU…\n$ `Transacted Price ($)`        &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 1280…\n$ `Area (SQFT)`                 &lt;dbl&gt; 882.65, 882.65, 1076.40, 1033.34, 871.88…\n$ `Unit Price ($ PSF)`          &lt;dbl&gt; 2625, 2066, 1320, 1218, 1468, 1767, 1095…\n$ `Sale Date`                   &lt;date&gt; 2023-01-01, 2023-01-02, 2023-01-02, 202…\n$ Address                       &lt;chr&gt; \"12 HARBOURFRONT AVENUE #05-32\", \"205 JA…\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", …\n$ `Area (SQM)`                  &lt;dbl&gt; 82.0, 82.0, 100.0, 96.0, 81.0, 308.7, 42…\n$ `Unit Price ($ PSM)`          &lt;dbl&gt; 28256, 22238, 14211, 13105, 15802, 19015…\n$ `Nett Price($)`               &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Property Type`               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive…\n$ `Number of Units`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Tenure                        &lt;chr&gt; \"99 yrs from 12/01/2021\", \"Freehold\", \"9…\n$ `Completion Date`             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncomplet…\n$ `Purchaser Address Indicator` &lt;chr&gt; \"HDB\", \"Private\", \"HDB\", \"HDB\", \"HDB\", \"…\n$ `Postal Code`                 &lt;chr&gt; \"097996\", \"419535\", \"269343\", \"269294\", …\n$ `Postal District`             &lt;chr&gt; \"04\", \"14\", \"27\", \"27\", \"28\", \"19\", \"10\"…\n$ `Postal Sector`               &lt;chr&gt; \"09\", \"41\", \"26\", \"26\", \"79\", \"54\", \"27\"…\n$ `Planning Region`             &lt;chr&gt; \"Central Region\", \"East Region\", \"North …\n$ `Planning Area`               &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishu…\n\n\n\n\n\n\n\n\nNote\n\n\n\nqa_pte_raw contains:\n\nPrivate residential property transaction data from 1st January 2023 to 31st March 2024\nThere are 26,800 rows and 21 columns.\n\n\n\n\n\n\nKeep Relevant Columns\nNot all 21 columns will be used for analysis e.g. contains overlapping information as another column. Only relevant columns will be kept.\nColumns to drop:\n\nArea (SQFT): Similar information as Area (SQM)\nUnit Price ($ PSF): Similar information as Unit Price ($ PSM)\nNett Price ($): Similar information as Transacted Price ($)\nPostal District and Postal Sector: Overlapping information as Postal Code\n\nColumns to be dropped can be specified by prefixing the column names with a minus sign (-) when using the select() function from the dplyr package.\n\nKeep Relevant ColumnsView Data\n\n\n\nqa_pte &lt;- qa_pte_raw %&gt;%\n    select(\n        -`Area (SQFT)`,\n        -`Unit Price ($ PSF)`,\n        -`Postal District`,\n        -`Postal Sector`\n    )\n\n\n\n\nglimpse(qa_pte)\n\nRows: 26,800\nColumns: 17\n$ `Project Name`                &lt;chr&gt; \"THE REEF AT KING'S DOCK\", \"URBAN TREASU…\n$ `Transacted Price ($)`        &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 1280…\n$ `Sale Date`                   &lt;date&gt; 2023-01-01, 2023-01-02, 2023-01-02, 202…\n$ Address                       &lt;chr&gt; \"12 HARBOURFRONT AVENUE #05-32\", \"205 JA…\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", …\n$ `Area (SQM)`                  &lt;dbl&gt; 82.0, 82.0, 100.0, 96.0, 81.0, 308.7, 42…\n$ `Unit Price ($ PSM)`          &lt;dbl&gt; 28256, 22238, 14211, 13105, 15802, 19015…\n$ `Nett Price($)`               &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Property Type`               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive…\n$ `Number of Units`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Tenure                        &lt;chr&gt; \"99 yrs from 12/01/2021\", \"Freehold\", \"9…\n$ `Completion Date`             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncomplet…\n$ `Purchaser Address Indicator` &lt;chr&gt; \"HDB\", \"Private\", \"HDB\", \"HDB\", \"HDB\", \"…\n$ `Postal Code`                 &lt;chr&gt; \"097996\", \"419535\", \"269343\", \"269294\", …\n$ `Planning Region`             &lt;chr&gt; \"Central Region\", \"East Region\", \"North …\n$ `Planning Area`               &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishu…\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nqa_pte contains:\n\nPrivate residential property transaction data from 1st January 2024 to 31st March 2024\nThere are 26,800 rows and 14 columns.\nColumns:\n\nProject Name\nTransacted Price ($)\nSale Date\nAddress\nType of Sale\nType of Area\nArea (SQM)\nUnit Price ($ PSM)\nNett Price\nProperty Type\nNumber of Units\nTensure\nCompletion Date\nPurchaser Address Indicator\nPostal Code\nPlanning Region\nPlanning Area\n\n\n\n\n\n\nSeparate Data by Quarters\nThe dataset contains 5 quarters:\n\nQuarter 1: 2023 Jan - Mar\nQuarter 2: 2023 Apr - Jun\nQuarter 3: 2023 Jul - Sep\nQuarter 4: 2023 Aug - Dec\nQuarter 5: 2024 Jan - Mar\n\nTo allow for comparison between quarters, qa_pte will be split into the respective quarters by Sale Date.\n\nq1 &lt;- qa_pte %&gt;%\n  filter(`Sale Date` &lt;= \"2023-03-31\")\n\nq2 &lt;- qa_pte %&gt;%\n  filter(`Sale Date` &gt; \"2023-03-31\" & `Sale Date` &lt;= \"2023-06-30\")\n\nq3 &lt;- qa_pte %&gt;%\n  filter(`Sale Date` &gt; \"2023-06-30\" & `Sale Date` &lt;= \"2023-09-30\")\n\nq4 &lt;- qa_pte %&gt;%\n  filter(`Sale Date` &gt; \"2023-09-30\" & `Sale Date` &lt;= \"2023-12-31\")\n\nq5 &lt;- qa_pte %&gt;%\n  filter(`Sale Date` &gt; \"2023-12-31\")\n\n\n\nView Data\n\nQ1Q2Q3Q4Q5\n\n\n\nglimpse(q1)\n\nRows: 4,722\nColumns: 17\n$ `Project Name`                &lt;chr&gt; \"THE REEF AT KING'S DOCK\", \"URBAN TREASU…\n$ `Transacted Price ($)`        &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 1280…\n$ `Sale Date`                   &lt;date&gt; 2023-01-01, 2023-01-02, 2023-01-02, 202…\n$ Address                       &lt;chr&gt; \"12 HARBOURFRONT AVENUE #05-32\", \"205 JA…\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", …\n$ `Area (SQM)`                  &lt;dbl&gt; 82.0, 82.0, 100.0, 96.0, 81.0, 308.7, 42…\n$ `Unit Price ($ PSM)`          &lt;dbl&gt; 28256, 22238, 14211, 13105, 15802, 19015…\n$ `Nett Price($)`               &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Property Type`               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive…\n$ `Number of Units`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Tenure                        &lt;chr&gt; \"99 yrs from 12/01/2021\", \"Freehold\", \"9…\n$ `Completion Date`             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncomplet…\n$ `Purchaser Address Indicator` &lt;chr&gt; \"HDB\", \"Private\", \"HDB\", \"HDB\", \"HDB\", \"…\n$ `Postal Code`                 &lt;chr&gt; \"097996\", \"419535\", \"269343\", \"269294\", …\n$ `Planning Region`             &lt;chr&gt; \"Central Region\", \"East Region\", \"North …\n$ `Planning Area`               &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishu…\n\n\n\n\n\nsummary(q2)\n\n Project Name       Transacted Price ($)   Sale Date         \n Length:6125        Min.   :  520000     Min.   :2023-04-01  \n Class :character   1st Qu.: 1268000     1st Qu.:2023-04-24  \n Mode  :character   Median : 1688000     Median :2023-05-13  \n                    Mean   : 2116310     Mean   :2023-05-13  \n                    3rd Qu.: 2350000     3rd Qu.:2023-05-31  \n                    Max.   :66800000     Max.   :2023-06-30  \n   Address          Type of Sale       Type of Area         Area (SQM)    \n Length:6125        Length:6125        Length:6125        Min.   :  30.0  \n Class :character   Class :character   Class :character   1st Qu.:  63.0  \n Mode  :character   Mode  :character   Mode  :character   Median :  89.0  \n                                                          Mean   : 106.7  \n                                                          3rd Qu.: 119.0  \n                                                          Max.   :2339.0  \n Unit Price ($ PSM) Nett Price($)      Property Type      Number of Units \n Min.   : 3364      Length:6125        Length:6125        Min.   : 1.000  \n 1st Qu.:14838      Class :character   Class :character   1st Qu.: 1.000  \n Median :19787      Mode  :character   Mode  :character   Median : 1.000  \n Mean   :20665                                            Mean   : 1.002  \n 3rd Qu.:26390                                            3rd Qu.: 1.000  \n Max.   :57053                                            Max.   :11.000  \n    Tenure          Completion Date    Purchaser Address Indicator\n Length:6125        Length:6125        Length:6125                \n Class :character   Class :character   Class :character           \n Mode  :character   Mode  :character   Mode  :character           \n                                                                  \n                                                                  \n                                                                  \n Postal Code        Planning Region    Planning Area     \n Length:6125        Length:6125        Length:6125       \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n\n\n\n\n\nsummary(q3)\n\n Project Name       Transacted Price ($)   Sale Date         \n Length:6200        Min.   :  440000     Min.   :2023-07-01  \n Class :character   1st Qu.: 1280000     1st Qu.:2023-07-15  \n Mode  :character   Median : 1642500     Median :2023-08-05  \n                    Mean   : 2017893     Mean   :2023-08-09  \n                    3rd Qu.: 2255250     3rd Qu.:2023-08-31  \n                    Max.   :32000000     Max.   :2023-09-30  \n   Address          Type of Sale       Type of Area         Area (SQM)   \n Length:6200        Length:6200        Length:6200        Min.   : 30.0  \n Class :character   Class :character   Class :character   1st Qu.: 67.0  \n Mode  :character   Mode  :character   Mode  :character   Median : 91.0  \n                                                          Mean   :105.7  \n                                                          3rd Qu.:119.0  \n                                                          Max.   :995.0  \n Unit Price ($ PSM) Nett Price($)      Property Type      Number of Units\n Min.   : 2158      Length:6200        Length:6200        Min.   :1      \n 1st Qu.:15071      Class :character   Class :character   1st Qu.:1      \n Median :19048      Mode  :character   Mode  :character   Median :1      \n Mean   :19857                                            Mean   :1      \n 3rd Qu.:24048                                            3rd Qu.:1      \n Max.   :59949                                            Max.   :2      \n    Tenure          Completion Date    Purchaser Address Indicator\n Length:6200        Length:6200        Length:6200                \n Class :character   Class :character   Class :character           \n Mode  :character   Mode  :character   Mode  :character           \n                                                                  \n                                                                  \n                                                                  \n Postal Code        Planning Region    Planning Area     \n Length:6200        Length:6200        Length:6200       \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n\n\n\n\n\nsummary(q4)\n\n Project Name       Transacted Price ($)   Sale Date         \n Length:4851        Min.   :  570000     Min.   :2023-10-01  \n Class :character   1st Qu.: 1285000     1st Qu.:2023-10-25  \n Mode  :character   Median : 1649340     Median :2023-11-11  \n                    Mean   : 2147366     Mean   :2023-11-13  \n                    3rd Qu.: 2370000     3rd Qu.:2023-12-04  \n                    Max.   :33888000     Max.   :2023-12-31  \n   Address          Type of Sale       Type of Area         Area (SQM)    \n Length:4851        Length:4851        Length:4851        Min.   :  30.0  \n Class :character   Class :character   Class :character   1st Qu.:  67.0  \n Mode  :character   Mode  :character   Mode  :character   Median :  96.0  \n                                                          Mean   : 110.7  \n                                                          3rd Qu.: 122.0  \n                                                          Max.   :1423.1  \n Unit Price ($ PSM) Nett Price($)      Property Type      Number of Units\n Min.   : 1484      Length:4851        Length:4851        Min.   :1.000  \n 1st Qu.:14900      Class :character   Class :character   1st Qu.:1.000  \n Median :18846      Mode  :character   Mode  :character   Median :1.000  \n Mean   :19682                                            Mean   :1.001  \n 3rd Qu.:23492                                            3rd Qu.:1.000  \n Max.   :47026                                            Max.   :7.000  \n    Tenure          Completion Date    Purchaser Address Indicator\n Length:4851        Length:4851        Length:4851                \n Class :character   Class :character   Class :character           \n Mode  :character   Mode  :character   Mode  :character           \n                                                                  \n                                                                  \n                                                                  \n Postal Code        Planning Region    Planning Area     \n Length:4851        Length:4851        Length:4851       \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n\n\n\n\n\nsummary(q5)\n\n Project Name       Transacted Price ($)   Sale Date         \n Length:4902        Min.   :  555000     Min.   :2024-01-01  \n Class :character   1st Qu.: 1330000     1st Qu.:2024-01-26  \n Mode  :character   Median : 1688000     Median :2024-02-17  \n                    Mean   : 2100902     Mean   :2024-02-16  \n                    3rd Qu.: 2300000     3rd Qu.:2024-03-14  \n                    Max.   :39500000     Max.   :2024-03-31  \n   Address          Type of Sale       Type of Area         Area (SQM)    \n Length:4902        Length:4902        Length:4902        Min.   :  30.0  \n Class :character   Class :character   Class :character   1st Qu.:  71.0  \n Mode  :character   Mode  :character   Mode  :character   Median :  94.0  \n                                                          Mean   : 111.5  \n                                                          3rd Qu.: 120.7  \n                                                          Max.   :1816.6  \n Unit Price ($ PSM) Nett Price($)      Property Type      Number of Units\n Min.   : 6183      Length:4902        Length:4902        Min.   :1      \n 1st Qu.:15237      Class :character   Class :character   1st Qu.:1      \n Median :18688      Mode  :character   Mode  :character   Median :1      \n Mean   :19502                                            Mean   :1      \n 3rd Qu.:23548                                            3rd Qu.:1      \n Max.   :58099                                            Max.   :2      \n    Tenure          Completion Date    Purchaser Address Indicator\n Length:4902        Length:4902        Length:4902                \n Class :character   Class :character   Class :character           \n Mode  :character   Mode  :character   Mode  :character           \n                                                                  \n                                                                  \n                                                                  \n Postal Code        Planning Region    Planning Area     \n Length:4902        Length:4902        Length:4902       \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_geo.html#geographical-distribution---choropleth-map",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_geo.html#geographical-distribution---choropleth-map",
    "title": "Take-home Exercise 1 - Creating Data Visualisation Beyond Default (Geographical Distribution)",
    "section": "Geographical Distribution - Choropleth Map",
    "text": "Geographical Distribution - Choropleth Map\nA choropleth map is useful for visualizing the variation in average property prices across different areas in Singapore. By shading each region according to its average property price, areas with higher or lower prices can be identified, thus revealing patterns and trends in property values across the city-state. This type of map can reveal hotspots of activity and areas with more affordable or expensive property options.\nTwo data sets will be used to create the map. They are:\n\nMPSZ-2019: This data provides the sub-zone boundary of URA Master Plan 2019. It can be downloaded at data.gov.sg It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2019.\nPrivate residential property transaction data from 1st January 2024 to 31st March 2024 in tibble data frame (i.e. q5).\n\nThe code chunk below loads the following packages:\n\ntmap: for thematic mapping\nsf: for geospatial data handling\nhttr: Make HTTP requests and handles web APIs\nfuture: Allows sequential and parallel processing\nfurrr: combine purrr’s family of mapping functions (within tidyverse) with future’s parallel processing capabilities\n\n\npacman::p_load(tmap,sf,httr, future, furrr)\n\n\nGeospatial Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeocoding using Singapore Land Authority (SLA) API\nGeocoding - provide geographical coordinates corresponding to a location.\nParallel processing is set up to speed up the process. Results are saved into a .csv file for easy future access.\n\nplan(multisession)\n\nurl &lt;- \"https://www.onemap.gov.sg/api/common/elastic/search\"\n\npostcodes &lt;- unique(q5$`Postal Code`)\n\n# Function to fetch data for a single postal code\nfetch_postcode_data &lt;- function(postcode) {\n    query &lt;- list('searchVal' = postcode, 'returnGeom' = 'Y', 'getAddrDetails' = 'Y', 'pageNum' = '1')\n    res &lt;- GET(url, query = query)\n    \n    if (http_error(res)) {\n        return(NULL) \n    }\n    \n    content_res &lt;- content(res)\n    if (content_res$found != 0) {\n        return(data.frame(content_res)[4:13])\n    } else {\n        return(data.frame(postcode = postcode))\n    }\n}\n\nresults &lt;- future_map(postcodes, fetch_postcode_data)\n\nfound &lt;- bind_rows(results, .id = \"postcode\")\n\nfound &lt;- found %&gt;%\n    filter(!is.na(postcode))\n\nwrite.csv(found, file = \"data/aspatial/found.csv\")\n\n\n\n\n\n\n\nNote\n\n\n\nAbove code chunk was written with syntax for httr, which has been superseded by httr2. Please make relevant modifications to utilise the newer package.\n\n\n\n\nImport Geospatial Data\nThe code chunk below uses the st_read() function of sf package to import MPSZ-2019 shapefile into R as a simple feature data frame called mpsz.\n\nCodeContent\n\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\n\n\n\n\nReading layer `MPSZ-2019' from data source \n  `C:\\lnealicia\\ISSS608\\Take-home_Ex\\Take-home_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\nAdd coordinates\nLink postal code to their relevant coordinates. Empty rows are removed. Not all postal codes may have relevant sales during Q1 of 2024.\n\nq5_coor &lt;- q5 %&gt;%\n    left_join(\n        found %&gt;% select(results.POSTAL, results.LATITUDE, results.LONGITUDE),\n        by = c(\"Postal Code\" = \"results.POSTAL\")\n    ) %&gt;%\n    rename(\n        Latitude = results.LATITUDE,\n        Longitude = results.LONGITUDE\n    ) %&gt;%\n   filter(!is.na(Longitude) & !is.na(Latitude))\n\n\n\nConvert to a sf tibble data frame\n\nq5_sf &lt;- st_as_sf(q5_coor,\n                       coords = c(\"Longitude\", \"Latitude\"),\n                       crs =4326) %&gt;%\n  st_transform(crs = 3414)\n\n\n\nKeep relevant columns\n\nq5_sf_plot &lt;- q5_sf %&gt;%\n    select(-`Project Name`,\n           -`Sale Date`,\n           -`Address`,\n           -`Type of Sale`,\n           -`Tenure`,\n           -`Completion Date`)\n\n\n\nAverage Transacted Price by Planning Area\n\navg_txn_px &lt;- q5_sf_plot %&gt;%\n    group_by(`Planning Area`) %&gt;%\n    summarize(\n        Avg_Transacted_Price = mean(`Transacted Price ($)`, na.rm = TRUE)\n    )\n\navg_txn_px &lt;- avg_txn_px %&gt;%\n    mutate(`Planning Area` = toupper(`Planning Area`))\n\navg_txn_px &lt;- st_drop_geometry(avg_txn_px)\n\n\n\nCombine avg_txn_px and mpsz\nPopulates the average transacted price of each planning area into mpsz sf data frame. Not every planning area may have transaction data, so empty rows are dropped.\n\nmpsz_avg_txn_px &lt;- mpsz %&gt;%\n    left_join(\n        avg_txn_px,\n        by = c(\"PLN_AREA_N\" = \"Planning Area\")\n    ) %&gt;%\n  drop_na()\n\n\n\nPlotting Choropleth Map and Geographical Distribution of Private Properties\nThe overall plot shows both the average transacted price of the planning area and the distribution of private residences. If viewing the data separately is preferred, click on the relevant tabs.\n\nOverall PlotAverage Transacted PriceGeographic Distribution of Private Property\n\n\n\ntmap_mode(\"view\")\n\ntm_shape(mpsz_avg_txn_px) +\n    tm_polygons(col = \"Avg_Transacted_Price\", \n                palette = \"YlOrRd\", \n                alpha = 0.3,\n                style = \"quantile\",\n                n = 7) +\n    tmap_options(check.and.fix = TRUE) +\n    \n    tm_shape(q5_sf_plot) +\n    tm_dots(col = \"Property Type\") +\n\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\n\n\ntmap_mode(\"view\")\n\ntm_shape(mpsz_avg_txn_px) +\n    tm_polygons(col = \"Avg_Transacted_Price\", \n                palette = \"YlOrRd\", \n                alpha = 0.3,\n                style = \"quantile\",\n                n = 7) +\n    tmap_options(check.and.fix = TRUE) +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\n\n\ntmap_mode(\"view\")\n\ntm_shape(mpsz_avg_txn_px) +\n    tm_polygons() +\n    tm_shape(q5_sf_plot) +\n    tm_dots(col = \"Property Type\") +\n\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\ntmap_mode(“view”):\n\nDesigned for interactive viewing of spatial data.\nEnables zooming, panning, and other interactive features, making it easier to explore the data in detail.\n\ntmap_mode(“plot”):\n\nUsed for static plotting of spatial data that can be saved as static images e.g., PNG\nDoes not support interactions like zooming and panning.\n\nSetting the mode to plot after the map is generated saves on resources and allows the code to run faster, as the plot does not require continuous updating.\n\n\n\n\n\n\n\n\nWrite Up\n\n\n\nThe plots reveal that of the private properties sold, areas with the highest average transaction price are concentrated around the Central Region, including areas like Bukit Timah and Newton. This is likely due to their proximity to the Central Business District (CBD). Although there are very few transactions in Sentosa and Changi, these areas still have high average transaction prices, mainly consisting of condominiums.\nSales of Executive Condominiums, which were previously noted to have the lowest overall transaction price and low transaction price variability, are predominantly located in the outskirts of Singapore, such as Woodlands and Bukit Batok. This suggests a trend toward more affordable options in these areas.\nApartments and condominiums constitute the majority of private residences sold and are distributed throughout the city-state. This extensive distribution may account for the significant number of outliers observed earlier in transaction prices."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Visual Analytics and Applications",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications homepage. In this website, you will find my coursework. Materials here are based on https://isss608-ay2023-24apr.netlify.app/ by Prof Kam Tin Seong from SMU.\nOverview:"
  },
  {
    "objectID": "index.html#hands-on-exercise",
    "href": "index.html#hands-on-exercise",
    "title": "Visual Analytics and Applications",
    "section": "Hands On Exercise",
    "text": "Hands On Exercise\n\n\n\n\n\n\n\n\n\nHands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods\n\n\n\nAlicia Loh\n\n\nApr 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 2 - Beyond ggplot2 Fundamentals\n\n\n\nAlicia Loh\n\n\nApr 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 3 - Programming Animated Statistical Graphics with R\n\n\n\nAlicia Loh\n\n\nApr 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 3 - Programming Interactive Data Visualisation with R\n\n\n\nAlicia Loh\n\n\nApr 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 4 - Funnel Plots for Fair Comparisons\n\n\n\nAlicia Loh\n\n\nApr 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 4 - Visual Statistical Analysis\n\n\n\nAlicia Loh\n\n\nApr 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 4 - Visualising Uncertainty\n\n\n\nAlicia Loh\n\n\nApr 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 5 - Visualising and Analysing Text Data\n\n\n\nAlicia Loh\n\n\nMay 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 6 - Modelling, Visualising and Analysing Network Data with R\n\n\n\nAlicia Loh\n\n\nMay 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 7 - Visualising and Analysing Time-Oriented Data\n\n\n\nAlicia Loh\n\n\nMay 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 8 Part I - Choropleth Mapping with R\n\n\n\nAlicia Loh\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 8 Part II - Visualising Geospatial Point Data\n\n\n\nAlicia Loh\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 8 Part III - Analytical Mapping\n\n\n\nAlicia Loh\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#in-class-exercise",
    "href": "index.html#in-class-exercise",
    "title": "Visual Analytics and Applications",
    "section": "In Class Exercise",
    "text": "In Class Exercise\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 1 - Introduction to ggplot2\n\n\n\nAlicia Loh\n\n\nApr 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 2 - Visualising Distribution\n\n\n\nAlicia Loh\n\n\nApr 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 4 - Fundamentals of Visual Analytics\n\n\n\nAlicia Loh\n\n\nMay 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 5\n\n\n\nAlicia Loh\n\n\nMay 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 6\n\n\n\nAlicia Loh\n\n\nMay 18, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#take-home-exercise",
    "href": "index.html#take-home-exercise",
    "title": "Visual Analytics and Applications",
    "section": "Take Home Exercise",
    "text": "Take Home Exercise\n\n\n\n\n\n\n\n\n\nTake-home Exercise 1 - Creating Data Visualisation Beyond Default\n\n\n\nAlicia Loh\n\n\n\n\n\n\n\n\n\n\n\n\nTake-home Exercise 1 - Creating Data Visualisation Beyond Default (Geographical Distribution)\n\n\n\nAlicia Loh\n\n\n\n\n\n\n\n\n\n\n\n\nTake-home Exercise 2 - DataVis Makeover\n\n\n\nAlicia Loh\n\n\nApr 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTake-home Exercise 3 - Vast Challenge 2024\n\n\n\nAlicia Loh\n\n\nMay 10, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-Class Exercise 6 -",
    "section": "",
    "text": "The following R packages will be used:\n\ncorporaexplorer\nstringi\nrvest\nreadtext\ntidyverse\n\nCode chunk below will be used to check if these packages have been installed and also will load them into the working R environment.\n\npacman::p_load(corporaexplorer, stringi, rvest, readtext, tidyverse)\n\n\n\n\nDownloading the King James Bible from Project Gutenberg:\n\n\n\nbible &lt;- readr::read_lines(\"http://www.gutenberg.org/cache/epub/10/pg10.txt\")\n\n\n\n\n\nbible &lt;- paste(bible, collapse = \"\\n\")\n\n\n\n\nTechnique borrowed from https://quanteda.io/articles/pkgdown/replication/digital-humanities.html\n\nstart_v &lt;- stri_locate_first_fixed(bible, \"The First Book of Moses: Called Genesis\")[1]\nend_v &lt;- stri_locate_last_fixed(bible, \"Amen.\")[2]\nbible &lt;- stri_sub(bible, start_v, end_v)\n\n\n\n\nEvery book in the bible is preceded by five newlines, which can be used to split the string into a vector where each element is a book.\n\nbooks &lt;- stri_split_regex(bible, \"\\n{5}\") %&gt;%\n    unlist %&gt;%\n    .[-40]  \n# Removing the heading \"The New Testament of the King James Bible\"\n\n\n\n\n\nbooks &lt;- str_replace_all(books, \"\\n{2,}\", \"NEW_PARAGRAPH\") %&gt;%\n    str_replace_all(\"\\n\", \" \") %&gt;%\n    str_replace_all(\"NEW_PARAGRAPH\", \"\\n\\n\")\nbooks &lt;- books[3:68]  # The two first elements are not books\n\n\n\n\n\nchapters &lt;- str_replace_all(books, \"(\\\\d+:1 )\", \"NEW_CHAPTER\\\\1\") %&gt;%\n    stri_split_regex(\"NEW_CHAPTER\")\n\n\n\n\n\nchapters &lt;- lapply(chapters, function(x) x[-1])\n\n\n\n\nRetrieve shorter book titles from esv.org to save space in the corpus map plot.\n\nbook_titles &lt;- read_html(\"https://www.esv.org/resources/esv-global-study-bible/list-of-abbreviations\") %&gt;%\n  html_nodes(\"td:nth-child(1)\") %&gt;%\n  html_text() %&gt;%\n  .[13:78]  # Removing irrelevant elements after manual inspection.\n\n\n\n\nIndicate whether a book belongs to the Old or New Testament.\n\ntestament &lt;- c(rep(\"Old\", 39), rep(\"New\", 27))\n\n\n# Data frame with one book as one row.\nbible_df &lt;- tibble::tibble(Text = chapters,\n                           Book = book_titles,\n                           Testament = testament)\n\n# Each chapter to be one row, but keep the metadata (which book and which testament).\nbible_df &lt;- tidyr::unnest(bible_df, Text)\n\n\n\n\nCorpus not organised by date, so date_based_corpus to FALSE.\n\nKJB &lt;- prepare_data(dataset = bible_df,\n                    date_based_corpus = FALSE,\n                    grouping_variable = \"Book\",\n                    columns_doc_info = c(\"Testament\", \"Book\"))\n\n\n\n\n\n\nexplore(KJB)\n\nShiny applications not supported in static R Markdown documents"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#installing-and-loading-the-required-libraries",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#installing-and-loading-the-required-libraries",
    "title": "In-Class Exercise 6 -",
    "section": "",
    "text": "The following R packages will be used:\n\ncorporaexplorer\nstringi\nrvest\nreadtext\ntidyverse\n\nCode chunk below will be used to check if these packages have been installed and also will load them into the working R environment.\n\npacman::p_load(corporaexplorer, stringi, rvest, readtext, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#the-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#the-data",
    "title": "In-Class Exercise 6 -",
    "section": "",
    "text": "Downloading the King James Bible from Project Gutenberg:\n\n\n\nbible &lt;- readr::read_lines(\"http://www.gutenberg.org/cache/epub/10/pg10.txt\")\n\n\n\n\n\nbible &lt;- paste(bible, collapse = \"\\n\")\n\n\n\n\nTechnique borrowed from https://quanteda.io/articles/pkgdown/replication/digital-humanities.html\n\nstart_v &lt;- stri_locate_first_fixed(bible, \"The First Book of Moses: Called Genesis\")[1]\nend_v &lt;- stri_locate_last_fixed(bible, \"Amen.\")[2]\nbible &lt;- stri_sub(bible, start_v, end_v)\n\n\n\n\nEvery book in the bible is preceded by five newlines, which can be used to split the string into a vector where each element is a book.\n\nbooks &lt;- stri_split_regex(bible, \"\\n{5}\") %&gt;%\n    unlist %&gt;%\n    .[-40]  \n# Removing the heading \"The New Testament of the King James Bible\"\n\n\n\n\n\nbooks &lt;- str_replace_all(books, \"\\n{2,}\", \"NEW_PARAGRAPH\") %&gt;%\n    str_replace_all(\"\\n\", \" \") %&gt;%\n    str_replace_all(\"NEW_PARAGRAPH\", \"\\n\\n\")\nbooks &lt;- books[3:68]  # The two first elements are not books\n\n\n\n\n\nchapters &lt;- str_replace_all(books, \"(\\\\d+:1 )\", \"NEW_CHAPTER\\\\1\") %&gt;%\n    stri_split_regex(\"NEW_CHAPTER\")\n\n\n\n\n\nchapters &lt;- lapply(chapters, function(x) x[-1])\n\n\n\n\nRetrieve shorter book titles from esv.org to save space in the corpus map plot.\n\nbook_titles &lt;- read_html(\"https://www.esv.org/resources/esv-global-study-bible/list-of-abbreviations\") %&gt;%\n  html_nodes(\"td:nth-child(1)\") %&gt;%\n  html_text() %&gt;%\n  .[13:78]  # Removing irrelevant elements after manual inspection.\n\n\n\n\nIndicate whether a book belongs to the Old or New Testament.\n\ntestament &lt;- c(rep(\"Old\", 39), rep(\"New\", 27))\n\n\n# Data frame with one book as one row.\nbible_df &lt;- tibble::tibble(Text = chapters,\n                           Book = book_titles,\n                           Testament = testament)\n\n# Each chapter to be one row, but keep the metadata (which book and which testament).\nbible_df &lt;- tidyr::unnest(bible_df, Text)\n\n\n\n\nCorpus not organised by date, so date_based_corpus to FALSE.\n\nKJB &lt;- prepare_data(dataset = bible_df,\n                    date_based_corpus = FALSE,\n                    grouping_variable = \"Book\",\n                    columns_doc_info = c(\"Testament\", \"Book\"))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#explore-corpus",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#explore-corpus",
    "title": "In-Class Exercise 6 -",
    "section": "",
    "text": "explore(KJB)\n\nShiny applications not supported in static R Markdown documents"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#installing-and-loading-the-required-libraries-1",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#installing-and-loading-the-required-libraries-1",
    "title": "In-Class Exercise 6 -",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nThe following R packages will be used:\n\nggforce\ntidygraph\nggraph\nvisNetwork\nskimr\ntidytext\ntidyverse\ngraphlayouts\njsonlite\n\nCode chunk below will be used to check if these packages have been installed and also will load them into the working R environment.\n\npacman::p_load(ggforce, tidygraph, ggraph, \n               visNetwork, skimr, tidytext,\n               tidyverse, graphlayouts, jsonlite)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-json-file",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-json-file",
    "title": "In-Class Exercise 6 -",
    "section": "Importing JSON File",
    "text": "Importing JSON File\n\nmc3_data &lt;- fromJSON(\"data/MC3.json\")\n\nVerify data type\n\nclass(mc3_data)\n\n[1] \"list\""
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#extract-edges",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#extract-edges",
    "title": "In-Class Exercise 6 -",
    "section": "Extract edges",
    "text": "Extract edges\n\nmc3_edges &lt;-\n  as_tibble(mc3_data$links) %&gt;%\n  distinct() %&gt;%\n  mutate(source =\n           as.character(source),\n         target =\n           as.character(target),\n         type = as.character(type)) %&gt;%\n  group_by(source,target,type) %&gt;% #to count number of unique links\n  summarise(weights = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#extract-nodes",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#extract-nodes",
    "title": "In-Class Exercise 6 -",
    "section": "Extract nodes",
    "text": "Extract nodes\n\nmc3_nodes &lt;-\n  as_tibble(mc3_data$nodes) %&gt;%\n  mutate(country = as.character(country),\n         id = as.character(id),\n         product_services = as.character(product_services),\n         revenue_omu = as.numeric(as.character(revenue_omu)),\n         type = as.character(type)) %&gt;%\n  select(id, country, type, revenue_omu, product_services)\n\n\nModifying network nodes and edges\n\nid1 &lt;- mc3_edges %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\n\nid2 &lt;- mc3_edges %&gt;%\n  select(target) %&gt;%\n  rename (id = target)\nmc3_nodes1 &lt;- rbind(id1, id2) %&gt;%\n  distinct() %&gt;%\n  left_join(mc3_nodes,\n            unmatched = \"drop\")\n\n\n\nConstructing graph\n\nmc3_graph &lt;- tbl_graph(nodes = mc3_nodes1,\n                       edges = mc3_edges,\n                       directed = FALSE) %&gt;%\n  mutate(betweeness_centrality = \n           centrality_betweenness(),\n         closeness_centrality = \n           centrality_closeness())\n\n\nmc3_graph\n\n# A tbl_graph: 37324 nodes and 24036 edges\n#\n# A bipartite simple graph with 13330 components\n#\n# Node Data: 37,324 × 7 (active)\n   id           country type  revenue_omu product_services betweeness_centrality\n   &lt;chr&gt;        &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;                            &lt;dbl&gt;\n 1 1 AS Marine… Islian… Comp…         NA  Scrapbook embel…                  6626\n 2 1 Ltd. Liab… Mawand… Comp…         NA  Unknown                              0\n 3 1 S.A. de C… Oceanus Comp…         NA  Unknown                              0\n 4 1 and Sagl … Kondan… Comp…      18529. Total logistics…                     1\n 5 2 Limited L… Marebak Comp…         NA  Canning, proces…                     6\n 6 2 Limited L… Marebak Comp…         NA  Unknown                              0\n 7 2 S.A. de C… Oceanus Comp…      12567. Unknown                              0\n 8 3 Coast Sp … Puerto… Comp…         NA  Unknown                              0\n 9 3 Limited L… Oceanus Comp…      26867. Fibres, yarns, …                     0\n10 3 Ltd. Liab… Oceanus Comp…     112667. European specia…                     0\n# ℹ 37,314 more rows\n# ℹ 1 more variable: closeness_centrality &lt;dbl&gt;\n#\n# Edge Data: 24,036 × 4\n   from    to type             weights\n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;              &lt;int&gt;\n1     1 16060 Company Contacts       1\n2     1 16061 Beneficial Owner       1\n3     2 16062 Beneficial Owner       1\n# ℹ 24,033 more rows"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#graph-visualisation",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#graph-visualisation",
    "title": "In-Class Exercise 6 -",
    "section": "Graph Visualisation",
    "text": "Graph Visualisation\n\nmc3_graph %&gt;%\n  filter(betweeness_centrality &gt;= 300000) %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = 0.5)) +\n  geom_node_point(aes(\n    size = betweeness_centrality,\n    color = \"lightblue\",\n    alpha = 0.5)) +\n  scale_size_continuous(range=c(1,10)) +\n  theme_graph()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-Class Exercise 4 - Fundamentals of Visual Analytics",
    "section": "",
    "text": "Learning Objectives:"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#installing-and-loading-the-required-libraries",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#installing-and-loading-the-required-libraries",
    "title": "In-Class Exercise 4 - Fundamentals of Visual Analytics",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nThe following R packages will be used:\n\nggstatsplotis an extension of ggplot2 package for creating graphics with details from statstical tests included in the plots themselces\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\nCode chunk below will be used to check if these packages have been installed and also will load them into the working R environment.\n\npacman::p_load(ggstatsplot, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#importing-the-data",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#importing-the-data",
    "title": "In-Class Exercise 4 - Fundamentals of Visual Analytics",
    "section": "Importing the Data",
    "text": "Importing the Data\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\nreadr is a pacakge within tidyverse.\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\nexam_data tibble data frame contains:\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#one-sample-test-gghistostats-method",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#one-sample-test-gghistostats-method",
    "title": "In-Class Exercise 4 - Fundamentals of Visual Analytics",
    "section": "One-sample test: gghistostats() method",
    "text": "One-sample test: gghistostats() method\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nset.seed(1234) # for reproducibility\n\np &lt;- gghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"parametric\",\n  test.value = 60,\n  bin.args = list(color = \"black\",\n                  fill = \"skyblue\",\n                  alpha = 0.7),\n  normal.curve = FALSE, #default value is FALSE\n  normal.curve.args = list(linewidth = .5),\n  xlab = \"English Scores\"\n)\n\np\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\nExtracting expressions and data frames with statistical details\nggstatsplot also offers a convenience function to extract data frames with statistical details that are used to create expressions displayed in ggstatsplot plots.\n\nextract_stats(p)\n\n$subtitle_data\n# A tibble: 1 × 15\n     mu statistic df.error  p.value method            alternative effectsize\n  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt;       &lt;chr&gt;     \n1    60      8.77      321 1.04e-16 One Sample t-test two.sided   Hedges' g \n  estimate conf.level conf.low conf.high conf.method conf.distribution n.obs\n     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;             &lt;int&gt;\n1    0.488       0.95    0.372     0.603 ncp         t                   322\n  expression\n  &lt;list&gt;    \n1 &lt;language&gt;\n\n$caption_data\n# A tibble: 1 × 16\n  term       effectsize      estimate conf.level conf.low conf.high    pd\n  &lt;chr&gt;      &lt;chr&gt;              &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 Difference Bayesian t-test     7.16       0.95     5.54      8.75     1\n  prior.distribution prior.location prior.scale    bf10 method         \n  &lt;chr&gt;                       &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          \n1 cauchy                          0       0.707 4.54e13 Bayesian t-test\n  conf.method log_e_bf10 n.obs expression\n  &lt;chr&gt;            &lt;dbl&gt; &lt;int&gt; &lt;list&gt;    \n1 ETI               31.4   322 &lt;language&gt;\n\n$pairwise_comparisons_data\nNULL\n\n$descriptive_data\nNULL\n\n$one_sample_data\nNULL\n\n$tidy_data\nNULL\n\n$glance_data\nNULL"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#ggdotplotstats",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#ggdotplotstats",
    "title": "In-Class Exercise 4 - Fundamentals of Visual Analytics",
    "section": "ggdotplotstats()",
    "text": "ggdotplotstats()\nIn the code chunk below, the function ggdotplotstats is used to provide an easy way to make publication-ready dot plots/charts with appropriate and selected statistical details embedded in the plot itself.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggdotplotstats(\n  data = exam,\n  x = ENGLISH, \n  y = CLASS,\n  title = \"p\",\n  xlab = \"FALSE\"\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#ggwithinstats",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#ggwithinstats",
    "title": "In-Class Exercise 4 - Fundamentals of Visual Analytics",
    "section": "ggwithinstats()",
    "text": "ggwithinstats()\nTransform data into suitable format for plot\n\nexam_long &lt;- exam %&gt;%\n  pivot_longer(\n    cols = ENGLISH:SCIENCE,\n    names_to = \"SUBJECT\",\n    values_to = \"SCORES\"\n  ) %&gt;%\n  filter(CLASS == \"3A\")\n\nIn the code chunk below, the function ggwithinstats is designed to facilitate data exploration, and for making highly customizable publication-ready plots, with relevant statistical details included in the plot itself if desired.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggwithinstats(\n  data = filter(exam_long,\n                SUBJECT %in%\n                  c(\"MATHS\", \"SCIENCE\")),\n  x = SUBJECT, \n  y = SCORES,\n  type = \"p\"\n)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#significant-test-of-correlation-ggscatterstats",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#significant-test-of-correlation-ggscatterstats",
    "title": "In-Class Exercise 4 - Fundamentals of Visual Analytics",
    "section": "Significant Test of Correlation: ggscatterstats()",
    "text": "Significant Test of Correlation: ggscatterstats()\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = TRUE,\n  label.var = ID, # show student ID \n  label.expression = ENGLISH &gt; 90 & MATHS &gt; 90 #criteria\n  )"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising-models",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising-models",
    "title": "In-Class Exercise 4 - Fundamentals of Visual Analytics",
    "section": "Visualising Models",
    "text": "Visualising Models\nVisualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#installing-and-loading-the-required-libraries-1",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#installing-and-loading-the-required-libraries-1",
    "title": "In-Class Exercise 4 - Fundamentals of Visual Analytics",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\n\npacman::p_load(readxl, performance, parameters, see)\n\n\nImporting Excel file: readxl methods\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#multiple-regression-model-using-lm",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#multiple-regression-model-using-lm",
    "title": "In-Class Exercise 4 - Fundamentals of Visual Analytics",
    "section": "Multiple Regression Model using lm()",
    "text": "Multiple Regression Model using lm()\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale) # list square model\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#model-diagnostic-checking-for-multicolinearity",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#model-diagnostic-checking-for-multicolinearity",
    "title": "In-Class Exercise 4 - Fundamentals of Visual Analytics",
    "section": "Model Diagnostic: checking for multicolinearity:",
    "text": "Model Diagnostic: checking for multicolinearity:\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#model-diagnostic-checking-normality-assumption",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#model-diagnostic-checking-normality-assumption",
    "title": "In-Class Exercise 4 - Fundamentals of Visual Analytics",
    "section": "Model Diagnostic: checking normality assumption",
    "text": "Model Diagnostic: checking normality assumption\nIn the code chunk, check_normality() of performance package.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\ncheck_n &lt;- check_normality(model1)\n\nplot(check_n)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#model-diagnostic-check-model-for-homogeneity-of-variances",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#model-diagnostic-check-model-for-homogeneity-of-variances",
    "title": "In-Class Exercise 4 - Fundamentals of Visual Analytics",
    "section": "Model Diagnostic: Check model for homogeneity of variances",
    "text": "Model Diagnostic: Check model for homogeneity of variances\nIn the code chunk, check_heteroscedasticity() of performance package.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ncheck_h &lt;- check_heteroscedasticity(model1)\nplot(check_h)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#model-diagnostic-complete-check",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#model-diagnostic-complete-check",
    "title": "In-Class Exercise 4 - Fundamentals of Visual Analytics",
    "section": "Model Diagnostic: Complete check",
    "text": "Model Diagnostic: Complete check\nWe can also perform the complete by using check_model().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ncheck_model(model1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising-regression-parameters-see-methods",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising-regression-parameters-see-methods",
    "title": "In-Class Exercise 4 - Fundamentals of Visual Analytics",
    "section": "Visualising Regression Parameters: see methods",
    "text": "Visualising Regression Parameters: see methods\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nplot(parameters(model1))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising-regression-parameters-ggcoefstats-methods",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising-regression-parameters-ggcoefstats-methods",
    "title": "In-Class Exercise 4 - Fundamentals of Visual Analytics",
    "section": "Visualising Regression Parameters: ggcoefstats() methods",
    "text": "Visualising Regression Parameters: ggcoefstats() methods\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-Class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-Class_Ex01.html",
    "title": "In-Class Exercise 1",
    "section": "",
    "text": "Note: Ensure that the pacman package has already been installed.\nThe code chunk below uses p_load() of pacman package to load the tidyverse family of packages.\n\npacman::p_load(tidyverse)\n\n\n\n\n\nThe code chunk below imports realis2019.csv into R environment by using read_csv() function of readr package.\nreadr is one of the tidyverse package.\n\n\nrealis &lt;- read_csv(\"data/realis2019.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-Class_Ex01.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex01/In-Class_Ex01.html#loading-r-packages",
    "title": "In-Class Exercise 1",
    "section": "",
    "text": "Note: Ensure that the pacman package has already been installed.\nThe code chunk below uses p_load() of pacman package to load the tidyverse family of packages.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-Class_Ex01.html#importing-the-data",
    "href": "In-class_Ex/In-class_Ex01/In-Class_Ex01.html#importing-the-data",
    "title": "In-Class Exercise 1",
    "section": "",
    "text": "The code chunk below imports realis2019.csv into R environment by using read_csv() function of readr package.\nreadr is one of the tidyverse package.\n\n\nrealis &lt;- read_csv(\"data/realis2019.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html",
    "title": "Hands-on Exercise 8 Part II - Visualising Geospatial Point Data",
    "section": "",
    "text": "Learning Objectives:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 8 Part II - Visualising Geospatial Point Data",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nThe following R packages will be used:\n\nTidyverse:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\n\nsf for handling geospatial data\ntmap for plotting choropleth maps\n\nCode chunk below will be used to check if these packages have been installed and also will load them into the working R environment.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#the-data",
    "title": "Hands-on Exercise 8 Part II - Visualising Geospatial Point Data",
    "section": "The Data",
    "text": "The Data\nThe data set used is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#data-import-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#data-import-and-preparation",
    "title": "Hands-on Exercise 8 Part II - Visualising Geospatial Point Data",
    "section": "Data Import and Preparation",
    "text": "Data Import and Preparation\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\n\nExamining the data content\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "title": "Hands-on Exercise 8 Part II - Visualising Geospatial Point Data",
    "section": "Creating a sf data frame from an aspatial data frame",
    "text": "Creating a sf data frame from an aspatial data frame\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe coords argument requires the column name of the x-coordinates to be provided first, followed by the column name of the y-coordinates.\nThe crs argument requires the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System to be provided. Country epsg codes can be found at epsg.io.\n\n\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n\nDisplay the basic information of the newly created sgpools_sf \n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#interactive-point-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#interactive-point-symbol-map",
    "title": "Hands-on Exercise 8 Part II - Visualising Geospatial Point Data",
    "section": "Interactive point symbol map",
    "text": "Interactive point symbol map\nThe code chunks below are used to create an interactive point symbol map.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#proportional-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#proportional-symbol-map",
    "title": "Hands-on Exercise 8 Part II - Visualising Geospatial Point Data",
    "section": "Proportional Symbol Map",
    "text": "Proportional Symbol Map\nTo draw a proportional symbol map, the numerical variable needs to be assigned to the size visual attribute. The code chunk below shows the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#colour-visual-attribute",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#colour-visual-attribute",
    "title": "Hands-on Exercise 8 Part II - Visualising Geospatial Point Data",
    "section": "Colour Visual Attribute",
    "text": "Colour Visual Attribute\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunk below, OUTLET_TYPE variable is used as the colour attribute variable.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#faceted-plots",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_2.html#faceted-plots",
    "title": "Hands-on Exercise 8 Part II - Visualising Geospatial Point Data",
    "section": "Faceted Plots",
    "text": "Faceted Plots\ntmap’s view mode also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\nSwitch tmap’s viewer back to plot mode\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands-on Exercise 7 - Visualising and Analysing Time-Oriented Data",
    "section": "",
    "text": "Learning Objectives:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 7 - Visualising and Analysing Time-Oriented Data",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nThe following R packages will be used:\n\nscales\nviridis\nggthemes\ngridExtra\nreadxl\nknitr\ndata.table\ntidyverse\nlubridate\nCGPfunctions\n\nCode chunk below will be used to check if these packages have been installed and also will load them into the working R environment.\n\npacman::p_load(scales, viridis, ggthemes, gridExtra, readxl, knitr, data.table, tidyverse, lubridate, CGPfunctions)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-calendar-heatmap",
    "title": "Hands-on Exercise 7 - Visualising and Analysing Time-Oriented Data",
    "section": "Plotting Calendar Heatmap",
    "text": "Plotting Calendar Heatmap\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\nThe Data\nImport eventlog.csv into RStudio environment by using read_csv() of readr package.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\nExamining the data structure\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nattacks contains three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\n\n\n\nData Preparation\nStep 1: Deriving weekday and hours of day fields\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\nNote\n\n\n\nmutate() of dplyr package is used to:\n\nextract necessary data into attacks dataframe\nconvert wkday and hour fields into factor so they’ll be ordered when plotting\n\n\n\nView dataframe\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\nBuilding the Calendar Heatmaps\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\ngrouped tibble dataframe is derived by aggregating the attacks by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\nNext, group the count by hour and wkday, then plot it."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#building-multiple-calendar-heatmaps",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#building-multiple-calendar-heatmaps",
    "title": "Hands-on Exercise 7 - Visualising and Analysing Time-Oriented Data",
    "section": "Building Multiple Calendar Heatmaps",
    "text": "Building Multiple Calendar Heatmaps\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\nPlotting Multiple Calendar Heatmaps\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, the following steps need to be done:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nExtract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\nPlotting Multiple Calendar Heatmaps\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-cycle-plot",
    "title": "Hands-on Exercise 7 - Visualising and Analysing Time-Oriented Data",
    "section": "Plotting Cycle Plot",
    "text": "Plotting Cycle Plot\nPlot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\nStep 1: Data Import\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\nStep 2: Deriving month and year fields\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\nStep 3: Extracting the target country\nThe code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\nStep 4: Computing year average arrivals by month\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\nStep 5: Plotting the cycle plot\nThe code chunk below is used to plot the cycle plot\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-slopegraph",
    "title": "Hands-on Exercise 7 - Visualising and Analysing Time-Oriented Data",
    "section": "Plotting Slopegraph",
    "text": "Plotting Slopegraph\nCGPfunctions will be used. Refer to Using newggslopegraph to learn more about the function. Read more about newggslopegraph() and its arguments by referring to its documentation.\n\nStep 1: Data Import\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\n\n\nStep 2: Plotting the slopegraph\nThe code chunk below will be used to plot a basic slopegraph.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Year field from numeric to factor."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5 - Visualising and Analysing Text Data",
    "section": "",
    "text": "Learning Objectives:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 5 - Visualising and Analysing Text Data",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nThe following R packages will be used:\n\ntidytext, tidyverse (mainly readr, purrr, stringr, ggplot2)\nwidyr,\nwordcloud and ggwordcloud,\ntextplot (required igraph, tidygraph and ggraph, )\nDT,\nlubridate and hms.\n\nCode chunk below will be used to check if these packages have been installed and also will load them into the working R environment.\n\npacman::p_load(tidytext, widyr, wordcloud, DT, ggwordcloud, textplot, lubridate, hms,tidyverse, tidygraph, ggraph, igraph)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders",
    "title": "Hands-on Exercise 5 - Visualising and Analysing Text Data",
    "section": "Importing Multiple Text Files from Multiple Folders",
    "text": "Importing Multiple Text Files from Multiple Folders\n\nCreating a folder list\n\nnews20 &lt;- \"data/20news/\"\n\n\n\nDefine a function to read all files from a folder into a data frame\n\nread_folder &lt;- function(infolder) {\n  tibble(file = dir(infolder, \n                    full.names = TRUE)) %&gt;%\n    mutate(text = map(file, \n                      read_lines)) %&gt;%\n    transmute(id = basename(file), \n              text) %&gt;%\n    unnest(text)\n}"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders-1",
    "title": "Hands-on Exercise 5 - Visualising and Analysing Text Data",
    "section": "Importing Multiple Text Files from Multiple Folders",
    "text": "Importing Multiple Text Files from Multiple Folders\n\nReading in all the messages from the 20news folder\n\nread_lines() of readr package is used to read up to n_max lines from a file.\nmap() of purrr package is used to transform their input by applying a function to each element of a list and returning an object of the same length as the input.\nunnest() of dplyr package is used to flatten a list-column of data frames back out into regular columns.\nmutate() of dplyr is used to add new variables and preserves existing ones;\ntransmute() of dplyr is used to add new variables and drops existing ones.\nread_rds() is used to save the extracted and combined data frame as rds file for future use.\n\n\nraw_text &lt;- tibble(folder = \n                     dir(news20, \n                         full.names = TRUE)) %&gt;%\n  mutate(folder_out = map(folder, \n                          read_folder)) %&gt;%\n  unnest(cols = c(folder_out)) %&gt;%\n  transmute(newsgroup = basename(folder), \n            id, text)\nwrite_rds(raw_text, \"data/rds/news20.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#initial-eda",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#initial-eda",
    "title": "Hands-on Exercise 5 - Visualising and Analysing Text Data",
    "section": "Initial EDA",
    "text": "Initial EDA\nFigure below shows the frequency of messages by newsgroup.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nraw_text &lt;- read_rds(\"data/rds/news20.rds\")\nraw_text %&gt;%\n  group_by(newsgroup) %&gt;%\n  summarize(messages = n_distinct(id)) %&gt;%\n  ggplot(aes(messages, newsgroup)) +\n  geom_col(fill = \"lightblue\") +\n  labs(y = NULL)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#introducing-tidytext",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#introducing-tidytext",
    "title": "Hands-on Exercise 5 - Visualising and Analysing Text Data",
    "section": "Introducing tidytext",
    "text": "Introducing tidytext\n\nUsing tidy data principles in processing, analysing and visualising text data.\nMuch of the infrastructure needed for text mining with tidy data frames already exists in packages like ‘dplyr’, ‘broom’, ‘tidyr’, and ‘ggplot2’.\n\n\nRemoving header and automated email signitures\nEach message contains certain structural elements and additional text that are undesirable for inclusion in the analysis. For example:\n\nHeader containing fields such as “from:” or “in_reply_to:”\nAutomated email signatures, which occur after a line like “–”.\n\nThe code chunk below uses:\n\ncumsum() of base R to return a vector whose elements are the cumulative sums of the elements of the argument.\nstr_detect() from stringr to detect the presence or absence of a pattern in a string.\n\n\ncleaned_text &lt;- raw_text %&gt;%\n  group_by(newsgroup, id) %&gt;%\n  filter(cumsum(text == \"\") &gt; 0,\n         cumsum(str_detect(\n           text, \"^--\")) == 0) %&gt;%\n  ungroup()\n\n\n\nRemoving lines with nested text representing quotes from other users\nRegular expressions are used to remove with nested text representing quotes from other users.\n\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string.\nfilter() of dplyr package is used to subset a data frame, retaining all rows that satisfy the specified conditions.\n\n\ncleaned_text &lt;- cleaned_text %&gt;%\n  filter(str_detect(text, \"^[^&gt;]+[A-Za-z\\\\d]\")\n         | text == \"\",\n         !str_detect(text, \n                     \"writes(:|\\\\.\\\\.\\\\.)$\"),\n         !str_detect(text, \n                     \"^In article &lt;\")\n  )\n\n\n\nText Data Processing\n\n unnest_tokens() of tidytext package is used to split the dataset into tokens\n stop_words() is used to remove stop-words\n\n\nusenet_words &lt;- cleaned_text %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\nHeaders, signatures and formatting have been removed. The code chunk below calculates individual word frequncies to explore common words in the dataset.\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\n# A tibble: 5,542 × 2\n   word           n\n   &lt;chr&gt;      &lt;int&gt;\n 1 people        57\n 2 time          50\n 3 jesus         47\n 4 god           44\n 5 message       40\n 6 br            27\n 7 bible         23\n 8 drive         23\n 9 homosexual    23\n10 read          22\n# ℹ 5,532 more rows\n\n\nWord frequencies within newsgroup\n\nwords_by_newsgroup &lt;- usenet_words %&gt;%\n  count(newsgroup, word, sort = TRUE) %&gt;%\n  ungroup()\n\n\n\nVisualising Words in newsgroups\n\nwordcloud() of wordcloud package is used to plot a static wordcloud\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nwordcloud(words_by_newsgroup$word,\n          words_by_newsgroup$n,\n          max.words = 300)\n\n\n\n\nA DT table can be used to complement the visual discovery.\n\nTableCode\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a data frame with word frequency data\nword_freq_table &lt;- data.frame(Word = words_by_newsgroup$word,\n                              Frequency = words_by_newsgroup$n)\n\n# Render the DataTable\ndatatable(word_freq_table, \n          options = list(pageLength = 10))\n\n\n\n\n\n\nVisualising Words in newsgroups\n ggwordcloud package is used to plot the wordcloud below\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\nwords_by_newsgroup %&gt;%\n  filter(n &gt; 0) %&gt;%\nggplot(aes(label = word,\n           size = n)) +\n  geom_text_wordcloud() +\n  theme_minimal() +\n  facet_wrap(~newsgroup)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#basic-concept-of-tf-idf",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#basic-concept-of-tf-idf",
    "title": "Hands-on Exercise 5 - Visualising and Analysing Text Data",
    "section": "Basic Concept of TF-IDF",
    "text": "Basic Concept of TF-IDF\ntf–idf, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection of corpus.\n\\(idf(term) = ln \\frac{n_{documents}}{n_{documents containing term}}\\)\n\nComputing tf-idf within newsgroups\nbind_tf_idf() of tidytext is used to compute and bind the term frequency, inverse document frequency and ti-idf of a tidy text dataset to the dataset.\n\ntf_idf &lt;- words_by_newsgroup %&gt;%\n  bind_tf_idf(word, newsgroup, n) %&gt;%\n  arrange(desc(tf_idf))\n\n\n\nVisualising tf-idf as interactive table\nInteractive table created by using datatable() to create a html table that allows pagination of rows and columns.\nThe code chunk below also uses:\n\nfilter() argument is used to turn control the filter UI.\nformatRound() is used to customise the values format. The argument digits define the number of decimal places.\nformatStyle() is used to customise the output table. In this example, the arguments target and lineHeight are used to reduce the line height by 25%.\n\n\nTableCode\n\n\n\n\n\n\n\n\n\n\n\n\nDT::datatable(tf_idf, filter = 'top') %&gt;% \n  formatRound(columns = c('tf', 'idf', \n                          'tf_idf'), \n              digits = 3) %&gt;%\n  formatStyle(0, \n              target = 'row', \n              lineHeight='25%')\n\n\n\n\n\n\nVisualising tf-idf within newsgroups\nFacet bar charts technique is used to visualise the tf-idf values of science related newsgroup.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ntf_idf %&gt;%\n  filter(str_detect(newsgroup, \"^sci\\\\.\")) %&gt;%\n  group_by(newsgroup) %&gt;%\n  slice_max(tf_idf, \n            n = 12) %&gt;%\n  ungroup() %&gt;%\n  mutate(word = reorder(word, \n                        tf_idf)) %&gt;%\n  ggplot(aes(tf_idf, \n             word, \n             fill = newsgroup)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ newsgroup, \n             scales = \"free\") +\n  labs(x = \"tf-idf\", \n       y = NULL)\n\n\n\n\n\n\nCounting and correlating pairs of words with the widyr package\n\nTo count the number of times that two words appear within the same document, or to see how correlated they are.\nMost operations for finding pairwise counts or correlations need to turn the data into a wide matrix first.\nwidyr package first ‘casts’ a tidy dataset into a wide matrix, performs an operation such as a correlation on it, then re-tidies the result.\n\nIn this code chunk below, pairwise_cor() of widyr package is used to compute the correlation between newsgroup based on the common words found.\n\nnewsgroup_cors &lt;- words_by_newsgroup %&gt;%\n  pairwise_cor(newsgroup, \n               word, \n               n, \n               sort = TRUE)\n\n\n\nVisualising correlation as a network\nRelationship between newgroups is visualised as a network graph\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nset.seed(2017)\n\nnewsgroup_cors %&gt;%\n  filter(correlation &gt; .025) %&gt;%\n  graph_from_data_frame() %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = correlation, \n                     width = correlation)) +\n  geom_node_point(size = 6, \n                  color = \"lightblue\") +\n  geom_node_text(aes(label = name),\n                 color = \"red\",\n                 repel = TRUE) +\n  theme_void()\n\n\n\n\n\n\nBigram\nCreated by using unnest_tokens() of tidytext.\n\nBigramCode\n\n\n\n\n# A tibble: 28,827 × 3\n   newsgroup   id    bigram    \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;     \n 1 alt.atheism 54256 &lt;NA&gt;      \n 2 alt.atheism 54256 &lt;NA&gt;      \n 3 alt.atheism 54256 as i      \n 4 alt.atheism 54256 i don't   \n 5 alt.atheism 54256 don't know\n 6 alt.atheism 54256 know this \n 7 alt.atheism 54256 this book \n 8 alt.atheism 54256 book i    \n 9 alt.atheism 54256 i will    \n10 alt.atheism 54256 will use  \n# ℹ 28,817 more rows\n\n\n\n\n\nbigrams &lt;- cleaned_text %&gt;%\n  unnest_tokens(bigram, \n                text, \n                token = \"ngrams\", \n                n = 2)\n\nbigrams\n\n\n\n\n\n\nCounting bigrams\nCount and sort the bigram data frame ascendingly\n\nBigram CountCode\n\n\n\n\n# A tibble: 19,888 × 2\n   bigram       n\n   &lt;chr&gt;    &lt;int&gt;\n 1 of the     169\n 2 in the     113\n 3 to the      74\n 4 to be       59\n 5 for the     52\n 6 i have      48\n 7 that the    47\n 8 if you      40\n 9 on the      39\n10 it is       38\n# ℹ 19,878 more rows\n\n\n\n\n\nbigrams_count &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  count(bigram, sort = TRUE)\n\nbigrams_count\n\n\n\n\n\n\nCleaning bigram\nSeperate the bigram into two words\n\nBigramCode\n\n\n\n\n# A tibble: 4,607 × 4\n   newsgroup   id    word1        word2        \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;        \n 1 alt.atheism 54256 defines      god          \n 2 alt.atheism 54256 term         preclues     \n 3 alt.atheism 54256 science      ideas        \n 4 alt.atheism 54256 ideas        drawn        \n 5 alt.atheism 54256 supernatural precludes    \n 6 alt.atheism 54256 scientific   assertions   \n 7 alt.atheism 54256 religious    dogma        \n 8 alt.atheism 54256 religion     involves     \n 9 alt.atheism 54256 involves     circumventing\n10 alt.atheism 54256 gain         absolute     \n# ℹ 4,597 more rows\n\n\n\n\n\nbigrams_separated &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), \n           sep = \" \")\n\nbigrams_filtered &lt;- bigrams_separated %&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\n\n\n\n\n\n\nCounting the bigram again\n\nbigram_counts &lt;- bigrams_filtered %&gt;% \n  count(word1, word2, sort = TRUE)\n\n\n\nCreate a network graph from bigram data frame\nA network graph is created by using graph_from_data_frame() of igraph package.\n\nbigram_graph &lt;- bigram_counts %&gt;%\n  filter(n &gt; 3) %&gt;%\n  graph_from_data_frame()\nbigram_graph\n\nIGRAPH 4934b7d DN-- 40 24 -- \n+ attr: name (v/c), n (e/n)\n+ edges from 4934b7d (vertex names):\n [1] 1          -&gt;2           1          -&gt;3           static     -&gt;void       \n [4] time       -&gt;pad         1          -&gt;4           infield    -&gt;fly        \n [7] mat        -&gt;28          vv         -&gt;vv          1          -&gt;5          \n[10] cock       -&gt;crow        noticeshell-&gt;widget      27         -&gt;1993       \n[13] 3          -&gt;4           child      -&gt;molestation cock       -&gt;crew       \n[16] gun        -&gt;violence    heat       -&gt;sink        homosexual -&gt;male       \n[19] homosexual -&gt;women       include    -&gt;xol         mary       -&gt;magdalene  \n[22] read       -&gt;write       rev        -&gt;20          tt         -&gt;ee         \n\n\n\n\nVisualizing a network of bigrams with ggraph\nggraph package is used to plot the bigram\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\nggraph(bigram_graph, layout = \"fr\") +\n  geom_edge_link() +\n  geom_node_point() +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1)\n\n\n\n\n\n\nRevised version\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\na &lt;- grid::arrow(type = \"closed\", \n                 length = unit(.15,\n                               \"inches\"))\n\nggraph(bigram_graph, \n       layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = n), \n                 show.legend = FALSE,\n                 arrow = a, \n                 end_cap = circle(.07,\n                                  'inches')) +\n  geom_node_point(color = \"lightblue\", \n                  size = 5) +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1) +\n  theme_void()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html",
    "title": "Hands-on Exercise 4 - Visualising Uncertainty",
    "section": "",
    "text": "Learning Objectives:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 4 - Visualising Uncertainty",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nThe following R packages will be used:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\nCode chunk below will be used to check if these packages have been installed and also will load them into the working R environment.\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#importing-the-data",
    "title": "Hands-on Exercise 4 - Visualising Uncertainty",
    "section": "Importing the Data",
    "text": "Importing the Data\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\nreadr is a pacakge within tidyverse.\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\nexam_data tibble data frame contains:\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on Exercise 4 - Visualising Uncertainty",
    "section": "Visualizing the uncertainty of point estimates: ggplot2 methods",
    "text": "Visualizing the uncertainty of point estimates: ggplot2 methods\nA point estimate is a single number, e.g., mean. Uncertainty, is expressed as standard error, confidence interval, or credible interval.\nThe code chunk below will be used to derive the necessary summary statistics.\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\nThe code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nTableCode\n\n\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\nknitr::kable(head(my_sum), format = 'html')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#plotting-standard-error-bars-of-point-estimates",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#plotting-standard-error-bars-of-point-estimates",
    "title": "Hands-on Exercise 4 - Visualising Uncertainty",
    "section": "Plotting standard error bars of point estimates",
    "text": "Plotting standard error bars of point estimates\nThe code chunk belows plots the standard error bars of mean maths score by race.\nNote:\n\nThe error bars are computed by using the formula mean+/-se.\nFor geom_point(), it is important to indicate stat=“identity”.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#plotting-confidence-interval-of-point-estimates",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#plotting-confidence-interval-of-point-estimates",
    "title": "Hands-on Exercise 4 - Visualising Uncertainty",
    "section": "Plotting confidence interval of point estimates",
    "text": "Plotting confidence interval of point estimates\nInstead of plotting the standard error bar of point estimates, the confidence intervals of mean maths score by race can also be plotted.\nNote:\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se.\nThe error bars is sorted by using the average maths scores.\nlabs() argument of ggplot2 is used to change the x-axis label.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visualizing-the-uncertainty-of-point-estimates-with-interactive-error-bars",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visualizing-the-uncertainty-of-point-estimates-with-interactive-error-bars",
    "title": "Hands-on Exercise 4 - Visualising Uncertainty",
    "section": "Visualizing the uncertainty of point estimates with interactive error bars",
    "text": "Visualizing the uncertainty of point estimates with interactive error bars\nThe code chunk below plots interactive error bars for the 99% confidence interval of mean maths score by race.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visualising-uncertainty-ggdist-package",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visualising-uncertainty-ggdist-package",
    "title": "Hands-on Exercise 4 - Visualising Uncertainty",
    "section": "Visualising Uncertainty: ggdist package",
    "text": "Visualising Uncertainty: ggdist package\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods",
    "title": "Hands-on Exercise 4 - Visualising Uncertainty",
    "section": "Visualizing the uncertainty of point estimates: ggdist methods",
    "text": "Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nIn the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median\n.interval = qi\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\nThe plot below shows 95% and 99% confidence intervals\n\nstat_pointinterval is used twice, once for each confidence interval.\nThe .width argument specifies the width of the intervals.\nThe .point argument specifies that we want to plot the median.\nThe .interval argument is set to “quantile” to indicate quantile-based intervals.\nscale_colour_manual is used to set custom colors for the confidence intervals and provide custom labels.\nOther aesthetic adjustments are made to improve the appearance of the plot, such as adjusting the size and position of the intervals.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(\n    .width = 0.95,\n    .point = \"median\",\n    .interval = \"quantile\",\n    aes(colour = \"95% CI\")) +\n  stat_pointinterval(\n    .width = 0.99,\n    .point = \"median\",\n    .interval = \"quantile\",\n    aes(colour = \"99% CI\")) +\n  scale_colour_manual(\n    values = c(\"95% CI\" = \"blue\", \"99% CI\" = \"red\"),\n    labels = c(\"95% CI\", \"99% CI\")) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\") +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods-1",
    "title": "Hands-on Exercise 4 - Visualising Uncertainty",
    "section": "Visualizing the uncertainty of point estimates: ggdist methods",
    "text": "Visualizing the uncertainty of point estimates: ggdist methods\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visualising-the-uncertainty-of-point-estimates-ggdist-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visualising-the-uncertainty-of-point-estimates-ggdist-methods",
    "title": "Hands-on Exercise 4 - Visualising Uncertainty",
    "section": "Visualising the uncertainty of point estimates: ggdist methods",
    "text": "Visualising the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands-on Exercise 4 - Visualising Uncertainty",
    "section": "Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "title": "Hands-on Exercise 4 - Visualising Uncertainty",
    "section": "Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html",
    "title": "Hands-on Exercise 3 - Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "Learning Objectives:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#terminology",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#terminology",
    "title": "Hands-on Exercise 3 - Programming Animated Statistical Graphics with R",
    "section": "Terminology",
    "text": "Terminology\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The settings that control how the animation behaves. For example:\n\nDuration of each frame\nEasing function used between frame transitions\nStart the animation from the current frame or from the beginning"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 3 - Programming Animated Statistical Graphics with R",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nThe following R packages will be used:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#importing-the-data",
    "title": "Hands-on Exercise 3 - Programming Animated Statistical Graphics with R",
    "section": "Importing the Data",
    "text": "Importing the Data\n\nThe code chunk below imports GlobalPopulation.xlsx into R environment by using read_xls() function of readr package.\nreadr is a pacakge within tidyverse.\n\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\n\n\nTip\n\n\n\nInstead of using mutate_at(), across() can be used to derive the same output"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#building-a-static-population-bubble-plot",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#building-a-static-population-bubble-plot",
    "title": "Hands-on Exercise 3 - Programming Animated Statistical Graphics with R",
    "section": "Building a static population bubble plot",
    "text": "Building a static population bubble plot\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#building-the-animated-bubble-plot",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#building-the-animated-bubble-plot",
    "title": "Hands-on Exercise 3 - Programming Animated Statistical Graphics with R",
    "section": "Building the animated bubble plot",
    "text": "Building the animated bubble plot\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics.\n\nThe default is linear.\nOther methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#building-an-animated-bubble-plot-ggplotly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#building-an-animated-bubble-plot-ggplotly-method",
    "title": "Hands-on Exercise 3 - Programming Animated Statistical Graphics with R",
    "section": "Building an animated bubble plot: ggplotly() method",
    "text": "Building an animated bubble plot: ggplotly() method\nCreate an animated bubble plot by using ggplotly() method.\n\nAppropriate ggplot2 functions are used to create a static bubble plot. The output is then saved as an R object called gg.\nggplotly() is then used to convert the R graphic object into an animated svg object.\n\nAlthough show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#building-an-animated-bubble-plot-plot_ly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#building-an-animated-bubble-plot-plot_ly-method",
    "title": "Hands-on Exercise 3 - Programming Animated Statistical Graphics with R",
    "section": "Building an animated bubble plot: plot_ly() method",
    "text": "Building an animated bubble plot: plot_ly() method\nCreate an animated bubble plot by using plot_ly() method.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2 - Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "Learning Objectives:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 2 - Beyond ggplot2 Fundamentals",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nBesides tidyverse, the following R packages will be used.\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nCode chunk below will be used to check if these packages have been installed and also will load them into the working R environment.\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-the-data",
    "title": "Hands-on Exercise 2 - Beyond ggplot2 Fundamentals",
    "section": "Importing the Data",
    "text": "Importing the Data\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\nreadr is a pacakge within tidyverse.\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nexam_data tibble data frame contains:\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggrepel",
    "title": "Hands-on Exercise 2 - Beyond ggplot2 Fundamentals",
    "section": "Working with ggrepel",
    "text": "Working with ggrepel\nggrepel is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text seen below. Simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBenefits of ggplot2 over in-built R graphics\n\nAutomated Legends: Unlike built-in plotting which requires manual legend creation, ggplot2 automatically generates legends based on the data’s aesthetics. This streamlines the process, especially for beginners who may find managing legends challenging.\nSimplified Faceting: ggplot2 simplifies the creation of faceted plots (multiple subplots) compared to base R plotting. The latter can be quite complex, requiring setup with par() and potentially confusing for loops, which might be overwhelming for beginners.\nTidy Data Integration: ggplot2 encourages the use of ‘tidy data’ principles, aligning with how other R tools and packages handle data. This practice helps beginners learn a consistent and widely-adopted approach to data analysis in R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggtheme-package",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggtheme-package",
    "title": "Hands-on Exercise 2 - Beyond ggplot2 Fundamentals",
    "section": "Working with ggtheme package",
    "text": "Working with ggtheme package\nggthemes provides ‘ggplot2’ themes that replicate the look of plots made by:\n\nFivethirtyeight\nThe Economist\nThe Wall Street Journal\namong others\n\nThe Economist theme is used below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-hrbthems-package",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-hrbthems-package",
    "title": "Hands-on Exercise 2 - Beyond ggplot2 Fundamentals",
    "section": "Working with hrbthems package",
    "text": "Working with hrbthems package\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe second goal centers around productivity for a production workflow, which is the context for where the elements of hrbrthemes should be used.\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15\ngrid argument is used to remove the x-axis grid lines"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plot-1-distribution-of-math-scores-histogram",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plot-1-distribution-of-math-scores-histogram",
    "title": "Hands-on Exercise 2 - Beyond ggplot2 Fundamentals",
    "section": "Plot 1: Distribution of Math Scores (Histogram)",
    "text": "Plot 1: Distribution of Math Scores (Histogram)\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plot-2-distribution-of-english-scores-histogram",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plot-2-distribution-of-english-scores-histogram",
    "title": "Hands-on Exercise 2 - Beyond ggplot2 Fundamentals",
    "section": "Plot 2: Distribution of English Scores (Histogram)",
    "text": "Plot 2: Distribution of English Scores (Histogram)\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plot-3-english-vs-maths-score-scatterplot",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plot-3-english-vs-maths-score-scatterplot",
    "title": "Hands-on Exercise 2 - Beyond ggplot2 Fundamentals",
    "section": "Plot 3: English vs Maths score (Scatterplot)",
    "text": "Plot 3: English vs Maths score (Scatterplot)\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English vs Maths scores for Primary 3\")\n\np3"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-composite-graphics-pathwork-methods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-composite-graphics-pathwork-methods",
    "title": "Hands-on Exercise 2 - Beyond ggplot2 Fundamentals",
    "section": "Creating Composite Graphics: pathwork methods",
    "text": "Creating Composite Graphics: pathwork methods\nggplot2 extension’s functions support composite figures by combining several graphs e.g., grid.arrange() of gridExtra package and plot_grid() of cowplot package.\nThis section uses a ggplot2 extension called patchwork, specially designed for combining separate ggplot2 graphs into a single figure.\nPatchwork package has a very simple syntax to create layouts. General syntax:\n\nPlus Sign “+” - Two-Column Layout\nParenthesis “( )” - Create a subplot group.\nDivision Sign “/” - Two-Row Layout"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-two-ggplot2-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-two-ggplot2-graphs",
    "title": "Hands-on Exercise 2 - Beyond ggplot2 Fundamentals",
    "section": "Combining two ggplot2 graphs",
    "text": "Combining two ggplot2 graphs\nFigure in the tabset below shows a composite of two histograms (p1 & p2 from above) created using patchwork.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\np1 + p2\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote the syntax simplicity. i.e. p1 + p2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-three-ggplot2-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-three-ggplot2-graphs",
    "title": "Hands-on Exercise 2 - Beyond ggplot2 Fundamentals",
    "section": "Combining three ggplot2 graphs",
    "text": "Combining three ggplot2 graphs\nMore complex composites can be achieved by using appropriate operators. For example, the composite figure below uses:\n\n“/” - stack two ggplot2 graphs on top of another\n“|” - place the plots adjacent to each other\n“( )” - define plot sequence\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n(p1 / p2) | p3\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nRefer to Plot Assembly. for more modification and layout controls"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-with-tag",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-with-tag",
    "title": "Hands-on Exercise 2 - Beyond ggplot2 Fundamentals",
    "section": "Creating a composite figure with tag",
    "text": "Creating a composite figure with tag\npatchwork also provides auto-tagging capabilities to identify subplots in text, as shown in the figure below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote the I, II, III labels in the subplots have been automatically labelled."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-figure-with-insert",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-figure-with-insert",
    "title": "Hands-on Exercise 2 - Beyond ggplot2 Fundamentals",
    "section": "Creating figure with insert",
    "text": "Creating figure with insert\n inset_element() of patchwork, allows the placement of one or several plots or graphic elements freely on top or below another plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-by-using-patchwork-and-ggtheme",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-by-using-patchwork-and-ggtheme",
    "title": "Hands-on Exercise 2 - Beyond ggplot2 Fundamentals",
    "section": "Creating a composite figure by using patchwork and ggtheme",
    "text": "Creating a composite figure by using patchwork and ggtheme\npatchwork and theme_economist() of ggthemes package are used to create the figure below\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hello, my name is Alicia.\nHere is a quick introduction of me and my life.\n\n\n\n\n\n\n\n\n\nMy motivations for MITB\n\n\n\nChat with me on UniBuddy"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "",
    "text": "Learning Objectives:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nNote: Ensure that the pacman package has already been installed.\nThe code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R. Otherwise, tidyverse will be installed and launched into R.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Importing the Data",
    "text": "Importing the Data\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\nreadr is one of the tidyverse package.\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nexam_data contains:\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#a-layered-grammar-of-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#a-layered-grammar-of-graphics",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "A Layered Grammar of Graphics",
    "text": "A Layered Grammar of Graphics\nggplot2 is an implementation of Leland Wilkinson’s Grammar of Graphics.\nThere are seven grammars of ggplot2:\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_bar",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_bar",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Geometric Objects: geom_bar",
    "text": "Geometric Objects: geom_bar\nThe code chunk below plots a bar chart by using geom_bar().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_dotplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_dotplot",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Geometric Objects: geom_dotplot",
    "text": "Geometric Objects: geom_dotplot\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\nIn the code chunk below, geom_dotplot() of ggplot2 is used to plot a dot plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThe y scale is misleading and not very useful.\n\n\nThe code chunk below does the following:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_histogram",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_histogram",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Geometric Objects: geom_histogram()",
    "text": "Geometric Objects: geom_histogram()\nThe code chunk below, uses geom_histogram() create a simple histogram by using values in MATHS field of exam_data.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe default bin is 30"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-geom",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-geom",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Modifying a geometric object by changing geom()",
    "text": "Modifying a geometric object by changing geom()\nThe code chunk below, does the following:\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-aes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-aes",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Modifying a geometric object by changing aes()",
    "text": "Modifying a geometric object by changing aes()\nThe code chunk below changes the interior colour of the histogram (i.e. fill) by using sub-group of aesthetic().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis approach can be used to colour, fill and alpha of the geometric."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom-density",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom-density",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Geometric Objects: geom-density()",
    "text": "Geometric Objects: geom-density()\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\nThe code below plots the distribution of Maths scores in a kernel density estimate plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\n\n\n\nThe code chunk below plots two kernel density lines by using colour or fill arguments of aes()\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_boxplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_boxplot",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Geometric Objects: geom_boxplot",
    "text": "Geometric Objects: geom_boxplot\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\nThe code chunk below plots boxplots by using geom_boxplot().\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_violin",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_violin",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Geometric Objects: geom_violin",
    "text": "Geometric Objects: geom_violin\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_point",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_point",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Geometric Objects: geom_point()",
    "text": "Geometric Objects: geom_point()\ngeom_point() is especially useful for creating scatterplot.\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#combining-geom-objects",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#combining-geom-objects",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Combining geom objects",
    "text": "Combining geom objects\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Working with stat()",
    "text": "Working with stat()\nThe boxplots below are incomplete because the positions of the means were not shown.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-stat_summary-method",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-stat_summary-method",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Working with stat - the stat_summary() method",
    "text": "Working with stat - the stat_summary() method\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"red\",        \n               size=4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-geom-method",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-geom-method",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Working with stat - the geom() method",
    "text": "Working with stat - the geom() method\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun.y=\"mean\",           \n             colour =\"red\",          \n             size=4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#adding-a-best-fit-curve-on-a-scatterplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#adding-a-best-fit-curve-on-a-scatterplot",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Adding a best fit curve on a scatterplot",
    "text": "Adding a best fit curve on a scatterplot\nThe interpretability of scatterplots can be improved by adding a best fit curve. n the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe default method used is loess.\n\n\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-facet_wrap",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-facet_wrap",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Working with facet_wrap()",
    "text": "Working with facet_wrap()\nfacet_wrap wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\nThe code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#facet_grid-function",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#facet_grid-function",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "facet_grid() function",
    "text": "facet_grid() function\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-coordinate",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-coordinate",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Working with Coordinate",
    "text": "Working with Coordinate\nBy the default, the bar chart of ggplot2 is in vertical form.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\nThe code chunk below flips the horizontal bar chart into vertical bar chart by using coord_flip().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#changing-the-y--and-x-axis-range",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#changing-the-y--and-x-axis-range",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Changing the y- and x-axis range",
    "text": "Changing the y- and x-axis range\nThe scatterplot below is slightly misleading because the y-aixs and x-axis range are not equal.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5)\n\n\n\n\nThe code chunk below fixed both the y-axis and x-axis range from 0-100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-theme",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-theme",
    "title": "Hands-on Exercise 1 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "Working with theme",
    "text": "Working with theme\nThe code chunk below plot a horizontal bar chart using theme_gray().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\nA horizontal bar chart plotted using theme_classic().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\nA horizontal bar chart plotted using theme_minimal().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "Learning Objectives:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nThe following R packages will be used:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nCode chunk below will be used to check if these packages have been installed and also will load them into the working R environment.\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#importing-the-data",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "Importing the Data",
    "text": "Importing the Data\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\nreadr is a pacakge within tidyverse.\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nexam_data tibble data frame contains:\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#tooltip-effect-with-tooltip-aesthetic",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#tooltip-effect-with-tooltip-aesthetic",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "Tooltip effect with tooltip aesthetic",
    "text": "Tooltip effect with tooltip aesthetic\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. \nFirst, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#displaying-multiple-information-on-tooltip",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#displaying-multiple-information-on-tooltip",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "Displaying multiple information on tooltip",
    "text": "Displaying multiple information on tooltip\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7. By hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#customising-tooltop-style",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#customising-tooltop-style",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "Customising Tooltop style",
    "text": "Customising Tooltop style\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFor more customisations, refer to Customizing girafe objects"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#displaying-statistics-on-tooltip",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#displaying-statistics-on-tooltip",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "Displaying statistics on tooltip",
    "text": "Displaying statistics on tooltip\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#hover-effect-with-data_id-aesthetic",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#hover-effect-with-data_id-aesthetic",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "Hover effect with data_id aesthetic",
    "text": "Hover effect with data_id aesthetic\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\nElements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe default value of the hover css is hover_css = “fill:orange;”."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#styling-hover-effect",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#styling-hover-effect",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "Styling hover effect",
    "text": "Styling hover effect\nIn the code chunk below, css codes are used to change the highlighting effect.\nElements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#plot-1-combining-tooltip-and-hover-effect",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#plot-1-combining-tooltip-and-hover-effect",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "Plot 1: Combining tooltip and hover effect",
    "text": "Plot 1: Combining tooltip and hover effect\nThe tooltip and hover effects are combined in the interactive statistical graph in the code chunk below.\nElements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#click-effect-with-onclick",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#click-effect-with-onclick",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "Click effect with onclick",
    "text": "Click effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on the web. Web document link with a data object will be displayed on the web browser upon mouse click.\nThe code chunk below shown an example of onclick.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nClick actions must be a string column in the dataset containing valid javascript instructions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#coordinated-multiple-views-with-ggiraph",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#coordinated-multiple-views-with-ggiraph",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "Coordinated Multiple Views with ggiraph",
    "text": "Coordinated Multiple Views with ggiraph\nWhen a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#there-are-two-ways-to-create-interactive-graph-by-using-plotly-they-are",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#there-are-two-ways-to-create-interactive-graph-by-using-plotly-they-are",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "There are two ways to create interactive graph by using plotly, they are:",
    "text": "There are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#creating-an-interactive-scatter-plot-plot_ly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#creating-an-interactive-scatter-plot-plot_ly-method",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "Creating an interactive scatter plot: plot_ly() method",
    "text": "Creating an interactive scatter plot: plot_ly() method\nThe code chunk below shows an example a basic interactive plot created by using plot_ly().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#working-with-visual-variable-plot_ly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#working-with-visual-variable-plot_ly-method",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "Working with visual variable: plot_ly() method",
    "text": "Working with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#creating-an-interactive-scatter-plot-ggplotly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#creating-an-interactive-scatter-plot-ggplotly-method",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "Creating an interactive scatter plot: ggplotly() method",
    "text": "Creating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe only extra line you need to include in the code chunk is ggplotly()."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "Interactive Data Visualisation - crosstalk methods",
    "text": "Interactive Data Visualisation - crosstalk methods\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\nDT::datatable(exam_data, class= \"compact\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#linked-brushing-crosstalk-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_1.html#linked-brushing-crosstalk-method",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "Linked brushing: crosstalk method",
    "text": "Linked brushing: crosstalk method\nCode chunk below is used to implement coordinated brushing.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "",
    "text": "Learning Objectives:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nThe following R packages will be used:\n\nggstatsplotis an extension of ggplot2 package for creating graphics with details from statstical tests included in the plots themselces\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\nCode chunk below will be used to check if these packages have been installed and also will load them into the working R environment.\n\npacman::p_load(ggstatsplot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#importing-the-data",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "Importing the Data",
    "text": "Importing the Data\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\nreadr is a pacakge within tidyverse.\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\nexam_data tibble data frame contains:\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#one-sample-test-gghistostats-method",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#one-sample-test-gghistostats-method",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "One-sample test: gghistostats() method",
    "text": "One-sample test: gghistostats() method\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nset.seed(1234) # for reproducibility\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#unpacking-the-bayes-factor",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#unpacking-the-bayes-factor",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "Unpacking the Bayes Factor",
    "text": "Unpacking the Bayes Factor\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. i.e., a measure of the strength of evidence in favor of one theory among two competing theories.\nBayes factor allows evaluation of the data in favor of a null hypothesis, and to use external information to do so. It gives the weight of the evidence in favor of a given hypothesis.\nWhen comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10, defined mathematically as:\n\\(\\frac{likelihood of data given H_{1}}{likelihood of data given H_{0}} = \\frac{P(D|H_{1})}{P(D|H_{0})}\\)\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\nInterpreting Bayes Factor\nA Bayes Factor can be any positive number. A common interpretation was first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\nB10 Value\nConclusion\n\n\n\n\n&gt;100\nExtreme evidence for H1\n\n\n30-100\nVery strong evidence for H1\n\n\n10-30\nStrong evidence for H1\n\n\n3-10\nModerate evidence for H1\n\n\n1-3\nAnecdotal evidence for H1\n\n\n1\nNo evidence\n\n\n1/3-1\nAnecdotal evidence for H1\n\n\n1/3-1/10\nModerate evidence for H1\n\n\n1/10-1/30\nStrong evidence for H1\n\n\n1/30-1/100\nVery strong evidence for H1\n\n\n&lt;1/100\nExtreme evidence for H1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#two-sample-mean-test-ggbetweenstats",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#two-sample-mean-test-ggbetweenstats",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "Two-sample mean test: ggbetweenstats()",
    "text": "Two-sample mean test: ggbetweenstats()\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#oneway-anova-test-ggbetweenstats-method",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#oneway-anova-test-ggbetweenstats-method",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "Oneway ANOVA Test: ggbetweenstats() method",
    "text": "Oneway ANOVA Test: ggbetweenstats() method\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\nggbetweenstats - Summary of tests\nFollowing (between-subjects) tests are carried out for each type of analyses:\n\n\n\n\n\n\n\n\nType\nNo. of groups\nTest\n\n\n\n\nParametric\n&gt;2\nFisher’s or Welch’s one-way ANOVA\n\n\nNon-parametric\n&gt;2\nKruskal-Wallis one-way ANOVA\n\n\nRobust\n&gt;2\nHeteroscedastic one-way ANOVA for trimmed means\n\n\nBayes Factor\n&gt;2\nFisher’s ANOVA\n\n\nParametric\n2\nStudent’s or Welch’s t-test\n\n\nNon-parametric\n2\nMann-Whitney U test\n\n\nRobust\n2\nYuen’s test for trimmed means\n\n\nBayes Factor\n2\nStudent’s t-test\n\n\n\nFollowing effect sizes (and confidence intervals) are available for each type of test:\n\n\n\n\n\n\n\n\n\nType\nNo. of Groups\nEffect Size\nConfidence Intervals\n\n\n\n\nParametric\n&gt;2\n\\({\\eta^2}_{p},\\eta^2,{\\omega^2}_{p},\\omega^2\\)\nYes\n\n\nNon-parametric\n&gt;2\n\\({\\eta^2}_{H}\\) (H-statistic based eta-squared)\nYes\n\n\nRobust\n&gt;2\n\\(\\xi\\) (Explanatory measure of effect size)\nYes\n\n\nBayes Factor\n&gt;2\nNo\nNo\n\n\nParametric\n2\nCohen’s d, Hedge’s g (central-and-noncentral-t distribution based)\nYes\n\n\nNon-parametric\n2\nr (computed as \\(Z/\\sqrt{N}\\))\nYes\n\n\nRobust\n2\n\\(\\xi\\) (Explanatory measure of effect size)\nYes\n\n\nBayes Factor\n2\nNo\nNo\n\n\n\nSummary of pairwise comparison tests supported in ggbetweenstats\n\n\n\n\n\n\n\n\n\nType\nEqual Variance\nTest\np-value Adjustment?\n\n\n\n\nParametric\nNo\nGames Howell Test\nYes\n\n\nParametric\nYes\nStudent’s t Test\nYes\n\n\nNon-Parametric\nNo\nDunn Test\nYes\n\n\nRobust\nNo\nYuen’s Trimmed Means Test\nYes\n\n\nBayes Factor\nNA\nStudent’s t Test\nNA"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#significant-test-of-correlation-ggscatterstats",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#significant-test-of-correlation-ggscatterstats",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "Significant Test of Correlation: ggscatterstats()",
    "text": "Significant Test of Correlation: ggscatterstats()\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#significant-test-of-association-depedence-ggbarstats-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#significant-test-of-association-depedence-ggbarstats-methods",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "Significant Test of Association (Depedence) : ggbarstats() methods",
    "text": "Significant Test of Association (Depedence) : ggbarstats() methods\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut(). ggbarstats() is used to build a visual for Significant Test of Association\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#visualising-models",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#visualising-models",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "Visualising Models",
    "text": "Visualising Models\nVisualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#installing-and-loading-the-required-libraries-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#installing-and-loading-the-required-libraries-1",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\n\npacman::p_load(readxl, performance, parameters, see)\n\n\nImporting Excel file: readxl methods\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#multiple-regression-model-using-lm",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#multiple-regression-model-using-lm",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "Multiple Regression Model using lm()",
    "text": "Multiple Regression Model using lm()\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#model-diagnostic-checking-for-multicolinearity",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#model-diagnostic-checking-for-multicolinearity",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "Model Diagnostic: checking for multicolinearity:",
    "text": "Model Diagnostic: checking for multicolinearity:\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#model-diagnostic-checking-normality-assumption",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#model-diagnostic-checking-normality-assumption",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "Model Diagnostic: checking normality assumption",
    "text": "Model Diagnostic: checking normality assumption\nIn the code chunk, check_normality() of performance package.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\ncheck_n &lt;- check_normality(model1)\n\nplot(check_n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#model-diagnostic-check-model-for-homogeneity-of-variances",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#model-diagnostic-check-model-for-homogeneity-of-variances",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "Model Diagnostic: Check model for homogeneity of variances",
    "text": "Model Diagnostic: Check model for homogeneity of variances\nIn the code chunk, check_heteroscedasticity() of performance package.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ncheck_h &lt;- check_heteroscedasticity(model1)\nplot(check_h)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#model-diagnostic-complete-check",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#model-diagnostic-complete-check",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "Model Diagnostic: Complete check",
    "text": "Model Diagnostic: Complete check\nWe can also perform the complete by using check_model().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ncheck_model(model1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#visualising-regression-parameters-see-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#visualising-regression-parameters-see-methods",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "Visualising Regression Parameters: see methods",
    "text": "Visualising Regression Parameters: see methods\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nplot(parameters(model1))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#visualising-regression-parameters-ggcoefstats-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#visualising-regression-parameters-ggcoefstats-methods",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis",
    "section": "Visualising Regression Parameters: ggcoefstats() methods",
    "text": "Visualising Regression Parameters: ggcoefstats() methods\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html",
    "title": "Hands-on Exercise 4 - Funnel Plots for Fair Comparisons",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities.\nLearning Objectives:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 4 - Funnel Plots for Fair Comparisons",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nThe following R packages will be used:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\nCode chunk below will be used to check if these packages have been installed and also will load them into the working R environment.\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#importing-the-data",
    "title": "Hands-on Exercise 4 - Funnel Plots for Fair Comparisons",
    "section": "Importing the Data",
    "text": "Importing the Data\nThe COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal.\nFor this hands-on exercise, compares the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#funnelplotr-methods-the-basic-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#funnelplotr-methods-the-basic-plot",
    "title": "Hands-on Exercise 4 - Funnel Plots for Fair Comparisons",
    "section": "FunnelPlotR methods: The basic plot",
    "text": "FunnelPlotR methods: The basic plot\nThe code chunk below plots a funnel plot.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\nPlotCode\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = `Positive`,\n  denominator = `Death`,\n  group = `Sub-district`\n)\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. Plot is adjusted for overdispersion."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#funnelplotr-methods-makeover-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#funnelplotr-methods-makeover-1",
    "title": "Hands-on Exercise 4 - Funnel Plots for Fair Comparisons",
    "section": "FunnelPlotR methods: Makeover 1",
    "text": "FunnelPlotR methods: Makeover 1\nThe code chunk below plots a funnel plot.\n\ndata_type argument is used to change from default “SR” to “PR” (i.e. proportions).\nx_range and y_range are used to set the range of x-axis and y-axis\n\n\nPlotCode\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = `Death`,\n  denominator = `Positive`,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  x_range = c(0, 6500),  #&lt;&lt;\n  y_range = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. Plot is adjusted for overdispersion."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#funnelplotr-methods-makeover-2",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#funnelplotr-methods-makeover-2",
    "title": "Hands-on Exercise 4 - Funnel Plots for Fair Comparisons",
    "section": "FunnelPlotR methods: Makeover 2",
    "text": "FunnelPlotR methods: Makeover 2\nThe code chunk below plots a funnel plot.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles.\n\n\nPlotCode\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = `Death`,\n  denominator = `Positive`,\n  group = `Sub-district`,\n  data_type = \"PR\",\n  x_range = c(0, 6500),  \n  y_range = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)    \n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. Plot is adjusted for overdispersion."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#computing-the-basic-derived-fields",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#computing-the-basic-derived-fields",
    "title": "Hands-on Exercise 4 - Funnel Plots for Fair Comparisons",
    "section": "Computing the basic derived fields",
    "text": "Computing the basic derived fields\nFirst, derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#calculate-lower-and-upper-limits-for-95-and-99.9-ci",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#calculate-lower-and-upper-limits-for-95-and-99.9-ci",
    "title": "Hands-on Exercise 4 - Funnel Plots for Fair Comparisons",
    "section": "Calculate lower and upper limits for 95% and 99.9% CI",
    "text": "Calculate lower and upper limits for 95% and 99.9% CI\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#plotting-a-static-funnel-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#plotting-a-static-funnel-plot",
    "title": "Hands-on Exercise 4 - Funnel Plots for Fair Comparisons",
    "section": "Plotting a static funnel plot",
    "text": "Plotting a static funnel plot\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#interactive-funnel-plot-plotly-ggplot2",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#interactive-funnel-plot-plotly-ggplot2",
    "title": "Hands-on Exercise 4 - Funnel Plots for Fair Comparisons",
    "section": "Interactive Funnel Plot: plotly + ggplot2",
    "text": "Interactive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "",
    "text": "Learning Objectives:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nThe following R packages will be used:\n\nigraph\ntidygraph\nggraph\nvisNetwork\ntidyverse\nlubridate\n\nCode chunk below will be used to check if these packages have been installed and also will load them into the working R environment.\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-data",
    "title": "Hands-on Exercise 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "The Data",
    "text": "The Data\nThe data sets used are from an oil exploration and extraction company. There are two data sets:\n\nNodes data: GAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\nedges (aka link) data: GAStech_email_nodes.csv which consist of the names, department and title of the 55 employees.\n\n\nImporting network data from files\nImport GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using read_csv() of readr package.\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\nReviewing the imported data\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\nWrangling time\nThe output report of GAStech_edges below reveals that the SentDate is treated as “Character” data type instead of date data type, which is incorrect. Thus, the data type of SentDate field needs to be changed to “Date”” data type.\nNote:\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\nReviewing the revised date fields\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\n\nWrangling attributes\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records, which is not very useful for visualisation.\nThus, aggregation is done for the individual by date, senders, receivers, main subject and day of the week.\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\nReviewing the revised edges file\n\nglimpse(GAStech_edges_aggregated)\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-network-objects-using-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-network-objects-using-tidygraph",
    "title": "Hands-on Exercise 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "Creating network objects using tidygraph",
    "text": "Creating network objects using tidygraph\n tidygraph package provides a tidy API for graph/network manipulation. Network data can be envisioned as 2 tidy tables, 1 for node data and 1 for edge data.\ntidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. It is also provides access to many graph algorithms with return values that facilitate their use in a tidy workflow.\n\nThe tbl_graph object\ntidygraph can be used to create network objects:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\nThe dplyr verbs in tidygraph\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n.N() function is used to gain access to the node data while manipulating the edge data. E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\n\nUsing tbl_graph() to build tidygraph data model.\nuse tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\nReviewing the output tidygraph’s graph object\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\n\nReviewing the output tidygraph’s graph object\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\nChanging the active object\nThe nodes tibble data frame is activated by default, but it can be changed with the activate() function. To rearrange the rows in the edges tibble to list those with the highest “weight” first, use activate() and then arrange().\n\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-static-network-graphs-with-ggraph-package",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-static-network-graphs-with-ggraph-package",
    "title": "Hands-on Exercise 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "Plotting Static Network Graphs with ggraph package",
    "text": "Plotting Static Network Graphs with ggraph package\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nThere are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\nedges and\nlayouts\n\n\nPlotting a basic network graph\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. \n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired.\nBoth of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\nChanging the default network graph theme\nUse theme_graph() to remove the x and y axes.\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\nChanging the coloring of the plot\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\nWorking with ggraph’s layouts\nggraph supports many standard layouts: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\nFruchterman and Reingold layout\nPlot the network graph using Fruchterman and Reingold layout.\n\nlayout argument is used to define the layout to be used.\n\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\nModifying network nodes\ncolour each node by referring to their respective departments\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes.\n\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\nModifying edges\nThe thickness of the edges will be mapped with the Weight variable.\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line.\n\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-facet-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-facet-graphs",
    "title": "Hands-on Exercise 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "Creating facet graphs",
    "text": "Creating facet graphs\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\nWorking with facet_edges()\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\nWorking with facet_edges()\nuses theme() to change the position of the legend\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\nA framed facet graph\nAdd frame to each graph\n\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\nWorking with facet_nodes()\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#network-metrics-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#network-metrics-analysis",
    "title": "Hands-on Exercise 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "Network Metrics Analysis",
    "text": "Network Metrics Analysis\n\nComputing centrality indices\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here.\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\nVisualising network metrics\nFrom ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\nVisualising Community\ntidygraph package inherits many of the community detection algorithms imbedded into igraph, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal).\ngroup_edge_betweenness() is used below\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#building-interactive-network-graph-with-visnetwork",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#building-interactive-network-graph-with-visnetwork",
    "title": "Hands-on Exercise 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "Building Interactive Network Graph with visNetwork",
    "text": "Building Interactive Network Graph with visNetwork\n\nvisNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nResulting graph:\n\nThe nodes can be moved and the graph will use an algorithm to keep the nodes properly spaced.\nThe plot can be moved around to be re-centered, zoomed in and out.\n\n\n\nData preparation\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\nPlotting the first interactive network graph\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\nWorking with layout\nFruchterman and Reingold layout is used.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\n\nWorking with visual attributes - Nodes\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nrename Department field to group\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\nvisNetwork shades the nodes by assigning unique colour to each category in the group field.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\nWorking with visual attributes - Edges\nvisEdges() is used to symbolise the edges.\n\nThe argument arrows is used to define where to place the arrow.\nThe smooth argument is used to plot the edges using a smooth curve.\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\nInteractivity\nvisOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_1.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_1.html",
    "title": "Hands-on Exercise 8 Part I - Choropleth Mapping with R",
    "section": "",
    "text": "Learning Objectives:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_1.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_1.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 8 Part I - Choropleth Mapping with R",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nThe following R packages will be used:\n\nTidyverse:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\n\nsf for handling geospatial data\ntmap for plotting choropleth maps\n\nCode chunk below will be used to check if these packages have been installed and also will load them into the working R environment.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_1.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_1.html#importing-data-into-r",
    "title": "Hands-on Exercise 8 Part I - Choropleth Mapping with R",
    "section": "Importing Data into R",
    "text": "Importing Data into R\n\nThe Data\nTwo data sets will be used to create the choropleth map:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format downloaded from data.gov.sg This geospatial data consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data file downloaded from Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\nImporting Geospatial Data into R\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\lnealicia\\ISSS608\\Hands-on_Ex\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\nExamining the data content\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\nImporting Attribute Data into R\nUse read_csv() function of readr package to import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\nData Preparation\nBefore a thematic map can be prepared, a data table with year 2020 values needs to be prepped. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\nData wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\nJoining the attribute data and geospatial data\nThe values of PA and SZ fields are a mix of upper and lower case. However, the values of SUBZONE_N and PLN_AREA_N are in upper case. Thus, we convert those of PA and SZ to uppercase, before we proceed with the join.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nleft_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\n\n\n\n\n\nNote\n\n\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nSave output into rds file\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\n\n\n\nChoropleth Mapping Geospatial Data Using tmap\nTwo approaches can be used to prepare thematic map using tmap:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\nPlotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\n\n\nCreating a choropleth map by using tmap’s elements\nTo draw a high quality and highly customisable cartographic choropleth map, tmap’s drawing elements should be used.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\nDrawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\nDrawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, the target variable such as Dependency needs to be assigned to tm_polygons().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe default interval binning used to draw the choropleth map is called “pretty”.\nThe default colour scheme used is YlOrRd of ColorBrewer.\nBy default, Missing value will be shaded in grey.\n\n\n\n\nDrawing a choropleth map using tm_fill() and tm_border()\ntm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone. Note that the planning subzones are shared according to the respective dependecy values.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_borders will be used to add the boundary of the planning subzones.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that light-gray border lines have been added to the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value is 1.\nBesides alpha argument, there are three other arguments for tm_borders():\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n\n\nData classification methods of tmap\nMost choropleth maps employ some methods of data classification to take a large number of observations and group them into data ranges or classes.\ntmap provides a ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() is used.\n\nPlotting choropleth maps with built-in classification methods\nThe code chunk below shows a quantile data classification with 5 classes.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nIn the code chunk below, the equal data classification method is used.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTthe distribution of quantile data classification method are more evenly distributed then equal data classification method\n\n\n\n\nPlotting choropleth map with custome break\nFor all built-in styles, category breaks are computed internally. To override these defaults, the breakpoints can be set explicitly using the breaks argument to the tm_fill().\nNote: tmap breaks include a minimum and maximum. Thus, to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nCode chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field in order to get descriptive statistics on the variable to aid setting break points.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nThe choropleth map is plotted with the above values by the code chunk below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nColour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\nUsing ColourBrewer palette\nTo change the colour, assign the preferred colour to palette argument of tm_fill()\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nTo reverse the colour shading, add a “-” prefix.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nMap Layouts\nMap layout refers to the combination of all map elements into a cohensive map. Map elements includes: objects to be mapped, title, scale bar, compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\nMap Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMap style\ntmap allows a wide variety of layout settings to be changed using tmap_style().\nThe code chunk below shows the classic style.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\nCartographic Furniture\nBeside map style, tmap also also draws other map furniture e.g., compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nTo reset the default style\n\ntmap_style(\"white\")\n\n\n\n\nDrawing Small Multiple Choropleth Maps\nSmall multiple maps, aka facet maps, are composed of many maps arranged side-by-side, and/or stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, e.g. time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments\nby defining a group-by variable in tm_facets()\nby creating multiple stand-alone maps with tmap_arrange().\n\n\nAssigning multiple values to at least one of the aesthetic arguments\nSmall multiple choropleth maps are created by defining ncols in tm_fill()\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\nsmall multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\nDefining a group-by variable in tm_facets()\nmultiple small choropleth maps are created by using tm_facets().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=FALSE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nCreating multiple stand-alone maps with tmap_arrange()\nmultiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\nMappping Spatial Object Meeting a Selection Criterion\nUse selection funtion to map spatial objects meeting the selection criterion.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html",
    "title": "Hands-on Exercise 8 Part III - Analytical Mapping",
    "section": "",
    "text": "Learning Objectives:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 8 Part III - Analytical Mapping",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nThe following R packages will be used:\n\nTidyverse:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\n\nsf for handling geospatial data\ntmap for plotting choropleth maps\n\nCode chunk below will be used to check if these packages have been installed and also will load them into the working R environment.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\nImporting data\n A data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\nThe code chunk below uses read_rds() function of readr package to import NGA_wp.rds into R as a tibble data frame called NGA_wp.\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#basic-choropleth-mapping",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#basic-choropleth-mapping",
    "title": "Hands-on Exercise 8 Part III - Analytical Mapping",
    "section": "Basic Choropleth Mapping",
    "text": "Basic Choropleth Mapping\n\nVisualising distribution of non-functional water point\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\np1 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside = FALSE)\n\np2 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total  water point by LGAs\",\n            legend.outside = FALSE)\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#choropleth-map-for-rates",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#choropleth-map-for-rates",
    "title": "Hands-on Exercise 8 Part III - Analytical Mapping",
    "section": "Choropleth Map for Rates",
    "text": "Choropleth Map for Rates\nAs water points are not equally distributed in space, map rates are more important than the count. If the location of the water points are not considered, total water point size will be mapped instead of the topic of interest.\n\nDeriving Proportion of Functional Water Points and Non-Functional Water Points\nIn the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#plotting-map-of-rate",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#plotting-map-of-rate",
    "title": "Hands-on Exercise 8 Part III - Analytical Mapping",
    "section": "Plotting map of rate",
    "text": "Plotting map of rate\nChoropleth map showing the distribution of percentage functional water point by LGA\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#extreme-value-maps",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_3.html#extreme-value-maps",
    "title": "Hands-on Exercise 8 Part III - Analytical Mapping",
    "section": "Extreme Value Maps",
    "text": "Extreme Value Maps\nExtreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\nPercentile Map\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note: the begin and endpoint need to be included.\n\nData Preparation\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen variables are extracted from an sf data.frame, the geometry is also extracted. For mapping and spatial manipulation, many base R functions cannot deal with the geometry. e.g., quantile() gives an error. Thus, st_set_geomtry(NULL) is used to drop geomtry field.\n\n\n\n\nCreating the get.var function\nFirstly, an R function as is written to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\nA percentile mapping function\nNext, a percentile mapping function is written by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\nTest drive the percentile mapping function\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAdditional arguments e.g., title, legend positioning can be passed to customise various features of the map.\n\n\n\n\n\nBox map\nA box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence.\nWhen there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\nCreating the boxbreaks function\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\nCreating the get.var function\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\nTest drive the newly created function\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\nBoxmap function\nThe code chunk below is an R function to create a box map. Arguments include:\n\nvnam: variable name (as character, in quotes)\ndf: simple features polygon layer\nlegtitle: legend title\nmtitle: map title\nmult: multiplier for IQR\nreturns: a tmap-element (plots a map)\n\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html",
    "title": "In-Class Exercise 2 - Visualising Distribution",
    "section": "",
    "text": "Statistical graphic methods for visualising distribution using ggplot2 and its extensions for:\n\nRidgeline plot\nRaincloud plot"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#loading-r-packages",
    "title": "In-Class Exercise 2 - Visualising Distribution",
    "section": "Loading R packages",
    "text": "Loading R packages\nNote: Ensure that the pacman package has already been installed.\nThe code chunk below uses p_load() of pacman package to load the tidyverse family of packages.\n\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots,\nggdist, a ggplot2 extension spacially desgin for visualising distribution and uncertainty,\ntidyverse, a family of R packages to meet the modern data science and visual communication needs,\nggthemes, a ggplot extension that provides the user additional themes, scales, and geoms for the ggplots package, and\ncolorspace, an R package provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualisations.\n\n\npacman::p_load(ggdist, ggridges, ggthemes, colorspace, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#importing-the-data",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#importing-the-data",
    "title": "In-Class Exercise 2 - Visualising Distribution",
    "section": "Importing the Data",
    "text": "Importing the Data\n\nThe code chunk below imports Exam_data.csv into R environment by using read_csv() function of readr package.\nreadr is one of the tidyverse package.\n\n\nexam_df &lt;- read_csv(\"data/Exam_data.csv\")\n\nexam_data contains:\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#varying-fill-colours-along-the-x-axis",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#varying-fill-colours-along-the-x-axis",
    "title": "In-Class Exercise 2 - Visualising Distribution",
    "section": "Varying Fill Colours along the X-axis",
    "text": "Varying Fill Colours along the X-axis\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis.\nTo achieve varying fill colours:\n\ngeom_ridgeline_gradient()\ngeom_density_ridges_gradient()\n\nHowever, they do not allow for alpha transparency.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(exam_df, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [°C]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English Grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#mapping-probabilities-directly-onto-colour",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#mapping-probabilities-directly-onto-colour",
    "title": "In-Class Exercise 2 - Visualising Distribution",
    "section": "Mapping Probabilities directly onto colour",
    "text": "Mapping Probabilities directly onto colour\nStat function called stat_density_ridges() replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(exam_df,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nInclude the argument calc_ecdf = TRUE in stat_density_ridges()!\n\n\n\nRidgeline Plots with Quantile Lines\nRidgeline plots can be coloured by quantile using geom_density_ridges_gradient(), via the calculated stat(quantile) \n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(exam_df,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\nQuantiles can also be specified by cut points e.g. 2.5% and 97.5% tails to colour the ridgeline plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(exam_df,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#plotting-a-half-eye-graph",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#plotting-a-half-eye-graph",
    "title": "In-Class Exercise 2 - Visualising Distribution",
    "section": "Plotting a Half Eye graph",
    "text": "Plotting a Half Eye graph\nPlot a Half-Eye graph by using stat_halfeye() of ggdist package, producing a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nRemove the slab interval by setting .width = 0 and point_colour = NA."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#adding-the-boxplot",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#adding-the-boxplot",
    "title": "In-Class Exercise 2 - Visualising Distribution",
    "section": "Adding the boxplot",
    "text": "Adding the boxplot\nThe second geometry layer i.e. a narrow boxplot is produced using geom_boxplot() of ggplot2 This produces a narrow boxplot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(exam_df, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#adding-the-dot-plots",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#adding-the-dot-plots",
    "title": "In-Class Exercise 2 - Visualising Distribution",
    "section": "Adding the Dot Plots",
    "text": "Adding the Dot Plots\nThe third geometry layer is added using stat_dots() of ggdist package. This produces a half-dotplot, similar to a histogram that indicates the number of samples (number of dots) in each bin. Use side = “left” to specify the dot plots on the left-hand side.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(exam_df, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#finishing-touch",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#finishing-touch",
    "title": "In-Class Exercise 2 - Visualising Distribution",
    "section": "Finishing touch",
    "text": "Finishing touch\n coord_flip() of ggplot2 package is used to flip the raincloud chart horizontally to give it the raincloud appearance. theme_economist() of ggthemes package is also used to give the raincloud chart a professional publishing standard look.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(exam_df, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "Hands-on Exercise 5 - Visualising and Analysing Text Data",
    "section": "",
    "text": "Learning Objectives:"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#installing-and-loading-the-required-libraries",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 5 - Visualising and Analysing Text Data",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nThe following R packages will be used:\n\ntidytext, tidyverse (mainly readr, purrr, stringr, ggplot2)\nwidyr,\nwordcloud and ggwordcloud,\ntextplot (required igraph, tidygraph and ggraph, )\nDT,\nlubridate and hms.\n\nCode chunk below will be used to check if these packages have been installed and also will load them into the working R environment.\n\npacman::p_load(tidytext, widyr, wordcloud, DT, ggwordcloud, textplot, lubridate, hms,tidyverse, tidygraph, ggraph, igraph)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#importing-multiple-text-files-from-multiple-folders",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#importing-multiple-text-files-from-multiple-folders",
    "title": "Hands-on Exercise 5 - Visualising and Analysing Text Data",
    "section": "Importing Multiple Text Files from Multiple Folders",
    "text": "Importing Multiple Text Files from Multiple Folders\n\nCreating a folder list\n\nnews20 &lt;- \"data/20news/\"\n\n\n\nDefine a function to read all files from a folder into a data frame\n\nread_folder &lt;- function(infolder) {\n  tibble(file = dir(infolder, \n                    full.names = TRUE)) %&gt;%\n    mutate(text = map(file, \n                      read_lines)) %&gt;%\n    transmute(id = basename(file), \n              text) %&gt;%\n    unnest(text)\n}"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#importing-multiple-text-files-from-multiple-folders-1",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#importing-multiple-text-files-from-multiple-folders-1",
    "title": "Hands-on Exercise 5 - Visualising and Analysing Text Data",
    "section": "Importing Multiple Text Files from Multiple Folders",
    "text": "Importing Multiple Text Files from Multiple Folders\n\nReading in all the messages from the 20news folder\n\nread_lines() of readr package is used to read up to n_max lines from a file.\nmap() of purrr package is used to transform their input by applying a function to each element of a list and returning an object of the same length as the input.\nunnest() of dplyr package is used to flatten a list-column of data frames back out into regular columns.\nmutate() of dplyr is used to add new variables and preserves existing ones;\ntransmute() of dplyr is used to add new variables and drops existing ones.\nread_rds() is used to save the extracted and combined data frame as rds file for future use.\n\n\nraw_text &lt;- tibble(folder = \n                     dir(news20, \n                         full.names = TRUE)) %&gt;%\n  mutate(folder_out = map(folder, \n                          read_folder)) %&gt;%\n  unnest(cols = c(folder_out)) %&gt;%\n  transmute(newsgroup = basename(folder), \n            id, text)\nwrite_rds(raw_text, \"data/rds/news20.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#initial-eda",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#initial-eda",
    "title": "Hands-on Exercise 5 - Visualising and Analysing Text Data",
    "section": "Initial EDA",
    "text": "Initial EDA\nFigure below shows the frequency of messages by newsgroup.\n\nPlotCode\n\n\n\nraw_text &lt;- read_rds(\"data/rds/news20.rds\")\nraw_text %&gt;%\n  group_by(newsgroup) %&gt;%\n  summarize(messages = n_distinct(id)) %&gt;%\n  ggplot(aes(messages, newsgroup)) +\n  geom_col(fill = \"lightblue\") +\n  labs(y = NULL)\n\n\n\n\nraw_text &lt;- read_rds(\"data/rds/news20.rds\")\nraw_text %&gt;%\n  group_by(newsgroup) %&gt;%\n  summarize(messages = n_distinct(id)) %&gt;%\n  ggplot(aes(messages, newsgroup)) +\n  geom_col(fill = \"lightblue\") +\n  labs(y = NULL)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#introducing-tidytext",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#introducing-tidytext",
    "title": "Hands-on Exercise 5 - Visualising and Analysing Text Data",
    "section": "Introducing tidytext",
    "text": "Introducing tidytext\n\nUsing tidy data principles in processing, analysing and visualising text data.\nMuch of the infrastructure needed for text mining with tidy data frames already exists in packages like ‘dplyr’, ‘broom’, ‘tidyr’, and ‘ggplot2’.\n\n\nRemoving header and automated email signitures\nEach message contains certain structural elements and additional text that are undesirable for inclusion in the analysis. For example:\n\nHeader containing fields such as “from:” or “in_reply_to:”\nAutomated email signatures, which occur after a line like “–”.\n\nThe code chunk below uses:\n\ncumsum() of base R to return a vector whose elements are the cumulative sums of the elements of the argument.\nstr_detect() from stringr to detect the presence or absence of a pattern in a string.\n\n\ncleaned_text &lt;- raw_text %&gt;%\n  group_by(newsgroup, id) %&gt;%\n  filter(cumsum(text == \"\") &gt; 0,\n         cumsum(str_detect(\n           text, \"^--\")) == 0) %&gt;%\n  ungroup()\n\n\n\nRemoving lines with nested text representing quotes from other users\nRegular expressions are used to remove with nested text representing quotes from other users.\n\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string.\nfilter() of dplyr package is used to subset a data frame, retaining all rows that satisfy the specified conditions.\n\n\ncleaned_text &lt;- cleaned_text %&gt;%\n  filter(str_detect(text, \"^[^&gt;]+[A-Za-z\\\\d]\")\n         | text == \"\",\n         !str_detect(text, \n                     \"writes(:|\\\\.\\\\.\\\\.)$\"),\n         !str_detect(text, \n                     \"^In article &lt;\")\n  )\n\n\n\nText Data Processing\n\n unnest_tokens() of tidytext package is used to split the dataset into tokens\n stop_words() is used to remove stop-words\n\n\nusenet_words &lt;- cleaned_text %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\nHeaders, signatures and formatting have been removed. The code chunk below calculates individual word frequncies to explore common words in the dataset.\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\nWord frequencies within newsgroup\n\nwords_by_newsgroup &lt;- usenet_words %&gt;%\n  count(newsgroup, word, sort = TRUE) %&gt;%\n  ungroup()\n\n\n\nVisualising Words in newsgroups\n\nwordcloud() of wordcloud package is used to plot a static wordcloud\n\n\nPlotCode\n\n\n\nwordcloud(words_by_newsgroup$word,\n          words_by_newsgroup$n,\n          max.words = 300)\n\n\n\n\nwordcloud(words_by_newsgroup$word,\n          words_by_newsgroup$n,\n          max.words = 300)\n\n\n\n\nA DT table can be used to complement the visual discovery.\n\nTableCode\n\n\n\n# Create a data frame with word frequency data\nword_freq_table &lt;- data.frame(Word = words_by_newsgroup$word,\n                              Frequency = words_by_newsgroup$n)\n\n# Render the DataTable\ndatatable(word_freq_table, \n          options = list(pageLength = 10))\n\n\n\n\n# Create a data frame with word frequency data\nword_freq_table &lt;- data.frame(Word = words_by_newsgroup$word,\n                              Frequency = words_by_newsgroup$n)\n\n# Render the DataTable\ndatatable(word_freq_table, \n          options = list(pageLength = 10))\n\n\n\n\n\n\nVisualising Words in newsgroups\n ggwordcloud package is used to plot the wordcloud below\n\nPlotCode\n\n\n\nset.seed(1234)\n\nwords_by_newsgroup %&gt;%\n  filter(n &gt; 0) %&gt;%\nggplot(aes(label = word,\n           size = n)) +\n  geom_text_wordcloud() +\n  theme_minimal() +\n  facet_wrap(~newsgroup)\n\n\n\n\nset.seed(1234)\n\nwords_by_newsgroup %&gt;%\n  filter(n &gt; 0) %&gt;%\nggplot(aes(label = word,\n           size = n)) +\n  geom_text_wordcloud() +\n  theme_minimal() +\n  facet_wrap(~newsgroup)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#basic-concept-of-tf-idf",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#basic-concept-of-tf-idf",
    "title": "Hands-on Exercise 5 - Visualising and Analysing Text Data",
    "section": "Basic Concept of TF-IDF",
    "text": "Basic Concept of TF-IDF\ntf–idf, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection of corpus.\n\\(idf(term) = ln \\frac{n_{documents}}{n_{documents containing term}}\\)\n\nComputing tf-idf within newsgroups\nbind_tf_idf() of tidytext is used to compute and bind the term frequency, inverse document frequency and ti-idf of a tidy text dataset to the dataset.\n\ntf_idf &lt;- words_by_newsgroup %&gt;%\n  bind_tf_idf(word, newsgroup, n) %&gt;%\n  arrange(desc(tf_idf))\n\n\n\nVisualising tf-idf as interactive table\nInteractive table created by using datatable() to create a html table that allows pagination of rows and columns.\nThe code chunk below also uses:\n\nfilter() argument is used to turn control the filter UI.\nformatRound() is used to customise the values format. The argument digits define the number of decimal places.\nformatStyle() is used to customise the output table. In this example, the arguments target and lineHeight are used to reduce the line height by 25%.\n\n\nTableCode\n\n\n\nDT::datatable(tf_idf, filter = 'top') %&gt;% \n  formatRound(columns = c('tf', 'idf', \n                          'tf_idf'), \n              digits = 3) %&gt;%\n  formatStyle(0, \n              target = 'row', \n              lineHeight='25%')\n\n\n\n\nDT::datatable(tf_idf, filter = 'top') %&gt;% \n  formatRound(columns = c('tf', 'idf', \n                          'tf_idf'), \n              digits = 3) %&gt;%\n  formatStyle(0, \n              target = 'row', \n              lineHeight='25%')\n\n\n\n\n\n\nVisualising tf-idf within newsgroups\nFacet bar charts technique is used to visualise the tf-idf values of science related newsgroup.\n\nPlotCode\n\n\n\ntf_idf %&gt;%\n  filter(str_detect(newsgroup, \"^sci\\\\.\")) %&gt;%\n  group_by(newsgroup) %&gt;%\n  slice_max(tf_idf, \n            n = 12) %&gt;%\n  ungroup() %&gt;%\n  mutate(word = reorder(word, \n                        tf_idf)) %&gt;%\n  ggplot(aes(tf_idf, \n             word, \n             fill = newsgroup)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ newsgroup, \n             scales = \"free\") +\n  labs(x = \"tf-idf\", \n       y = NULL)\n\n\n\n\ntf_idf %&gt;%\n  filter(str_detect(newsgroup, \"^sci\\\\.\")) %&gt;%\n  group_by(newsgroup) %&gt;%\n  slice_max(tf_idf, \n            n = 12) %&gt;%\n  ungroup() %&gt;%\n  mutate(word = reorder(word, \n                        tf_idf)) %&gt;%\n  ggplot(aes(tf_idf, \n             word, \n             fill = newsgroup)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ newsgroup, \n             scales = \"free\") +\n  labs(x = \"tf-idf\", \n       y = NULL)\n\n\n\n\n\n\nCounting and correlating pairs of words with the widyr package\n\nTo count the number of times that two words appear within the same document, or to see how correlated they are.\nMost operations for finding pairwise counts or correlations need to turn the data into a wide matrix first.\nwidyr package first ‘casts’ a tidy dataset into a wide matrix, performs an operation such as a correlation on it, then re-tidies the result.\n\nIn this code chunk below, pairwise_cor() of widyr package is used to compute the correlation between newsgroup based on the common words found.\n\nnewsgroup_cors &lt;- words_by_newsgroup %&gt;%\n  pairwise_cor(newsgroup, \n               word, \n               n, \n               sort = TRUE)\n\n\n\nVisualising correlation as a network\nRelationship between newgroups is visualised as a network graph\n\nPlotCode\n\n\n\nset.seed(2017)\n\nnewsgroup_cors %&gt;%\n  filter(correlation &gt; .025) %&gt;%\n  graph_from_data_frame() %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = correlation, \n                     width = correlation)) +\n  geom_node_point(size = 6, \n                  color = \"lightblue\") +\n  geom_node_text(aes(label = name),\n                 color = \"red\",\n                 repel = TRUE) +\n  theme_void()\n\n\n\n\nset.seed(2017)\n\nnewsgroup_cors %&gt;%\n  filter(correlation &gt; .025) %&gt;%\n  graph_from_data_frame() %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = correlation, \n                     width = correlation)) +\n  geom_node_point(size = 6, \n                  color = \"lightblue\") +\n  geom_node_text(aes(label = name),\n                 color = \"red\",\n                 repel = TRUE) +\n  theme_void()\n\n\n\n\n\n\nBigram\nCreated by using unnest_tokens() of tidytext.\n\nBigramCode\n\n\n\nbigrams &lt;- cleaned_text %&gt;%\n  unnest_tokens(bigram, \n                text, \n                token = \"ngrams\", \n                n = 2)\n\nbigrams\n\n\n\n\nbigrams &lt;- cleaned_text %&gt;%\n  unnest_tokens(bigram, \n                text, \n                token = \"ngrams\", \n                n = 2)\n\nbigrams\n\n\n\n\n\n\nCounting bigrams\nCount and sort the bigram data frame ascendingly\n\nBigram CountCode\n\n\n\nbigrams_count &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  count(bigram, sort = TRUE)\n\nbigrams_count\n\n\n\n\nbigrams_count &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  count(bigram, sort = TRUE)\n\nbigrams_count\n\n\n\n\n\n\nCleaning bigram\nSeperate the bigram into two words\n\nBigramCode\n\n\n\nbigrams_separated &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), \n           sep = \" \")\n\nbigrams_filtered &lt;- bigrams_separated %&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\n\nbigrams_filtered\n\n\n\n\nbigrams_separated &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), \n           sep = \" \")\n\nbigrams_filtered &lt;- bigrams_separated %&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\n\n\n\n\n\n\nCounting the bigram again\n\nbigram_counts &lt;- bigrams_filtered %&gt;% \n  count(word1, word2, sort = TRUE)\n\n\n\nCreate a network graph from bigram data frame\nA network graph is created by using graph_from_data_frame() of igraph package.\n\nbigram_graph &lt;- bigram_counts %&gt;%\n  filter(n &gt; 3) %&gt;%\n  graph_from_data_frame()\nbigram_graph\n\n\n\nVisualizing a network of bigrams with ggraph\nggraph package is used to plot the bigram\n\nPlotCode\n\n\n\nset.seed(1234)\n\nggraph(bigram_graph, layout = \"fr\") +\n  geom_edge_link() +\n  geom_node_point() +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1)\n\n\n\n\nset.seed(1234)\n\nggraph(bigram_graph, layout = \"fr\") +\n  geom_edge_link() +\n  geom_node_point() +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1)\n\n\n\n\n\n\nRevised version\n\nPlotCode\n\n\n\nset.seed(1234)\n\na &lt;- grid::arrow(type = \"closed\", \n                 length = unit(.15,\n                               \"inches\"))\n\nggraph(bigram_graph, \n       layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = n), \n                 show.legend = FALSE,\n                 arrow = a, \n                 end_cap = circle(.07,\n                                  'inches')) +\n  geom_node_point(color = \"lightblue\", \n                  size = 5) +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1) +\n  theme_void()\n\n\n\n\nset.seed(1234)\n\na &lt;- grid::arrow(type = \"closed\", \n                 length = unit(.15,\n                               \"inches\"))\n\nggraph(bigram_graph, \n       layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = n), \n                 show.legend = FALSE,\n                 arrow = a, \n                 end_cap = circle(.07,\n                                  'inches')) +\n  geom_node_point(color = \"lightblue\", \n                  size = 5) +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1) +\n  theme_void()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/data/shp/Oceanus Geography.html",
    "href": "In-class_Ex/In-class_Ex08/data/shp/Oceanus Geography.html",
    "title": "ISSS608",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#downloading-the-dataset",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#downloading-the-dataset",
    "title": "Take-home Exercise 1 - Creating Data Visualisation Beyond Default",
    "section": "Downloading the Dataset",
    "text": "Downloading the Dataset\n\nAccess Dataset via SMU e-library\n\nAfter logging in with SMU credentials, navigate to “Residential” tab\n\nUnder Property Types, “Select All”\nUnder Sale Date, select “2023 Jan” - “2024 Mar”\nClick “Search”\nClick “Download”\nDue to the size of the dataset, it is split into multiple segments. Download all in .csv format"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-designing-tool",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-designing-tool",
    "title": "Take-home Exercise 1 - Creating Data Visualisation Beyond Default",
    "section": "The Designing Tool",
    "text": "The Designing Tool\nThe data will be processed using the appropriate tidyverse family of packages and the statistical graphics will be prepared using ggplot2 and its extensions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#installing-and-loading-the-required-libraries",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#installing-and-loading-the-required-libraries",
    "title": "Take-home Exercise 1 - Creating Data Visualisation Beyond Default",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nNote: Ensure that the pacman package has already been installed.\nThe code chunk below loads the following packages using uses p_load() of pacman package:\n\ntidyverse: (i.e. readr, tidyr, dplyr, ggplot2, lubridate) for performing data science tasks such as importing, tidying, and wrangling data, as well as creating graphics based on The Grammar of Graphics\nreshape2 for transforming data between wide and long formats\nggthemes: provides some extra themes, geoms, and scales for ‘ggplot2’.\nggdist: a ggplot2 extension specially designed for visualising distribution and uncertainty\npatchwork: an R package for preparing composite figure created using ggplot2.\n\n\npacman::p_load(tidyverse, reshape2, ggthemes, ggdist, patchwork)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-the-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-the-data",
    "title": "Take-home Exercise 1 - Creating Data Visualisation Beyond Default",
    "section": "Importing the Data",
    "text": "Importing the Data\n\nThe data has been split into multiple .csv files\nlist.files() list all CSV files in the specified directory.\nAfter looping through each CSV file, read it into a data frame using read_csv(), and store it in a list.\nbind_rows() combines all data frames in the list into a single big data frame.\n\n\ncsv_directory &lt;- \"data/\"\ncsv_files &lt;- list.files(csv_directory, pattern = \"\\\\.csv$\", full.names = TRUE)\n\nrealis &lt;- list()\n\nfor (file in csv_files) {\n  realis[[file]] &lt;- read_csv(file)\n}\n\n\nrealis_all &lt;- bind_rows(realis)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#view-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#view-data",
    "title": "Take-home Exercise 1 - Creating Data Visualisation Beyond Default",
    "section": "View Data",
    "text": "View Data\n\nnames() function prints the names of the columns in the tibble data frame.\nglimpse() function gives a quick overview of the tibble data frame\n\n\nColumn NamesOverview of Tibble Data Frame\n\n\n\ncol_names &lt;- names(realis_all)\ncol_names\n\n [1] \"Project Name\"                \"Transacted Price ($)\"       \n [3] \"Area (SQFT)\"                 \"Unit Price ($ PSF)\"         \n [5] \"Sale Date\"                   \"Address\"                    \n [7] \"Type of Sale\"                \"Type of Area\"               \n [9] \"Area (SQM)\"                  \"Unit Price ($ PSM)\"         \n[11] \"Nett Price($)\"               \"Property Type\"              \n[13] \"Number of Units\"             \"Tenure\"                     \n[15] \"Completion Date\"             \"Purchaser Address Indicator\"\n[17] \"Postal Code\"                 \"Postal District\"            \n[19] \"Postal Sector\"               \"Planning Region\"            \n[21] \"Planning Area\"              \n\n\n\n\n\nglimpse(realis_all)\n\nRows: 26,806\nColumns: 21\n$ `Project Name`                &lt;chr&gt; \"THE REEF AT KING'S DOCK\", \"URBAN TREASU…\n$ `Transacted Price ($)`        &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 1280…\n$ `Area (SQFT)`                 &lt;dbl&gt; 882.65, 882.65, 1076.40, 1033.34, 871.88…\n$ `Unit Price ($ PSF)`          &lt;dbl&gt; 2625, 2066, 1320, 1218, 1468, 1767, 1095…\n$ `Sale Date`                   &lt;chr&gt; \"01 Jan 2023\", \"02 Jan 2023\", \"02 Jan 20…\n$ Address                       &lt;chr&gt; \"12 HARBOURFRONT AVENUE #05-32\", \"205 JA…\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", …\n$ `Area (SQM)`                  &lt;dbl&gt; 82.0, 82.0, 100.0, 96.0, 81.0, 308.7, 42…\n$ `Unit Price ($ PSM)`          &lt;dbl&gt; 28256, 22238, 14211, 13105, 15802, 19015…\n$ `Nett Price($)`               &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Property Type`               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive…\n$ `Number of Units`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Tenure                        &lt;chr&gt; \"99 yrs from 12/01/2021\", \"Freehold\", \"9…\n$ `Completion Date`             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncomplet…\n$ `Purchaser Address Indicator` &lt;chr&gt; \"HDB\", \"Private\", \"HDB\", \"HDB\", \"HDB\", \"…\n$ `Postal Code`                 &lt;chr&gt; \"097996\", \"419535\", \"269343\", \"269294\", …\n$ `Postal District`             &lt;chr&gt; \"04\", \"14\", \"27\", \"27\", \"28\", \"19\", \"10\"…\n$ `Postal Sector`               &lt;chr&gt; \"09\", \"41\", \"26\", \"26\", \"79\", \"54\", \"27\"…\n$ `Planning Region`             &lt;chr&gt; \"Central Region\", \"East Region\", \"North …\n$ `Planning Area`               &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishu…\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nrealis_all contains:\n\nPublic and Private residential property transaction data from 1st January 2023 to 31st March 2024.\nThere are 26,806 rows and 21 columns."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-preparation",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-preparation",
    "title": "Take-home Exercise 1 - Creating Data Visualisation Beyond Default",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nStandardise Date Format\nThe “Sales Date” column is currently a cha type. It needs to be converted into date format.\ndmy() is a function from the lubridate package that converts character strings to date format in the day-month-year (DMY) order.\n\nStandardise Date FormatView Data\n\n\n\nrealis_all$`Sale Date` &lt;- dmy(realis_all$`Sale Date`)\n\n\n\n\nhead(realis_all$`Sale Date`)\n\n[1] \"2023-01-01\" \"2023-01-02\" \"2023-01-02\" \"2023-01-02\" \"2023-01-03\"\n[6] \"2023-01-03\"\n\n\n\n\n\n\n\nKeep Relevant Rows\nDuplicate and empty rows are removed.\n\nqa_pte_raw &lt;- realis_all %&gt;%\n    distinct() %&gt;%\n    drop_na()\n\n\nView Data\n\nglimpse(qa_pte_raw)\n\nRows: 26,800\nColumns: 21\n$ `Project Name`                &lt;chr&gt; \"THE REEF AT KING'S DOCK\", \"URBAN TREASU…\n$ `Transacted Price ($)`        &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 1280…\n$ `Area (SQFT)`                 &lt;dbl&gt; 882.65, 882.65, 1076.40, 1033.34, 871.88…\n$ `Unit Price ($ PSF)`          &lt;dbl&gt; 2625, 2066, 1320, 1218, 1468, 1767, 1095…\n$ `Sale Date`                   &lt;date&gt; 2023-01-01, 2023-01-02, 2023-01-02, 202…\n$ Address                       &lt;chr&gt; \"12 HARBOURFRONT AVENUE #05-32\", \"205 JA…\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", …\n$ `Area (SQM)`                  &lt;dbl&gt; 82.0, 82.0, 100.0, 96.0, 81.0, 308.7, 42…\n$ `Unit Price ($ PSM)`          &lt;dbl&gt; 28256, 22238, 14211, 13105, 15802, 19015…\n$ `Nett Price($)`               &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Property Type`               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive…\n$ `Number of Units`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Tenure                        &lt;chr&gt; \"99 yrs from 12/01/2021\", \"Freehold\", \"9…\n$ `Completion Date`             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncomplet…\n$ `Purchaser Address Indicator` &lt;chr&gt; \"HDB\", \"Private\", \"HDB\", \"HDB\", \"HDB\", \"…\n$ `Postal Code`                 &lt;chr&gt; \"097996\", \"419535\", \"269343\", \"269294\", …\n$ `Postal District`             &lt;chr&gt; \"04\", \"14\", \"27\", \"27\", \"28\", \"19\", \"10\"…\n$ `Postal Sector`               &lt;chr&gt; \"09\", \"41\", \"26\", \"26\", \"79\", \"54\", \"27\"…\n$ `Planning Region`             &lt;chr&gt; \"Central Region\", \"East Region\", \"North …\n$ `Planning Area`               &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishu…\n\n\n\n\n\n\n\n\nNote\n\n\n\nqa_pte_raw contains:\n\nPrivate residential property transaction data from 1st January 2023 to 31st March 2024\nThere are 26,800 rows and 21 columns.\n\n\n\n\n\n\nKeep Relevant Columns\nNot all 21 columns will be used for analysis e.g. contains overlapping information as another column. Only relevant columns will be kept.\nColumns to drop:\n\nArea (SQFT): Similar information as Area (SQM)\nUnit Price ($ PSF): Similar information as Unit Price ($ PSM)\nNett Price ($): Similar information as Transacted Price ($)\nPostal District and Postal Sector: Overlapping information as Postal Code\n\nColumns to be dropped can be specified by prefixing the column names with a minus sign (-) when using the select() function from the dplyr package.\n\nKeep Relevant ColumnsView Data\n\n\n\nqa_pte &lt;- qa_pte_raw %&gt;%\n    select(\n        -`Area (SQFT)`,\n        -`Unit Price ($ PSF)`,\n        -`Postal District`,\n        -`Postal Sector`\n    )\n\n\n\n\nglimpse(qa_pte)\n\nRows: 26,800\nColumns: 17\n$ `Project Name`                &lt;chr&gt; \"THE REEF AT KING'S DOCK\", \"URBAN TREASU…\n$ `Transacted Price ($)`        &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 1280…\n$ `Sale Date`                   &lt;date&gt; 2023-01-01, 2023-01-02, 2023-01-02, 202…\n$ Address                       &lt;chr&gt; \"12 HARBOURFRONT AVENUE #05-32\", \"205 JA…\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", …\n$ `Area (SQM)`                  &lt;dbl&gt; 82.0, 82.0, 100.0, 96.0, 81.0, 308.7, 42…\n$ `Unit Price ($ PSM)`          &lt;dbl&gt; 28256, 22238, 14211, 13105, 15802, 19015…\n$ `Nett Price($)`               &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Property Type`               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive…\n$ `Number of Units`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Tenure                        &lt;chr&gt; \"99 yrs from 12/01/2021\", \"Freehold\", \"9…\n$ `Completion Date`             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncomplet…\n$ `Purchaser Address Indicator` &lt;chr&gt; \"HDB\", \"Private\", \"HDB\", \"HDB\", \"HDB\", \"…\n$ `Postal Code`                 &lt;chr&gt; \"097996\", \"419535\", \"269343\", \"269294\", …\n$ `Planning Region`             &lt;chr&gt; \"Central Region\", \"East Region\", \"North …\n$ `Planning Area`               &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishu…\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nqa_pte contains:\n\nPrivate residential property transaction data from 1st January 2024 to 31st March 2024\nThere are 26,800 rows and 14 columns.\nColumns:\n\nProject Name\nTransacted Price ($)\nSale Date\nAddress\nType of Sale\nType of Area\nArea (SQM)\nUnit Price ($ PSM)\nNett Price\nProperty Type\nNumber of Units\nTenure\nCompletion Date\nPurchaser Address Indicator\nPostal Code\nPlanning Region\nPlanning Area\n\n\n\n\n\n\nSeparate Data by Quarters\nThe dataset contains 5 quarters:\n\nQuarter 1: 2023 Jan - Mar\nQuarter 2: 2023 Apr - Jun\nQuarter 3: 2023 Jul - Sep\nQuarter 4: 2023 Aug - Dec\nQuarter 5: 2024 Jan - Mar\n\nTo allow for comparison between quarters, qa_pte will be split into the respective quarters by Sale Date.\n\nq1 &lt;- qa_pte %&gt;%\n  filter(`Sale Date` &lt;= \"2023-03-31\")\n\nq2 &lt;- qa_pte %&gt;%\n  filter(`Sale Date` &gt; \"2023-03-31\" & `Sale Date` &lt;= \"2023-06-30\")\n\nq3 &lt;- qa_pte %&gt;%\n  filter(`Sale Date` &gt; \"2023-06-30\" & `Sale Date` &lt;= \"2023-09-30\")\n\nq4 &lt;- qa_pte %&gt;%\n  filter(`Sale Date` &gt; \"2023-09-30\" & `Sale Date` &lt;= \"2023-12-31\")\n\nq5 &lt;- qa_pte %&gt;%\n  filter(`Sale Date` &gt; \"2023-12-31\")\n\n\n\nView Data\n\nQ1Q2Q3Q4Q5\n\n\n\nglimpse(q1)\n\nRows: 4,722\nColumns: 17\n$ `Project Name`                &lt;chr&gt; \"THE REEF AT KING'S DOCK\", \"URBAN TREASU…\n$ `Transacted Price ($)`        &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 1280…\n$ `Sale Date`                   &lt;date&gt; 2023-01-01, 2023-01-02, 2023-01-02, 202…\n$ Address                       &lt;chr&gt; \"12 HARBOURFRONT AVENUE #05-32\", \"205 JA…\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", …\n$ `Area (SQM)`                  &lt;dbl&gt; 82.0, 82.0, 100.0, 96.0, 81.0, 308.7, 42…\n$ `Unit Price ($ PSM)`          &lt;dbl&gt; 28256, 22238, 14211, 13105, 15802, 19015…\n$ `Nett Price($)`               &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Property Type`               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive…\n$ `Number of Units`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Tenure                        &lt;chr&gt; \"99 yrs from 12/01/2021\", \"Freehold\", \"9…\n$ `Completion Date`             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncomplet…\n$ `Purchaser Address Indicator` &lt;chr&gt; \"HDB\", \"Private\", \"HDB\", \"HDB\", \"HDB\", \"…\n$ `Postal Code`                 &lt;chr&gt; \"097996\", \"419535\", \"269343\", \"269294\", …\n$ `Planning Region`             &lt;chr&gt; \"Central Region\", \"East Region\", \"North …\n$ `Planning Area`               &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishu…\n\n\n\n\n\nsummary(q2)\n\n Project Name       Transacted Price ($)   Sale Date         \n Length:6125        Min.   :  520000     Min.   :2023-04-01  \n Class :character   1st Qu.: 1268000     1st Qu.:2023-04-24  \n Mode  :character   Median : 1688000     Median :2023-05-13  \n                    Mean   : 2116310     Mean   :2023-05-13  \n                    3rd Qu.: 2350000     3rd Qu.:2023-05-31  \n                    Max.   :66800000     Max.   :2023-06-30  \n   Address          Type of Sale       Type of Area         Area (SQM)    \n Length:6125        Length:6125        Length:6125        Min.   :  30.0  \n Class :character   Class :character   Class :character   1st Qu.:  63.0  \n Mode  :character   Mode  :character   Mode  :character   Median :  89.0  \n                                                          Mean   : 106.7  \n                                                          3rd Qu.: 119.0  \n                                                          Max.   :2339.0  \n Unit Price ($ PSM) Nett Price($)      Property Type      Number of Units \n Min.   : 3364      Length:6125        Length:6125        Min.   : 1.000  \n 1st Qu.:14838      Class :character   Class :character   1st Qu.: 1.000  \n Median :19787      Mode  :character   Mode  :character   Median : 1.000  \n Mean   :20665                                            Mean   : 1.002  \n 3rd Qu.:26390                                            3rd Qu.: 1.000  \n Max.   :57053                                            Max.   :11.000  \n    Tenure          Completion Date    Purchaser Address Indicator\n Length:6125        Length:6125        Length:6125                \n Class :character   Class :character   Class :character           \n Mode  :character   Mode  :character   Mode  :character           \n                                                                  \n                                                                  \n                                                                  \n Postal Code        Planning Region    Planning Area     \n Length:6125        Length:6125        Length:6125       \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n\n\n\n\n\nsummary(q3)\n\n Project Name       Transacted Price ($)   Sale Date         \n Length:6200        Min.   :  440000     Min.   :2023-07-01  \n Class :character   1st Qu.: 1280000     1st Qu.:2023-07-15  \n Mode  :character   Median : 1642500     Median :2023-08-05  \n                    Mean   : 2017893     Mean   :2023-08-09  \n                    3rd Qu.: 2255250     3rd Qu.:2023-08-31  \n                    Max.   :32000000     Max.   :2023-09-30  \n   Address          Type of Sale       Type of Area         Area (SQM)   \n Length:6200        Length:6200        Length:6200        Min.   : 30.0  \n Class :character   Class :character   Class :character   1st Qu.: 67.0  \n Mode  :character   Mode  :character   Mode  :character   Median : 91.0  \n                                                          Mean   :105.7  \n                                                          3rd Qu.:119.0  \n                                                          Max.   :995.0  \n Unit Price ($ PSM) Nett Price($)      Property Type      Number of Units\n Min.   : 2158      Length:6200        Length:6200        Min.   :1      \n 1st Qu.:15071      Class :character   Class :character   1st Qu.:1      \n Median :19048      Mode  :character   Mode  :character   Median :1      \n Mean   :19857                                            Mean   :1      \n 3rd Qu.:24048                                            3rd Qu.:1      \n Max.   :59949                                            Max.   :2      \n    Tenure          Completion Date    Purchaser Address Indicator\n Length:6200        Length:6200        Length:6200                \n Class :character   Class :character   Class :character           \n Mode  :character   Mode  :character   Mode  :character           \n                                                                  \n                                                                  \n                                                                  \n Postal Code        Planning Region    Planning Area     \n Length:6200        Length:6200        Length:6200       \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n\n\n\n\n\nsummary(q4)\n\n Project Name       Transacted Price ($)   Sale Date         \n Length:4851        Min.   :  570000     Min.   :2023-10-01  \n Class :character   1st Qu.: 1285000     1st Qu.:2023-10-25  \n Mode  :character   Median : 1649340     Median :2023-11-11  \n                    Mean   : 2147366     Mean   :2023-11-13  \n                    3rd Qu.: 2370000     3rd Qu.:2023-12-04  \n                    Max.   :33888000     Max.   :2023-12-31  \n   Address          Type of Sale       Type of Area         Area (SQM)    \n Length:4851        Length:4851        Length:4851        Min.   :  30.0  \n Class :character   Class :character   Class :character   1st Qu.:  67.0  \n Mode  :character   Mode  :character   Mode  :character   Median :  96.0  \n                                                          Mean   : 110.7  \n                                                          3rd Qu.: 122.0  \n                                                          Max.   :1423.1  \n Unit Price ($ PSM) Nett Price($)      Property Type      Number of Units\n Min.   : 1484      Length:4851        Length:4851        Min.   :1.000  \n 1st Qu.:14900      Class :character   Class :character   1st Qu.:1.000  \n Median :18846      Mode  :character   Mode  :character   Median :1.000  \n Mean   :19682                                            Mean   :1.001  \n 3rd Qu.:23492                                            3rd Qu.:1.000  \n Max.   :47026                                            Max.   :7.000  \n    Tenure          Completion Date    Purchaser Address Indicator\n Length:4851        Length:4851        Length:4851                \n Class :character   Class :character   Class :character           \n Mode  :character   Mode  :character   Mode  :character           \n                                                                  \n                                                                  \n                                                                  \n Postal Code        Planning Region    Planning Area     \n Length:4851        Length:4851        Length:4851       \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n\n\n\n\n\nsummary(q5)\n\n Project Name       Transacted Price ($)   Sale Date         \n Length:4902        Min.   :  555000     Min.   :2024-01-01  \n Class :character   1st Qu.: 1330000     1st Qu.:2024-01-26  \n Mode  :character   Median : 1688000     Median :2024-02-17  \n                    Mean   : 2100902     Mean   :2024-02-16  \n                    3rd Qu.: 2300000     3rd Qu.:2024-03-14  \n                    Max.   :39500000     Max.   :2024-03-31  \n   Address          Type of Sale       Type of Area         Area (SQM)    \n Length:4902        Length:4902        Length:4902        Min.   :  30.0  \n Class :character   Class :character   Class :character   1st Qu.:  71.0  \n Mode  :character   Mode  :character   Mode  :character   Median :  94.0  \n                                                          Mean   : 111.5  \n                                                          3rd Qu.: 120.7  \n                                                          Max.   :1816.6  \n Unit Price ($ PSM) Nett Price($)      Property Type      Number of Units\n Min.   : 6183      Length:4902        Length:4902        Min.   :1      \n 1st Qu.:15237      Class :character   Class :character   1st Qu.:1      \n Median :18688      Mode  :character   Mode  :character   Median :1      \n Mean   :19502                                            Mean   :1      \n 3rd Qu.:23548                                            3rd Qu.:1      \n Max.   :58099                                            Max.   :2      \n    Tenure          Completion Date    Purchaser Address Indicator\n Length:4902        Length:4902        Length:4902                \n Class :character   Class :character   Class :character           \n Mode  :character   Mode  :character   Mode  :character           \n                                                                  \n                                                                  \n                                                                  \n Postal Code        Planning Region    Planning Area     \n Length:4902        Length:4902        Length:4902       \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#number-of-units-sold",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#number-of-units-sold",
    "title": "Take-home Exercise 1 - Creating Data Visualisation Beyond Default",
    "section": "Number of Units Sold",
    "text": "Number of Units Sold\nCreate bar chart plots for the price distribution of each private residence property type. A bar chart or graph that presents categorical data with rectangular bars with heights or lengths proportional to the values that they represent. They can be plotted vertically or horizontally.\nFor each quarter, the data is grouped by property type, then summed by the number of units, in order to obtain the number of units sold per quarter.\n\nSummarise Number of Units Sold by Property Type\n\nQ1 2023Q2 2023Q3 2023Q4 2023Q1 2024\n\n\n\nq1_units &lt;- q1 %&gt;%\n  group_by(`Property Type`) %&gt;%\n  summarize(`Total Units` = sum(`Number of Units`), .groups = \"drop\")\nq1_units\n\n# A tibble: 6 × 2\n  `Property Type`       `Total Units`\n  &lt;chr&gt;                         &lt;dbl&gt;\n1 Apartment                      1662\n2 Condominium                    2267\n3 Detached House                   64\n4 Executive Condominium           535\n5 Semi-Detached House              88\n6 Terrace House                   212\n\n\n\n\n\nq2_units &lt;- q2 %&gt;%\n  group_by(`Property Type`) %&gt;%\n  summarize(`Total Units` = sum(`Number of Units`), .groups = \"drop\")\nq2_units\n\n# A tibble: 6 × 2\n  `Property Type`       `Total Units`\n  &lt;chr&gt;                         &lt;dbl&gt;\n1 Apartment                      2664\n2 Condominium                    2451\n3 Detached House                   50\n4 Executive Condominium           620\n5 Semi-Detached House             129\n6 Terrace House                   226\n\n\n\n\n\nq3_units &lt;- q3 %&gt;%\n  group_by(`Property Type`) %&gt;%\n  summarize(`Total Units` = sum(`Number of Units`), .groups = \"drop\")\nq3_units\n\n# A tibble: 6 × 2\n  `Property Type`       `Total Units`\n  &lt;chr&gt;                         &lt;dbl&gt;\n1 Apartment                      2578\n2 Condominium                    2250\n3 Detached House                   34\n4 Executive Condominium           954\n5 Semi-Detached House             127\n6 Terrace House                   259\n\n\n\n\n\nq4_units &lt;- q4 %&gt;%\n  group_by(`Property Type`) %&gt;%\n  summarize(`Total Units` = sum(`Number of Units`), .groups = \"drop\")\nq4_units\n\n# A tibble: 6 × 2\n  `Property Type`       `Total Units`\n  &lt;chr&gt;                         &lt;dbl&gt;\n1 Apartment                      2028\n2 Condominium                    1918\n3 Detached House                   42\n4 Executive Condominium           582\n5 Semi-Detached House              90\n6 Terrace House                   197\n\n\n\n\n\nq5_units &lt;- q5 %&gt;%\n  group_by(`Property Type`) %&gt;%\n  summarize(`Total Units` = sum(`Number of Units`), .groups = \"drop\")\nq5_units\n\n# A tibble: 6 × 2\n  `Property Type`       `Total Units`\n  &lt;chr&gt;                         &lt;dbl&gt;\n1 Apartment                      1853\n2 Condominium                    1858\n3 Detached House                   40\n4 Executive Condominium           843\n5 Semi-Detached House              93\n6 Terrace House                   216\n\n\n\n\n\nThe code chunk below plots the number of units by property type for each quarter.\n\n2023 Q12023 Q22023 Q32023 Q42024 Q1\n\n\n\nq1_mean &lt;- mean(q1_units$`Total Units`)\n\nq1_plot &lt;- ggplot(q1_units, aes(x = `Property Type`, y = `Total Units`)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Property Type\", y = \"Total Units Sold\") +\n  ggtitle(\"Q1 2023\") +\n  ylim(0, 2700) +\n  theme_economist() +\n  theme(axis.text.x = element_text(angle = 90)) +\n  geom_hline(yintercept = q1_mean, color = \"navy\", linetype = \"dashed\") +\n  annotate(geom = \"text\", x = 5, y = q1_mean + 100, \n           label = paste(\"Mean:\", round(q1_mean, 2)), color = \"navy\")\n\nq1_plot\n\n\n\n\n\n\n\nq2_mean &lt;- mean(q2_units$`Total Units`)\n\nq2_plot &lt;- ggplot(q2_units, aes(x = `Property Type`, y = `Total Units`)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Property Type\", y = \"Total Units Sold\") +\n  ggtitle(\"Q2 2023\") +\n  ylim(0, 2700) +\n  theme_economist() +\n  theme(axis.text.x = element_text(angle = 90)) +\n  geom_hline(yintercept = q2_mean, color = \"navy\", linetype = \"dashed\") +\n  annotate(geom = \"text\", x = 5, y = q2_mean + 100, \n           label = paste(\"Mean:\", round(q2_mean, 2)), color = \"navy\")\n\nq2_plot\n\n\n\n\n\n\n\nq3_mean &lt;- mean(q3_units$`Total Units`)\n\nq3_plot &lt;- ggplot(q3_units, aes(x = `Property Type`, y = `Total Units`)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Property Type\", y = \"Total Units Sold\") +\n  ggtitle(\"Q3 2023\") +\n  ylim(0, 2700) +\n  theme_economist() +\n  theme(axis.text.x = element_text(angle = 90)) +\n  geom_hline(yintercept = q3_mean, color = \"navy\", linetype = \"dashed\") +\n  annotate(geom = \"text\", x = 5, y = q3_mean + 100, \n           label = paste(\"Mean:\", round(q3_mean, 2)), color = \"navy\")\n\nq3_plot\n\n\n\n\n\n\n\nq4_mean &lt;- mean(q4_units$`Total Units`)\n\nq4_plot &lt;- ggplot(q4_units, aes(x = `Property Type`, y = `Total Units`)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Property Type\", y = \"Total Units Sold\") +\n  ggtitle(\"Q4 2023\") +\n  ylim(0, 2700) +\n  theme_economist() +\n  theme(axis.text.x = element_text(angle = 90)) +\n  geom_hline(yintercept = q4_mean, color = \"navy\", linetype = \"dashed\") +\n  annotate(geom = \"text\", x = 5, y = q4_mean + 100, \n           label = paste(\"Mean:\", round(q4_mean, 2)), color = \"navy\")\n\nq4_plot\n\n\n\n\n\n\n\nq5_mean &lt;- mean(q5_units$`Total Units`)\n\nq5_plot &lt;- ggplot(q5_units, aes(x = `Property Type`, y = `Total Units`)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Property Type\", y = \"Total Units Sold\") +\n  ggtitle(\"Q1 2024\") +\n  ylim(0, 2700) +\n  theme_economist() +\n  theme(axis.text.x = element_text(angle = 90)) +\n  geom_hline(yintercept = q5_mean, color = \"navy\", linetype = \"dashed\") +\n  annotate(geom = \"text\", x = 5, y = q5_mean + 100, \n           label = paste(\"Mean:\", round(q5_mean, 2)), color = \"navy\")\n\nq5_plot\n\n\n\n\n\n\n\n\n\nComposite Plot\nUsing patchwork package, the plots for Q1 2023 and Q1 2024 are stacked into 1 composite plot for a quarter on quarter analysis.\n\nq1_plot | q5_plot\n\n\n\n\n\n\n\n\n\n\nWrite Up\n\n\n\nComparing bar chart plots for Q1 2023 and Q1 2024 (quarter on quarter), insights emerge regarding the mean number of units sold. In Q1 2023, the average stood at 804.67 units, edging slightly higher to 817.17 units in Q1 2024. This suggests a slight overall increase in property sales.\nWhile Apartments and Executive Condominiums experienced growth in sales volumes, Semi-Detached Houses and Terrace Houses maintained stable figures. Conversely, a decline was observed in the number of Condominiums and Detached Houses sold.\nNotably, Apartments and Condominiums, the predominant property types, experienced the most significant shifts in sales volumes, with Apartments witnessing the largest increase and Condominiums facing the most substantial decline."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#price-distribution",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#price-distribution",
    "title": "Take-home Exercise 1 - Creating Data Visualisation Beyond Default",
    "section": "Price Distribution",
    "text": "Price Distribution\nCreate box plots for the price distribution of each private residence property type. geom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\nNote: For better visibility, labels parameter with the function scales::number, formats the y-axis labels to include thousands separators.\nThe code chunk below shows that in Q1 2023 for Condominiums, there are two points with value above 900 million that is affecting the rest of the box plot. Thus, the decision was made to remove those points, and replot the data without the extreme outliers.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data = q1, \n       aes(x = `Property Type`, y = `Transacted Price ($)`)) + \ngeom_boxplot() +\nlabs(title = \"Q1 2023\",\n     x = \"Property Type\",\n     y = \"Transacted Price ($)\") +\nscale_y_continuous(labels = scales::number) + \ntheme_economist() +\ntheme(axis.text.x = element_text(angle = 90)) \n\n\n\n\n\nDrop Extreme Outlier\n\nq1_filtered &lt;- q1 %&gt;%\n  filter(`Transacted Price ($)` &lt;= 90000000)\n\n\n\nPrice Distribution by Property Type\nNote: For better visibility, labels parameter with the function scales::number(scale = 1e-6, suffix = \"M\") formats the y-axis labels to display in the millions unit, instead of the default scientific notation.\n\nQ1 2023Q2 2023Q3 2023Q4 2023Q1 2024\n\n\n\nq1_median &lt;- median(q1_filtered$`Transacted Price ($)`, na.rm = TRUE)\n\nq1_box &lt;- ggplot(data = q1_filtered, \n                aes(x = `Property Type`, y = `Transacted Price ($)`)) + \n          geom_boxplot() +\n          labs(title = \"Q1 2023\",\n                x = \"Property Type\",\n                y = \"Transacted Price ($)\") +\nscale_y_continuous(labels = scales::number_format(scale = 1e-6, suffix = \"M\"),\n                  limits = c(0, 67000000)) +\ngeom_hline(yintercept = q1_median,\n             linetype = \"dashed\", color = \"navy\") +\n  annotate(geom = \"text\",\n           x = 4, y = q1_median *10, \n           label = paste(\"Median:\", scales::number(q1_median, color = \"navy\"))) +\ntheme_economist() +\ntheme(axis.text.x = element_text(angle = 90)) \n\nq1_box\n\n\n\n\n\n\n\nq2_median &lt;- median(q2$`Transacted Price ($)`, na.rm = TRUE)\n\nq2_box &lt;- ggplot(data = q2, \n                aes(x = `Property Type`, y = `Transacted Price ($)`)) + \n          geom_boxplot() +\n          labs(title = \"Q2 2023\",\n                x = \"Property Type\",\n                y = \"Transacted Price ($)\") +\nscale_y_continuous(labels = scales::number_format(scale = 1e-6, suffix = \"M\"),\n                  limits = c(0, 67000000)) +\ngeom_hline(yintercept = q2_median,\n             linetype = \"dashed\", color = \"navy\") +\n  annotate(geom = \"text\",\n           x = 4, y = q2_median *10, \n           label = paste(\"Median:\", scales::number(q2_median, color = \"navy\"))) +\ntheme_economist() +\ntheme(axis.text.x = element_text(angle = 90)) \n\nq2_box\n\n\n\n\n\n\n\nq3_median &lt;- median(q3$`Transacted Price ($)`, na.rm = TRUE)\n\nq3_box &lt;- ggplot(data = q3, \n                aes(x = `Property Type`, y = `Transacted Price ($)`)) + \n          geom_boxplot() +\n          labs(title = \"Q3 2023\",\n                x = \"Property Type\",\n                y = \"Transacted Price ($)\") +\nscale_y_continuous(labels = scales::number_format(scale = 1e-6, suffix = \"M\"),\n                  limits = c(0, 67000000)) +\ngeom_hline(yintercept = q3_median,\n             linetype = \"dashed\", color = \"navy\") +\n  annotate(geom = \"text\",\n           x = 4, y = q3_median *10, \n           label = paste(\"Median:\", scales::number(q3_median, color = \"navy\"))) +\ntheme_economist() +\ntheme(axis.text.x = element_text(angle = 90)) \n\nq3_box\n\n\n\n\n\n\n\nq4_median &lt;- median(q4$`Transacted Price ($)`, na.rm = TRUE)\n\nq4_box &lt;- ggplot(data = q4, \n                aes(x = `Property Type`, y = `Transacted Price ($)`)) + \n          geom_boxplot() +\n          labs(title = \"Q4 2023\",\n                x = \"Property Type\",\n                y = \"Transacted Price ($)\") +\nscale_y_continuous(labels = scales::number_format(scale = 1e-6, suffix = \"M\"),\n                  limits = c(0, 67000000)) +\ngeom_hline(yintercept = q4_median,\n             linetype = \"dashed\", color = \"navy\") +\n  annotate(geom = \"text\",\n           x = 4, y = q4_median *10, \n          label = paste(\"Median:\", scales::number(q4_median, color = \"navy\"))) +\ntheme_economist() +\ntheme(axis.text.x = element_text(angle = 90)) \n\nq4_box\n\n\n\n\n\n\n\nq5_median &lt;- median(q5$`Transacted Price ($)`, na.rm = TRUE)\n\nq5_box &lt;- ggplot(data = q5, \n                aes(x = `Property Type`, y = `Transacted Price ($)`)) + \n          geom_boxplot() +\n          labs(title = \"Q1 2024\",\n                x = \"Property Type\",\n                y = \"Transacted Price ($)\") +\nscale_y_continuous(labels = scales::number_format(scale = 1e-6, suffix = \"M\"),\n                  limits = c(0, 67000000)) +\ngeom_hline(yintercept = q5_median,\n             linetype = \"dashed\", color = \"navy\") +\n  annotate(geom = \"text\",\n           x = 4, y = q5_median *10, \n          label = paste(\"Median:\", scales::number(q5_median, color = \"navy\"))) +\ntheme_economist() +\ntheme(axis.text.x = element_text(angle = 90)) \n\nq5_box\n\n\n\n\n\n\n\n\n\nComposite Plot\nUsing patchwork package, the plots for Q1 2023 and Q1 2024 are stacked into 1 composite plot for a quarter on quarter analysis.\n\nq1_box | q5_box\n\n\n\n\n\n\n\n\n\n\nWrite Up\n\n\n\nOverall, there is an increase in overall prices from 1.63 million to 1.69 million. However, the price variability for all property types have decreased, with fewer outliers present.\nThe boxplot shows Detached Houses generally have the highest transacted prices. The Q1, median, and Q3 values for this property type are all substantially higher than those of other types, indicating its premium market status.\nDetached Houses also exhibit the highest variability in transacted prices, although there are relatively few outliers. In contrast, Executive Condominiums demonstrate the least variability in transacted prices, with their interquartile ranges (IQR) closely aligning with their medians. This suggests a stable and consistent pricing trend. Executive Condominiums have the lowest transacted prices, indicating their appeal as an affordable option within the private housing market.\nApartments and Condominiums, on the other hand, show a significant number of outliers in their transacted prices, suggesting a wider range of pricing and potentially more diversity in market conditions for these property types."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2 - DataVis Makeover",
    "section": "",
    "text": "Select one data visualisation from the Take-home Exercise 1 submission prepared by a peer,\nCritic the submission in terms of clarity and aesthetics,\nPrepare a sketch for the alternative design by using the data visualisation design principles and best practices you had learned in Lesson 1 and 2.\nRemake the original design by using ggplot2, ggplot2 extensions and tidyverse packages."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualisation",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualisation",
    "title": "Take-home Exercise 2 - DataVis Makeover",
    "section": "Visualisation",
    "text": "Visualisation\nIn “Visualization 1 - How has transacted price varied over the 2024 Q1 and 2023”, the following plot is presented:\n\n\nAesthetics\n\n\n\n\n\n\n\nPros\nCons\n\n\n\n\n\nThe presented charts are relatively well spaced, so while there is a lot of information, chart elements are not overlaid on top of each other and obscured.\nColour theme of the plot is consistently applied, making reference between presented charts quick and easy\n\n\nAt first glance, one could mistakenly assume that the 3 general colour groups i.e. blue, green, orange were meant to be a grouping, where:\n\nGroup 1: Apartment, Condominium\nGroup 2: Detached House, Semi-detached House, Terrace House\nGroup 3: Executive Condominium\n\nIn addition, the light colours chosen, when presented with a light background in the raincloud plot, does not have good contrast.\nNot immediately obvious what the different shades of gray used for the line-bar chart represents, especially for bar charts where the bars have similar Y values\nIn-consistent Y axis labels for bar-line chart\n\nAbbreviations such as “EC”, “Apt”, “Condo” is not used anywhere else in the plot\nLeft Y axis has “Median Price” labeled for the second and fifth plot only, which could cause confusion as to why the rest of the plots are not labeled\n\n\n\n\n\n\n\nClarity\n\n\n\n\n\n\n\nPros\nCons\n\n\n\n\n\nGenerally, the volume of the bars in the stacked bar chart and line-bar chart correspond to their relative values, useful for quick comparison\n\n\nIt is not clear on first glance what the red dotted line separates:\n\nTimeline? In the bar-line chart and stacked bar chart, it appears to be separating timeline of interest, but it is unclear whether the right or left side is the timeline of interest.\nMean/Median? In the raincloud plot, there is no timeline per se, so it seems to denote the mean or median transacted price\n\nIn-consistent Y axis for bar-line chart\n\nRight Y-axis, includes both numbers and scientific notation, making it challenging to interpret. Specifically, the lack of clear spacing between the digits in the numerical format makes it difficult to read, while the scientific notation may not be readily understandable to individuals unfamiliar with it."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#aesthetics-1",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#aesthetics-1",
    "title": "Take-home Exercise 2 - DataVis Makeover",
    "section": "Aesthetics",
    "text": "Aesthetics\n\n\n\n\n\n\n\nIdentified Areas for Improvement\nProposed Solutions\n\n\n\n\n\nAt first glance, one could mistakenly assume that the 3 general colour groups i.e. blue, green, orange were meant to be a grouping, where:\n\nGroup 1: Apartment, Condominium\nGroup 2: Detached House, Semi-detached House, Terrace House\nGroup 3: Executive Condominium\n\nIn addition, the light colours chosen, when presented with a light background in the raincloud plot, does not have good contrast.\nNot immediately obvious what the different shades of gray used for the line-bar chart represents, especially for bar charts where the bars have similar Y values\nIn-consistent Y axis labels for bar-line chart\n\nAbbreviations such as “EC”, “Apt”, “Condo” is not used anywhere else in the plot\nLeft Y axis has “Median Price” labeled for the second and fifth plot only, which could cause confusion as to why the rest of the plots are not labeled\n\n\n\nColours simplified to various shades of blue to prevent any distraction. Colours chosen work with both light and dark backgrounds with good contrast. In addition, the colours are different enough from each other to be easily differentiated from each other in the plots\nInstead of colouring the background for the bar-line chart, the bars themselves were coloured with the corresponding colour for easy identification\nGray shading of the bars are removed, since it is generally obvious which bar is longer than the other\nIndividual Y axis labels for type of property is removed for simplicity. The same colour scheme is applied throughout the composite plot, so further labelling is not necessary\nThe composite plot showing six bar-line charts have one Y axis on each side, serving as an overall Y axis title"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#clarity-1",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#clarity-1",
    "title": "Take-home Exercise 2 - DataVis Makeover",
    "section": "Clarity",
    "text": "Clarity\n\n\n\n\n\n\n\nIdentified Areas for Improvement\nProposed Solutions\n\n\n\n\n\nIt is not clear on first glance what the red dotted line separates:\n\nTimeline? In the bar-line chart and stacked bar chart, it appears to be separating timeline of interest, but it is unclear whether the right or left side is the timeline of interest.\nMean/Median? In the raincloud plot, there is no timeline per se, so it seems to denote the mean or median transacted price\n\nIn-consistent Y axis for bar-line chart\n\nRight Y-axis, includes both numbers and scientific notation, making it challenging to interpret. Specifically, the lack of clear spacing between the digits in the numerical format makes it difficult to read, while the scientific notation may not be readily understandable to individuals unfamiliar with it.\n\n\n\nOnly plot mean or median as a red dotted line, for comparison between quarters\nThe graph gives an overall sense of trend. For more specific analysis, adding a description before or after the plot should suffice\nConvert all prices in axes to “millions” unit for ease of interpretability"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#sketch",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#sketch",
    "title": "Take-home Exercise 2 - DataVis Makeover",
    "section": "Sketch",
    "text": "Sketch"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#installing-and-loading-the-required-libraries",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#installing-and-loading-the-required-libraries",
    "title": "Take-home Exercise 2 - DataVis Makeover",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nNote: Ensure that the pacman package has already been installed.\nThe code chunk below loads the following packages using uses p_load() of pacman package:\n\n\n\n\n\n\n\ntidyverse\n\nInclude dpylr for data manipulation with “mutate”, “group_by”, “summarize”, etc.\nInclude ggplot2 for visualisation through histogram, boxplots, etc.\nInclude forcats for factoring and ordering of variables\n\n\n\nggdist\nggridges\nggrepel\nggthemes & hrbrthemes\n\nFor visualisation of distributions and uncertainity.\nFor creating density plots for visualisation of continuous distribution.\nFor repelling overlapping text labels in plot\nFor customisation of plot appearance\n\n\n\npatchwork\nFor combination and alignment of multiple plots for each visualisation.\n\n\nknitr\nFor elegant, flexible and fast report generation of underlying dataframes.\n\n\n\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse, readr, ggdist, ggridges, colorspace, knitr, forcats, reshape2, png, grid)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-the-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-the-data",
    "title": "Take-home Exercise 2 - DataVis Makeover",
    "section": "Importing the Data",
    "text": "Importing the Data\n\nThe data has been split into multiple .csv files\nThey will be loaded seperately, then bound together using rbind.\n\n\nrealis_1 &lt;- read_csv(\"data/ResidentialTransaction20240308160536.csv\")\nrealis_2 &lt;- read_csv(\"data/ResidentialTransaction20240308160736.csv\")\nrealis_3 &lt;- read_csv(\"data/ResidentialTransaction20240308161009.csv\")\nrealis_4 &lt;- read_csv(\"data/ResidentialTransaction20240308161109.csv\")\nrealis_5 &lt;- read_csv(\"data/ResidentialTransaction20240414220633.csv\")\n\nrealis_full &lt;- rbind(realis_1, realis_2, realis_3, realis_4, realis_5)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#summary-of-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#summary-of-data",
    "title": "Take-home Exercise 2 - DataVis Makeover",
    "section": "Summary of Data",
    "text": "Summary of Data\nsummary() function used to obtain dataset min, max values and interquartile range.\n\nOverview of Tibble Data FrameCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTransacted_Price\nArea_SQFT\nUnit_Price_PSF\nNumber_of_Units\n\n\n\n\n\nMin. : 440000\nMin. : 322.9\nMin. : 138\nMin. : 1.000\n\n\n\n1st Qu.: 1280000\n1st Qu.: 721.2\n1st Qu.:1384\n1st Qu.: 1.000\n\n\n\nMedian : 1660000\nMedian : 990.3\nMedian :1762\nMedian : 1.000\n\n\n\nMean : 2143286\nMean : 1191.6\nMean :1852\nMean : 1.005\n\n\n\n3rd Qu.: 2320000\n3rd Qu.: 1302.4\n3rd Qu.:2260\n3rd Qu.: 1.000\n\n\n\nMax. :392180000\nMax. :144883.4\nMax. :5756\nMax. :60.000\n\n\n\n\n\n\n\n\n# Understanding the distribution of numerical values in Realis \nrealis_num &lt;- realis_full[,c(\"Transacted Price ($)\", \"Area (SQFT)\", \"Unit Price ($ PSF)\", \"Number of Units\")]\n\nrealis_num &lt;- realis_num %&gt;% \n  rename(\"Transacted_Price\" = \"Transacted Price ($)\") %&gt;% \n  rename(\"Area_SQFT\" = \"Area (SQFT)\") %&gt;%\n  rename(\"Unit_Price_PSF\" = \"Unit Price ($ PSF)\") %&gt;% \n  rename(\"Number_of_Units\" = \"Number of Units\")\n  \nkable(summary(realis_num))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#exploring-outliers",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#exploring-outliers",
    "title": "Take-home Exercise 2 - DataVis Makeover",
    "section": "Exploring outliers",
    "text": "Exploring outliers\n\nCommercial En-bloc\nThe data set includes transactions that include commercial purchases that are infrequent and done by private developers for large land masses. This subset of transactions are unlikely to be done by individual buyers, and will be excluded from subsequent visualisation to prevent distortion of the axis.\n\nNumber of Units &gt; 5\nType of Sale = “Resale”\nPurchaser Address Indicator =“Private”\nTenure = “Freehold”\n\n\nOverview of DataframeCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject Name\nTransacted_Price\nArea_SQFT\nUnit_Price_PSF\nSale_Date\nAddress\nType of Sale\nType of Area\nArea (SQM)\nUnit Price ($ PSM)\nNett Price($)\nProperty Type\nNumber_of_Units\nTenure\nCompletion Date\nPurchaser Address Indicator\nPostal Code\nPostal District\nPostal Sector\nPlanning Region\nPlanning Area\nRegion_type\n\n\n\n\nBAGNALL COURT\n115280000\n68491.33\n1683\n04 Jan 2023\n813,817 ETC ENBLOC UPPER EAST COAST ROAD\nResale\nStrata\n6363\n18117\n-\nCondominium\n43\nFreehold\n1991\nPrivate\n466609\n16\n46\nEast Region\nBedok\nOCR\n\n\nMEYER PARK\n392180000\n144883.44\n2707\n09 Feb 2023\n81,83 ENBLOC MEYER ROAD #19-01,02 ETC\nResale\nStrata\n13460\n29137\n-\nCondominium\n60\nFreehold\n1985\nPrivate\n437910\n15\n43\nCentral Region\nMarine Parade\nRCR\n\n\nKEW LODGE\n66800000\n25177.00\n2653\n23 May 2023\n34,34A,36 ETC ENBLOC KHEAM HOCK ROAD\nResale\nStrata\n2339\n28559\n-\nTerrace House\n11\nFreehold\n1984\nPrivate\n298796\n11\n29\nCentral Region\nNovena\nCCR\n\n\nKARTAR APARTMENTS\n18000000\n6964.31\n2585\n11 Oct 2023\n41A,43 ETC ENBLOC THOMSON ROAD\nResale\nStrata\n647\n27821\n-\nApartment\n7\nFreehold\n-\nPrivate\n307583\n11\n30\nCentral Region\nNovena\nCCR\n\n\n\n\n\n\n\n\nenbloc_set &lt;- realis_full %&gt;% filter(`Tenure` == \"Freehold\", \n                                     `Number of Units` &gt; 5, \n                                     `Purchaser Address Indicator` == \"Private\", \n                                     `Type of Sale` == \"Resale\"\n                                      )\nenbloc_set_2 &lt;- enbloc_set %&gt;% \n  rename(\"Transacted_Price\" = \"Transacted Price ($)\") %&gt;% \n  rename(\"Area_SQFT\" = \"Area (SQFT)\") %&gt;%\n  rename(\"Unit_Price_PSF\" = \"Unit Price ($ PSF)\") %&gt;% \n  rename(\"Sale_Date\" = \"Sale Date\") %&gt;% \n  rename(\"Number_of_Units\" = \"Number of Units\")\n\nkable(enbloc_set_2)\n\n\n\n\n\n\nLarge new launches\nAnother subset identified are new project launches, where we observe a spike in transaction volumes in the month which new large developments are launched.\n\nType of Sale = “New Sale”\nCompletion Date = “Uncompleted”\nSum of Number of Units group by Project Name &gt; 100\n\n\nOverview of DataframeCode\n\n\n\n\n\n\n\nProject Name\nproj_sale\nmedian_proj_psf\n\n\n\n\nTHE RESERVE RESIDENCES\n679\n2474.0\n\n\nGRAND DUNMAN\n641\n2523.0\n\n\nLENTOR HILLS RESIDENCES\n487\n2107.0\n\n\nN.A.\n486\n2473.5\n\n\nLENTOR MANSION\n409\n2269.0\n\n\nTEMBUSU GRAND\n389\n2461.0\n\n\n\n\n\n\n\n\nSale_by_proj &lt;- realis_full %&gt;% \n  group_by(`Project Name`) %&gt;% \n  mutate(total_sale = sum(`Number of Units`))%&gt;% \n  arrange(desc(total_sale)) %&gt;%\n  ungroup()\n  \nnew_launch &lt;- Sale_by_proj %&gt;% \n  filter(`Type of Sale` == \"New Sale\", \n         `Completion Date` == \"Uncompleted\")\n\nlarge_new_launch &lt;- Sale_by_proj %&gt;% \n  filter(`Type of Sale` == \"New Sale\", \n         `Completion Date` == \"Uncompleted\", \n         total_sale &gt; 100)\n\nlarge_new_launch &lt;- large_new_launch %&gt;% \n  rename(\"Unit_Price_PSF\" = \"Unit Price ($ PSF)\")\n\nnew_proj_sale &lt;- large_new_launch %&gt;%\n  group_by(`Project Name`) %&gt;%\n  summarize(proj_sale = total_sale, \n            median_proj_psf = median(as.numeric(`Unit_Price_PSF`))) %&gt;%\n  arrange(desc(proj_sale))\n\nkable(head(distinct(new_proj_sale)), n =5)\n\n\n\n\n\n\nLuxury market\nTransactions with Transacted Price ($) in the top 2.5% are excluded in earlier price distribution visualisations as they skewed the records.\n\nhigh_val &lt;- realis_clean2 %&gt;%\n  filter(`Transacted Price ($)` &gt; quantile(`Transacted Price ($)`, 0.975, na.rm = TRUE)) \n\nind_high_val &lt;- anti_join(high_val, enbloc_set, by = c(\"Tenure\",\"Number of Units\",\"Type of Sale\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#no.-of-property-sold-per-property-type",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#no.-of-property-sold-per-property-type",
    "title": "Take-home Exercise 2 - DataVis Makeover",
    "section": "No. of Property Sold per Property Type",
    "text": "No. of Property Sold per Property Type\n\nData Wrangling\n\nsale_by_prop_month &lt;- realis_clean2 %&gt;% \n  group_by(`Property Type`, (year_month = format(`Sale Date`, \"%Y-%m\"))) %&gt;%\n  summarise(total_units = sum(`Number of Units`), avg_price = median(`Transacted Price ($)`))\n\nsale_by_prop_month &lt;- sale_by_prop_month %&gt;% rename_with( ~ \"year_month\", .cols = 2)\n\n# Converting the year_month from character back to continuous date for line plots \nsale_by_prop_month$year_month &lt;- as.Date(paste0(sale_by_prop_month$year_month, \"-01\"))\n\n# Extract the month and year information for labeling\nsale_by_prop_month$month &lt;- format(sale_by_prop_month$year_month, \"%b\")\nsale_by_prop_month$year &lt;- format(sale_by_prop_month$year_month, \"%Y\")\n\n# Create a label for each point showing the month and year\nsale_by_prop_month$label &lt;- paste(sale_by_prop_month$month, sale_by_prop_month$year)\n\nsale_by_prop_month_2 &lt;- sale_by_prop_month[,c(\"Property Type\", \"label\", \"total_units\", \"avg_price\")]\n\nmonth_sale &lt;- dcast(sale_by_prop_month_2, `Property Type` ~ `label`, value.var = \"total_units\")\n\nmonth_price &lt;- dcast(sale_by_prop_month_2, `Property Type` ~ `label`, value.var = \"avg_price\")\n\n\n\nHistogram Plot\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n# Sum the total number of units sold per month\nmonthly_sum &lt;- sale_by_prop_month %&gt;%\n  group_by(year_month) %&gt;%\n  summarise(total_units_sum = sum(total_units))\n\n# Calculate the mean of the total number of units sold per month\nmean_value &lt;- mean(monthly_sum$total_units_sum)\n\n# Plot the histogram with a mean line\nhist_plot &lt;- ggplot(data = sale_by_prop_month, \n                    aes(x = year_month, y = total_units, fill = `Property Type`)) + \n  geom_col(color = \"grey30\") + \n  labs(title = \"Distribution of Units Sold per Month\", \n       x = \"\", \n       y = \"No. of Units Sold\") +\n scale_fill_manual(values = prop_colors) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n  lims(x = as.Date(c(\"2023-01-01\", \"2024-03-01\"))) +\n  scale_x_continuous(breaks = seq(as.Date(\"2023-01-01\"), as.Date(\"2024-03-01\"), by = \"1 month\"),\n                     labels = format(seq(as.Date(\"2023-01-01\"), as.Date(\"2024-03-01\"), by = \"1 month\"), \"%b-%y\")) +\n  geom_hline(yintercept = mean_value, linetype = \"dotted\", color = \"red\") +\n  annotate(\"text\", x = as.Date(\"2023-12-01\"), y = mean_value, label = paste(\"Mean:\", round(mean_value, 2)), vjust = -3, colour=\"red\")\n\nhist_plot\n\n\n\n\n\n\nRaincloud Plot\nOnly select outliers within values defined in upper_bound will be plotted to maintain visibility of the raincloud plot.\n\n# Calculate the upper bound price at 97.5%\nupper_bound &lt;- quantile(realis_clean2$`Transacted Price ($)`, 0.975)\nprint(paste(\"Upper bound price at 97.5%:\", upper_bound))\n\n[1] \"Upper bound price at 97.5%: 6200000\"\n\n# Filter realis_clean2 to include only rows where Transacted Price ($) is less than or equal to the upper bound\nfor_raincloud &lt;- realis_clean2[realis_clean2$`Transacted Price ($)` &lt;= upper_bound, ]\n\n# View the first few rows of the new dataframe\nhead(for_raincloud)\n\n# A tibble: 6 × 27\n  `Project Name`       `Transacted Price ($)` `Area (SQFT)` `Unit Price ($ PSF)`\n  &lt;chr&gt;                                 &lt;dbl&gt;         &lt;dbl&gt;                &lt;dbl&gt;\n1 THE REEF AT KING'S …                2317000          883.                 2625\n2 URBAN TREASURES                     1823500          883.                 2066\n3 NORTH GAIA                          1421112         1076.                 1320\n4 NORTH GAIA                          1258112         1033.                 1218\n5 PARC BOTANNIA                       1280000          872.                 1468\n6 NANYANG PARK                        5870000         3323.                 1767\n# ℹ 23 more variables: `Sale Date` &lt;date&gt;, Address &lt;chr&gt;, `Type of Sale` &lt;chr&gt;,\n#   `Type of Area` &lt;chr&gt;, `Area (SQM)` &lt;dbl&gt;, `Unit Price ($ PSM)` &lt;dbl&gt;,\n#   `Nett Price($)` &lt;chr&gt;, `Property Type` &lt;chr&gt;, `Number of Units` &lt;dbl&gt;,\n#   Tenure &lt;chr&gt;, `Completion Date` &lt;chr&gt;, `Purchaser Address Indicator` &lt;chr&gt;,\n#   `Postal Code` &lt;chr&gt;, `Postal District` &lt;dbl&gt;, `Postal Sector` &lt;chr&gt;,\n#   `Planning Region` &lt;chr&gt;, `Planning Area` &lt;chr&gt;, Region_type &lt;chr&gt;,\n#   years &lt;dbl&gt;, start_date &lt;date&gt;, end_date &lt;date&gt;, remaining_years &lt;dbl&gt;, …\n\n\nDistribution of Transacted Price by Property Type\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n# Calculate the median transacted price\nmedian_price &lt;- median(for_raincloud$`Transacted Price ($)`)\n\n# Create the plot\nprop_price_dist &lt;- ggplot(for_raincloud, \n                     aes(x = `Property Type`, y = `Transacted Price ($)`, fill = `Property Type` )) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2) +\n   coord_flip() +\n  scale_y_continuous(labels = scales::number_format(scale = 1e-6, suffix = \"M\")) +\n  scale_fill_manual(values = prop_colors)  + \n  scale_x_discrete() + \n  labs(title = \"Distribution of Transacted Price\\nby Property Type\", \n       x = \"\", \n       y = \"Transacted Price\") +\n   theme(legend.position = \"none\",plot.title = element_text(size = 10)) +\n   geom_hline(yintercept = median_price, linetype = \"dotted\", color = \"red\") +\n  annotate(\"text\", x = 0.5, y = median_price, label = \"Median: 1.6M\", vjust = -6, colour = \"red\")\n\n\nprop_price_dist"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#transaction-price-no.-of-units-sold-by-property-type",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#transaction-price-no.-of-units-sold-by-property-type",
    "title": "Take-home Exercise 2 - DataVis Makeover",
    "section": "Transaction Price & No. of Units sold by Property Type",
    "text": "Transaction Price & No. of Units sold by Property Type\nThe code chunk below:\n\nPartitions subset of the transaction records based on Property Type\nCreates bar chart on the sum of No of Units sold per month\nCreates line graph on the median Transaction Price for the property sold that month\n\n\nApartmentCondominiumExecutive CondominiumTerrace HouseSemi-Detached HouseDetached House\n\n\n\n# summary(apt_by_month)\n# Max units: 1444, max price = $1,875,000\n\napt_by_month &lt;- subset(sale_by_prop_month,  sale_by_prop_month$`Property Type` == \"Apartment\")\n\n# Creating the graph\nhist_plot_apt &lt;- ggplot(data = apt_by_month, aes(x = year_month, y = total_units, fill = total_units)) +\n  geom_col(fill = \"steelblue\") +\n  geom_line(aes(y = avg_price * 1500 / 2000000), color = \"blueviolet\", linewidth = 1) +\n  scale_y_continuous(\n    name = \"No. of Units Sold\",\n    limits = c(0, 1500),\n    sec.axis = sec_axis(~. * 2000000 / 1500, name = \"Median Price\", labels = scales::number_format(scale = 1e-6, suffix = \"M\"))\n  ) +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 90, hjust = 1)) +  \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b-%y\") +\n  scale_x_continuous(breaks = seq(as.Date(\"2023-01-01\"), as.Date(\"2024-03-01\"), by = \"1 month\"),labels = format(seq(as.Date(\"2023-01-01\"), as.Date(\"2024-03-01\"), by = \"1 month\"), \"%b-%y\")) +\n  labs(x = NULL)\n\nhist_plot_apt\n\n\n\n\n\n\n\n# summary(c_by_month)\n# max unit sold: 1108, max price: 1780000\n\nc_by_month &lt;- subset(sale_by_prop_month,  sale_by_prop_month$`Property Type` == \"Condominium\")\n\n#Creating the graph\nhist_plot_c &lt;- ggplot(data = c_by_month, aes(x = year_month, y = total_units, fill = total_units)) +\n  geom_col(fill = \"skyblue\") +\n  geom_line(aes(y = avg_price * 1500 / 2000000), color = \"blueviolet\", linewidth = 1) +\n  scale_y_continuous(\n    name = \"No. of Units Sold\",\n    limits = c(0, 1500),\n    sec.axis = sec_axis(~. * 2000000 / 1500, name = \"Median Price\", labels = scales::number_format(scale = 1e-6, suffix = \"M\"))\n  ) +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 90, hjust = 1)) +  \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b-%y\") +\n  scale_x_continuous(breaks = seq(as.Date(\"2023-01-01\"), as.Date(\"2024-03-01\"), by = \"1 month\"),labels = format(seq(as.Date(\"2023-01-01\"), as.Date(\"2024-03-01\"), by = \"1 month\"), \"%b-%y\")) +\n  labs(x = NULL)\n\nhist_plot_c\n\n\n\n\n\n\n\n# summary(ec_by_month) \n# max unit sold: 459, max avg price = 1504000\n\nec_by_month &lt;- subset(sale_by_prop_month,  sale_by_prop_month$`Property Type` == \"Executive Condominium\")\n\n\n#Creating the graph\nhist_plot_ec &lt;- ggplot(data = ec_by_month, aes(x = year_month, y = total_units, fill = total_units)) +\n  geom_col(fill = \"royalblue\") +\n  geom_line(aes(y = avg_price * 1500 / 2000000), color = \"blueviolet\", linewidth = 1) +\n  scale_y_continuous(\n    name = \"No. of Units Sold\",\n    limits = c(0, 1500),\n    sec.axis = sec_axis(~. * 2000000 / 1500, name = \"Median Price\", labels = scales::number_format(scale = 1e-6, suffix = \"M\"))\n  ) +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 90, hjust = 1)) +  \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b-%y\") +\n  scale_x_continuous(breaks = seq(as.Date(\"2023-01-01\"), as.Date(\"2024-03-01\"), by = \"1 month\"),labels = format(seq(as.Date(\"2023-01-01\"), as.Date(\"2024-03-01\"), by = \"1 month\"), \"%b-%y\")) +\n  labs(x = NULL)\n\nhist_plot_ec\n\n\n\n\n\n\n\n# kable(summary(t_by_month))\n# max units: 95\n# max price: 3,844,000\n\nt_by_month &lt;- subset(sale_by_prop_month,  sale_by_prop_month$`Property Type` == \"Terrace House\")\n\n\n#Creating the graph\nhist_plot_t &lt;- ggplot(data = t_by_month, aes(x = year_month, y = total_units, fill = total_units)) +\n  geom_col(fill = \"deepskyblue\") +\n  geom_line(aes(y = avg_price * 100 / 15000000), color = \"blueviolet\", linewidth = 1) +\n  scale_y_continuous(\n    name = \"No. of Units Sold\",\n    limits = c(0, 100),\n    sec.axis = sec_axis(~. * 15000000 / 100, name = \"Median Price\", labels = scales::number_format(scale = 1e-6, suffix = \"M\"))\n  ) +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 90, hjust = 1)) +  \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b-%y\")  +\n  scale_x_continuous(breaks = seq(as.Date(\"2023-01-01\"), as.Date(\"2024-03-01\"), by = \"1 month\"),labels = format(seq(as.Date(\"2023-01-01\"), as.Date(\"2024-03-01\"), by = \"1 month\"), \"%b-%y\")) +\n  labs(x = NULL)\n\nhist_plot_t\n\n\n\n\n\n\n\n# kable(summary(sd_by_month))\n# max unit: 67\n# max price: 6,539,400\n\nsd_by_month &lt;- subset(sale_by_prop_month,  sale_by_prop_month$`Property Type` == \"Semi-Detached House\")\n\n\n#Creating the graph\nhist_plot_sd &lt;- ggplot(data = sd_by_month, aes(x = year_month, y = total_units, fill = total_units)) +\n  geom_col(fill = \"cornflowerblue\") +\n  geom_line(aes(y = avg_price * 100 / 15000000), color = \"blueviolet\", linewidth = 1) +\n  scale_y_continuous(\n    name = \"No. of Units Sold\",\n    limits = c(0, 100),\n    sec.axis = sec_axis(~. * 15000000 / 100, name = \"Median Price\", labels = scales::number_format(scale = 1e-6, suffix = \"M\"))\n  ) +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 90, hjust = 1)) +  \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b-%y\")  +\n  scale_x_continuous(breaks = seq(as.Date(\"2023-01-01\"), as.Date(\"2024-03-01\"), by = \"1 month\"),labels = format(seq(as.Date(\"2023-01-01\"), as.Date(\"2024-03-01\"), by = \"1 month\"), \"%b-%y\")) +\n  labs(x = NULL)\n\nhist_plot_sd\n\n\n\n\n\n\n\n# kable(summary(d_by_month))\n# max unit: 34\n# max price: 14,500,000\n\nd_by_month &lt;- subset(sale_by_prop_month,  sale_by_prop_month$`Property Type` == \"Detached House\")\n\nhist_plot_d &lt;- ggplot(data = d_by_month, aes(x = year_month, y = total_units, fill = total_units)) +\n  geom_col(fill = \"lightblue\") +\n  geom_line(aes(y = avg_price * 100 / 15000000), color = \"blueviolet\", linewidth = 1) +\n  scale_y_continuous(\n    name = \"No. of Units Sold\",\n    limits = c(0, 100),\n    sec.axis = sec_axis(~. * 15000000 / 100, name = \"Median Price\", labels = scales::number_format(scale = 1e-6, suffix = \"M\"))\n  ) +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 90, hjust = 1)) +  \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b-%y\")  +\n  scale_x_continuous(breaks = seq(as.Date(\"2023-01-01\"), as.Date(\"2024-03-01\"), by = \"1 month\"),labels = format(seq(as.Date(\"2023-01-01\"), as.Date(\"2024-03-01\"), by = \"1 month\"), \"%b-%y\")) +\n  labs(x = NULL)\n\nhist_plot_d"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#composite-plot-1",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#composite-plot-1",
    "title": "Take-home Exercise 2 - DataVis Makeover",
    "section": "Composite Plot 1",
    "text": "Composite Plot 1\nTo facilitate the composite plot, the legend for the plots are hidden\n\nhist_plot &lt;- hist_plot + theme(legend.position = \"none\")\n\nPatchwork is used to create the composite plot. Since the color scheme remains consistent throughout the plot and the property types are clearly represented in the raincloud plot just below it, the legend is omitted from the bar chart.\n\n# Combine the plots\ncplot1 &lt;- hist_plot + prop_price_dist + plot_layout(heights = c(1, 4), ncol =1)\n\n# Display the combined plot\ncplot1"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#composite-plot-2",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#composite-plot-2",
    "title": "Take-home Exercise 2 - DataVis Makeover",
    "section": "Composite Plot 2",
    "text": "Composite Plot 2\nIn the resulting bar-line charts, the use of non-standardized Y-axes diminishes the ease of direct comparison between different categories. Standardizing the values could potentially improve comparability but would obscure bars representing extremely small values. For instance, the “Number of Units Sold” might vary widely, such as 34 for Detached Houses and 1444 for Apartments.\nTo strike a balance, two separate scales were employed for each Y-axis. The left Y-axis ranges from 0 to 100 for the number of units sold and from 0 to 150 for the median price. Meanwhile, the right Y-axis spans from 0 to 2 million for the number of units sold and from 0 to 15 million for the median price. This approach ensures that both the magnitude of the values and the differences between categories remain visible to the audience.\nTo facilitate the composite plot, the x axis showing Sale Date for the plots are hidden\n\nhist_plot_apt &lt;- hist_plot_apt + \n  labs(x = NULL) +\n    theme(axis.text.x = element_blank(),\n          axis.title.x = element_blank(),\n          axis.ticks.x = element_blank())\n\nhist_plot_c &lt;- hist_plot_c + \n  labs(x = NULL) +\n    theme(axis.text.x = element_blank(),\n          axis.title.x = element_blank(),\n          axis.ticks.x = element_blank())\n\nhist_plot_d &lt;- hist_plot_d + \n  labs(x = NULL) +\n    theme(axis.text.x = element_blank(),\n          axis.title.x = element_blank(),\n          axis.ticks.x = element_blank())\n\nhist_plot_ec &lt;- hist_plot_ec + \n  labs(x = NULL) +\n    theme(axis.text.x = element_blank(),\n          axis.title.x = element_blank(),\n          axis.ticks.x = element_blank())\n\nhist_plot_sd &lt;- hist_plot_sd + \n  labs(x = NULL) +\n    theme(axis.text.x = element_blank(),\n          axis.title.x = element_blank(),\n          axis.ticks.x = element_blank())\n\nhist_plot_t &lt;- hist_plot_t + \n  labs(x = NULL) +\n    theme(axis.text.x = element_blank(),\n          axis.title.x = element_blank(),\n          axis.ticks.x = element_blank())\n\nIn the plot below, we see that:\n\nHaving repeated y axis labels are not necessary, since they are consistent for all plots\nWith X-axis i.e. sale date removed, it can be more challenging to discern when the transaction happened\nDue to the scale on the left Y-axis, bar charts for Detached House, Semi Detached House and Terrace House are difficult to interpret from the plot\nDue to the scales of the Y axis, the plots should also be rearranged accordingly for easy visual comparison\nTitle “Transaction Price & No. of Units sold by Property Type” is missing\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nhist_plot_apt / hist_plot_c / hist_plot_d / hist_plot_ec / hist_plot_sd / hist_plot_t\n\n\n\n\nTherefore, we revise the plot as follows:\n\nHide all Y axis labels\nOnly show Y axis label i.e. “Number of Units” and “Median Price” for third plot i.e. Executive Condominium. This will serve as an overall Y-axis label . It should be clear that this label applies to all plots in the composite plots\nOnly last plot i.e. Terrace House, will show X-axis label “Sale date”. It should be clear that this label applies to all above plots as well\nRearrange the plots to show in this order: Apartment, Condominium, Executive Condominium, Detached House, Semi Detached House, Terrace House\nAdd overall plot title\n\n\n# List of plots\nplot_list2 &lt;- list(hist_plot_apt, hist_plot_d, hist_plot_ec, hist_plot_sd, hist_plot_t)\n\n# Apply theme modifications to all plots in the list\nfor (plot in plot_list2) {\n  plot &lt;- plot +\n    labs(x = NULL, y = NULL) +\n  theme(axis.text.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        axis.title.y = element_blank())\n}\n\n# hist_plot_a add title\nhist_plot_apt &lt;- hist_plot_apt +\n  labs(title = \"Transaction Price & No. of Units sold\\nby Property Type\") +\n  theme(plot.title = element_text(size = 10))\n\n\n# hist_plot_c keep Y axis\nhist_plot_c &lt;- hist_plot_c +\n  labs(x = NULL) +\n  theme(axis.text.x = element_blank(),\n        axis.ticks.x = element_blank())\n\n# hist_plot_t x axis to turn back on\nhist_plot_t &lt;- hist_plot_t +\n  labs(x = NULL, y = NULL) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1),\n        axis.ticks.x = element_line(),\n        axis.title.y = element_blank())\n\nRevised plot\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ncplot2 &lt;- hist_plot_apt + hist_plot_c + hist_plot_ec + hist_plot_d + hist_plot_sd + hist_plot_t +  plot_layout(ncol = 1,axis_titles = \"collect\") \n\ncplot2"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#overall-composite-plot",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#overall-composite-plot",
    "title": "Take-home Exercise 2 - DataVis Makeover",
    "section": "Overall Composite Plot",
    "text": "Overall Composite Plot\n\ncplot1 | cplot2"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#before",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#before",
    "title": "Take-home Exercise 2 - DataVis Makeover",
    "section": "Before",
    "text": "Before"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#after",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#after",
    "title": "Take-home Exercise 2 - DataVis Makeover",
    "section": "After",
    "text": "After\n\n\n\n\n\n\n\n\nNote\n\n\n\nThank you Jing Yi for providing your take home exercise 1 for my learning!"
  }
]